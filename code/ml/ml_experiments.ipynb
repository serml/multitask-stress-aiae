{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import optuna\n",
    "import warnings\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "# English: Import models and tools\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(df, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Finds and removes one of each pair of highly correlated features in a dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe with numerical features.\n",
    "    threshold : float, optional\n",
    "        The correlation threshold above which a feature is considered redundant. \n",
    "        Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        A new dataframe with highly correlated features removed.\n",
    "    list\n",
    "        A list of the column names that were dropped.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # --- Step 1: Remove zero-variance columns ---\n",
    "    # These columns have no predictive power and can cause issues with correlation calculation.\n",
    "    cols_to_drop_zerovar = df_copy.columns[df_copy.nunique() <= 1]\n",
    "    if not cols_to_drop_zerovar.empty:\n",
    "        df_copy.drop(columns=cols_to_drop_zerovar, inplace=True)\n",
    "        print(f\"Removed {len(cols_to_drop_zerovar)} columns with zero or single unique values: {cols_to_drop_zerovar.tolist()}\")\n",
    "    \n",
    "    # --- Step 2: Calculate the correlation matrix ---\n",
    "    # Use .abs() because a strong negative correlation (-0.95) is as redundant as a strong positive one.\n",
    "    corr_matrix = df_copy.corr().abs()\n",
    "    \n",
    "    # --- Step 3: Identify one of each highly correlated pair ---\n",
    "    # Select the upper triangle of the correlation matrix to avoid duplicates\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find features with correlation greater than the threshold\n",
    "    cols_to_drop_corr = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    # --- Step 4: Drop the identified features ---\n",
    "    df_reduced = df_copy.drop(columns=cols_to_drop_corr)\n",
    "    \n",
    "    # Combine all dropped columns for the report\n",
    "    all_dropped_cols = cols_to_drop_zerovar.tolist() + cols_to_drop_corr\n",
    "    \n",
    "    return df_reduced, all_dropped_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/processed/studentlife_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>...</th>\n",
       "      <th>organizational_deadlines</th>\n",
       "      <th>organizational_days_until_next_deadline</th>\n",
       "      <th>environmental_weekday</th>\n",
       "      <th>individual_personality_extraversion</th>\n",
       "      <th>individual_personality_agreeableness</th>\n",
       "      <th>individual_personality_conscientiousness</th>\n",
       "      <th>individual_personality_neuroticism</th>\n",
       "      <th>individual_personality_openness</th>\n",
       "      <th>individual_previous_stress_level</th>\n",
       "      <th>individual_days_since_previous_stress_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>3.354167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.525000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>44.291667</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.150000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.929167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>47.041667</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>0</td>\n",
       "      <td>18.033333</td>\n",
       "      <td>24.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>87.875000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-22</td>\n",
       "      <td>0</td>\n",
       "      <td>14.208333</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>87.708333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>0</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>88.083333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>19.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>1</td>\n",
       "      <td>9.662500</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.041667</td>\n",
       "      <td>95.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id        date  stress_level  environmental_temperature_mean  \\\n",
       "1          4  2013-03-28             1                        3.450000   \n",
       "2          4  2013-03-29             1                        3.354167   \n",
       "3          4  2013-04-02             2                       -1.525000   \n",
       "4          4  2013-04-03             2                       -1.150000   \n",
       "5          4  2013-04-04             1                        1.929167   \n",
       "..       ...         ...           ...                             ...   \n",
       "643       59  2013-05-21             0                       18.033333   \n",
       "644       59  2013-05-22             0                       14.208333   \n",
       "645       59  2013-05-23             0                       18.450000   \n",
       "646       59  2013-05-24             1                       13.508333   \n",
       "647       59  2013-05-27             1                        9.662500   \n",
       "\n",
       "     environmental_temperature_max  environmental_temperature_min  \\\n",
       "1                              8.0                            0.9   \n",
       "2                              8.6                           -1.6   \n",
       "3                              1.0                           -3.6   \n",
       "4                              4.0                           -4.2   \n",
       "5                              8.6                           -2.2   \n",
       "..                             ...                            ...   \n",
       "643                           24.4                           13.9   \n",
       "644                           24.5                            8.5   \n",
       "645                           24.7                           13.7   \n",
       "646                           19.4                            6.9   \n",
       "647                           17.4                            2.3   \n",
       "\n",
       "     environmental_humidity_mean  environmental_humidity_max  \\\n",
       "1                      76.333333                        95.0   \n",
       "2                      75.833333                        95.0   \n",
       "3                      44.291667                        53.0   \n",
       "4                      45.833333                        58.0   \n",
       "5                      47.041667                        58.0   \n",
       "..                           ...                         ...   \n",
       "643                    87.875000                        97.0   \n",
       "644                    87.708333                        99.0   \n",
       "645                    88.083333                        99.0   \n",
       "646                    94.250000                       100.0   \n",
       "647                    69.041667                        95.0   \n",
       "\n",
       "     environmental_humidity_min  environmental_precipitation  ...  \\\n",
       "1                          47.0                          1.5  ...   \n",
       "2                          55.0                          1.3  ...   \n",
       "3                          32.0                          0.0  ...   \n",
       "4                          29.0                          0.0  ...   \n",
       "5                          33.0                          0.0  ...   \n",
       "..                          ...                          ...  ...   \n",
       "643                        67.0                          5.5  ...   \n",
       "644                        63.0                          6.2  ...   \n",
       "645                        68.0                          1.9  ...   \n",
       "646                        84.0                         11.7  ...   \n",
       "647                        38.0                          0.0  ...   \n",
       "\n",
       "     organizational_deadlines  organizational_days_until_next_deadline  \\\n",
       "1                         0.0                                     11.0   \n",
       "2                         0.0                                     10.0   \n",
       "3                         0.0                                      6.0   \n",
       "4                         0.0                                      5.0   \n",
       "5                         0.0                                      4.0   \n",
       "..                        ...                                      ...   \n",
       "643                       0.0                                      3.0   \n",
       "644                       0.0                                      2.0   \n",
       "645                       0.0                                      1.0   \n",
       "646                       1.0                                      5.0   \n",
       "647                       0.0                                      2.0   \n",
       "\n",
       "     environmental_weekday  individual_personality_extraversion  \\\n",
       "1                        3                                    1   \n",
       "2                        4                                    1   \n",
       "3                        1                                    1   \n",
       "4                        2                                    1   \n",
       "5                        3                                    1   \n",
       "..                     ...                                  ...   \n",
       "643                      1                                   14   \n",
       "644                      2                                   14   \n",
       "645                      3                                   14   \n",
       "646                      4                                   14   \n",
       "647                      0                                   14   \n",
       "\n",
       "     individual_personality_agreeableness  \\\n",
       "1                                       4   \n",
       "2                                       4   \n",
       "3                                       4   \n",
       "4                                       4   \n",
       "5                                       4   \n",
       "..                                    ...   \n",
       "643                                    13   \n",
       "644                                    13   \n",
       "645                                    13   \n",
       "646                                    13   \n",
       "647                                    13   \n",
       "\n",
       "     individual_personality_conscientiousness  \\\n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "5                                           0   \n",
       "..                                        ...   \n",
       "643                                        -1   \n",
       "644                                        -1   \n",
       "645                                        -1   \n",
       "646                                        -1   \n",
       "647                                        -1   \n",
       "\n",
       "     individual_personality_neuroticism  individual_personality_openness  \\\n",
       "1                                    15                               17   \n",
       "2                                    15                               17   \n",
       "3                                    15                               17   \n",
       "4                                    15                               17   \n",
       "5                                    15                               17   \n",
       "..                                  ...                              ...   \n",
       "643                                   5                               23   \n",
       "644                                   5                               23   \n",
       "645                                   5                               23   \n",
       "646                                   5                               23   \n",
       "647                                   5                               23   \n",
       "\n",
       "     individual_previous_stress_level  \\\n",
       "1                                 0.0   \n",
       "2                                 1.0   \n",
       "3                                 1.0   \n",
       "4                                 2.0   \n",
       "5                                 2.0   \n",
       "..                                ...   \n",
       "643                               0.0   \n",
       "644                               0.0   \n",
       "645                               0.0   \n",
       "646                               0.0   \n",
       "647                               1.0   \n",
       "\n",
       "     individual_days_since_previous_stress_measurement  \n",
       "1                                                  1.0  \n",
       "2                                                  1.0  \n",
       "3                                                  4.0  \n",
       "4                                                  1.0  \n",
       "5                                                  1.0  \n",
       "..                                                 ...  \n",
       "643                                                1.0  \n",
       "644                                                1.0  \n",
       "645                                                1.0  \n",
       "646                                                1.0  \n",
       "647                                                3.0  \n",
       "\n",
       "[569 rows x 37 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando validación cruzada con 5 pliegues ---\n",
      "\n",
      "--- Procesando Pliegue 1/5 ---\n",
      "  - Entrenando gplearn...\n",
      "  - gplearn F1-Score: 0.3384\n",
      "  - Entrenando PySR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:1036: FutureWarning: `loss` has been renamed to `elementwise_loss` in PySRRegressor. Please use that instead.\n",
      "  warnings.warn(\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - PySR F1-Score: 0.3384\n",
      "\n",
      "--- Procesando Pliegue 2/5 ---\n",
      "  - Entrenando gplearn...\n",
      "  - gplearn F1-Score: 0.1939\n",
      "  - Entrenando PySR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:1036: FutureWarning: `loss` has been renamed to `elementwise_loss` in PySRRegressor. Please use that instead.\n",
      "  warnings.warn(\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - PySR F1-Score: 0.1939\n",
      "\n",
      "--- Procesando Pliegue 3/5 ---\n",
      "  - Entrenando gplearn...\n",
      "  - gplearn F1-Score: 0.1886\n",
      "  - Entrenando PySR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:1036: FutureWarning: `loss` has been renamed to `elementwise_loss` in PySRRegressor. Please use that instead.\n",
      "  warnings.warn(\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - PySR F1-Score: 0.1886\n",
      "\n",
      "--- Procesando Pliegue 4/5 ---\n",
      "  - Entrenando gplearn...\n",
      "  - gplearn F1-Score: 0.1480\n",
      "  - Entrenando PySR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:1036: FutureWarning: `loss` has been renamed to `elementwise_loss` in PySRRegressor. Please use that instead.\n",
      "  warnings.warn(\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - PySR F1-Score: 0.1480\n",
      "\n",
      "--- Procesando Pliegue 5/5 ---\n",
      "  - Entrenando gplearn...\n",
      "  - gplearn F1-Score: 0.3231\n",
      "  - Entrenando PySR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:1036: FutureWarning: `loss` has been renamed to `elementwise_loss` in PySRRegressor. Please use that instead.\n",
      "  warnings.warn(\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - PySR F1-Score: 0.3277\n",
      "\n",
      "--- Resultados Finales del Experimento ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "      <th>Best Formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gplearn</td>\n",
       "      <td>0.338443</td>\n",
       "      <td>div(X30, X22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PySR</td>\n",
       "      <td>0.338443</td>\n",
       "      <td>exp(sin(individual_personality_openness) * 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gplearn</td>\n",
       "      <td>0.193939</td>\n",
       "      <td>div(X3, X22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>PySR</td>\n",
       "      <td>0.193939</td>\n",
       "      <td>exp(sin(individual_personality_agreeableness) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>gplearn</td>\n",
       "      <td>0.188569</td>\n",
       "      <td>div(X15, X22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>PySR</td>\n",
       "      <td>0.188569</td>\n",
       "      <td>exp(sin(individual_personality_agreeableness /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>gplearn</td>\n",
       "      <td>0.147951</td>\n",
       "      <td>div(X8, X22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>PySR</td>\n",
       "      <td>0.147951</td>\n",
       "      <td>exp(sin(individual_personality_agreeableness) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>gplearn</td>\n",
       "      <td>0.323096</td>\n",
       "      <td>div(X22, X22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>PySR</td>\n",
       "      <td>0.327654</td>\n",
       "      <td>(sin(individual_personality_agreeableness) * -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Algorithm  F1-Score (weighted)  \\\n",
       "0     1   gplearn             0.338443   \n",
       "1     1      PySR             0.338443   \n",
       "2     2   gplearn             0.193939   \n",
       "3     2      PySR             0.193939   \n",
       "4     3   gplearn             0.188569   \n",
       "5     3      PySR             0.188569   \n",
       "6     4   gplearn             0.147951   \n",
       "7     4      PySR             0.147951   \n",
       "8     5   gplearn             0.323096   \n",
       "9     5      PySR             0.327654   \n",
       "\n",
       "                                        Best Formula  \n",
       "0                                      div(X30, X22)  \n",
       "1  exp(sin(individual_personality_openness) * 0.4...  \n",
       "2                                       div(X3, X22)  \n",
       "3  exp(sin(individual_personality_agreeableness) ...  \n",
       "4                                      div(X15, X22)  \n",
       "5  exp(sin(individual_personality_agreeableness /...  \n",
       "6                                       div(X8, X22)  \n",
       "7  exp(sin(individual_personality_agreeableness) ...  \n",
       "8                                      div(X22, X22)  \n",
       "9  (sin(individual_personality_agreeableness) * -...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resumen de Rendimiento Promedio ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PySR</td>\n",
       "      <td>0.239311</td>\n",
       "      <td>0.087481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gplearn</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.086347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm      mean       std\n",
       "0      PySR  0.239311  0.087481\n",
       "1   gplearn  0.238400  0.086347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparar los datos\n",
    "X = dataset.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "y = dataset['stress_level']\n",
    "groups = dataset['user_id']\n",
    "\n",
    "# --- 2. CONFIGURACIÓN DEL EXPERIMENTO ---\n",
    "n_splits = 5  # Usamos 2 pliegues para una demostración rápida\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "results_list = []\n",
    "\n",
    "min_class, max_class = y.min(), y.max() # Para el clipping posterior\n",
    "\n",
    "# --- 3. BUCLE DE VALIDACIÓN CRUZADA ---\n",
    "print(f\"--- Iniciando validación cruzada con {n_splits} pliegues ---\")\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    print(f\"\\n--- Procesando Pliegue {fold + 1}/{n_splits} ---\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --- Experimento A: gplearn ---\n",
    "    print(\"  - Entrenando gplearn...\")\n",
    "    # Usamos SymbolicClassifier ya que stress_level es una categoría\n",
    "    gp_model = SymbolicRegressor(population_size=2000,\n",
    "                           generations=15, \n",
    "                           stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, \n",
    "                           p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, \n",
    "                           p_point_mutation=0.1,\n",
    "                           max_samples=0.9, \n",
    "                           verbose=0,\n",
    "                           parsimony_coefficient=0.001, \n",
    "                           random_state=42)\n",
    "    gp_model.fit(X_train, y_train)\n",
    "    # <-- CORRECCIÓN: Convertir predicciones de regresión a clases\n",
    "    raw_gp_preds = gp_model.predict(X_test)\n",
    "    rounded_gp_preds = np.round(raw_gp_preds)\n",
    "    gp_preds = np.clip(rounded_gp_preds, min_class, max_class).astype(int)\n",
    "    \n",
    "    gp_f1 = f1_score(y_test, gp_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Guardar resultados de gplearn\n",
    "    results_list.append({\n",
    "        'Fold': fold + 1,\n",
    "        'Algorithm': 'gplearn',\n",
    "        'F1-Score (weighted)': gp_f1,\n",
    "        'Best Formula': str(gp_model._program)\n",
    "    })\n",
    "    print(f\"  - gplearn F1-Score: {gp_f1:.4f}\")\n",
    "\n",
    "    # --- Experimento B: PySR ---\n",
    "    # PySR es opcional y requiere una instalación más compleja.\n",
    "    try:\n",
    "        \n",
    "        print(\"  - Entrenando PySR...\")\n",
    "        pysr_model = PySRRegressor(\n",
    "            niterations=30,  # Menos iteraciones que gplearn, ya que es más eficiente\n",
    "            binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "            unary_operators=[\"sin\", \"cos\", \"exp\", \"log\"],\n",
    "            model_selection=\"best\", # Selecciona la mejor fórmula que equilibra complejidad y precisión\n",
    "            # El `loss` define cómo se mide el error\n",
    "            loss=\"L2DistLoss()\",\n",
    "            procs=0,\n",
    "            verbosity=0\n",
    "        )\n",
    "        pysr_model.fit(X_train, y_train)\n",
    "\n",
    "        # <-- INICIO DE LA CORRECCIÓN ---\n",
    "        # 1. Obtener las predicciones continuas del regresor\n",
    "        raw_predictions = pysr_model.predict(X_test)\n",
    "        \n",
    "        # 2. Redondear al entero más cercano para convertir a clase\n",
    "        rounded_predictions = np.round(raw_predictions)\n",
    "        \n",
    "        # 3. Asegurar que las predicciones estén dentro del rango de clases válidas (clipping)\n",
    "        pysr_preds = np.clip(rounded_predictions, min_class, max_class).astype(int)\n",
    "        # <-- FIN DE LA CORRECCIÓN ---\n",
    "\n",
    "        pysr_f1 = f1_score(y_test, pysr_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        # Guardar resultados de PySR\n",
    "        results_list.append({\n",
    "            'Fold': fold + 1,\n",
    "            'Algorithm': 'PySR',\n",
    "            'F1-Score (weighted)': pysr_f1,\n",
    "            'Best Formula': pysr_model.get_best()[\"equation\"] # Obtener la mejor fórmula\n",
    "        })\n",
    "        print(f\"  - PySR F1-Score: {pysr_f1:.4f}\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"  - PySR no está instalado. Saltando este experimento.\")\n",
    "        results_list.append({\n",
    "            'Fold': fold + 1,\n",
    "            'Algorithm': 'PySR',\n",
    "            'F1-Score (weighted)': np.nan,\n",
    "            'Best Formula': 'Not executed'\n",
    "        })\n",
    "\n",
    "# --- 4. PRESENTACIÓN DE RESULTADOS ---\n",
    "print(\"\\n--- Resultados Finales del Experimento ---\")\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n--- Resumen de Rendimiento Promedio ---\")\n",
    "summary = results_df.groupby('Algorithm')['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting cross-validation with 5 folds ---\n",
      "\n",
      "--- Processing Fold 1/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.5509\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:06:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.3889\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3799\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4075\n",
      "\n",
      "--- Processing Fold 2/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4879\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.4953\n",
      "  - Training LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:06:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LightGBM F1-Score: 0.4779\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4614\n",
      "\n",
      "--- Processing Fold 3/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4584\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.4468\n",
      "  - Training LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:06:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LightGBM F1-Score: 0.4039\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4466\n",
      "\n",
      "--- Processing Fold 4/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3452\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:06:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.3338\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3586\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4204\n",
      "\n",
      "--- Processing Fold 5/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4345\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.4317\n",
      "  - Training LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:06:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LightGBM F1-Score: 0.4760\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4228\n",
      "\n",
      "--- Final Experiment Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.550871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.388927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.379858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.407457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.487889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.495305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.477943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.461417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.458394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.446847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.403910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.446615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.345241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.333752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.358587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.420439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.434524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.431680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.475963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.422849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fold            Algorithm  F1-Score (weighted)\n",
       "0      1  Logistic Regression             0.550871\n",
       "1      1              XGBoost             0.388927\n",
       "2      1             LightGBM             0.379858\n",
       "3      1             CatBoost             0.407457\n",
       "4      2  Logistic Regression             0.487889\n",
       "5      2              XGBoost             0.495305\n",
       "6      2             LightGBM             0.477943\n",
       "7      2             CatBoost             0.461417\n",
       "8      3  Logistic Regression             0.458394\n",
       "9      3              XGBoost             0.446847\n",
       "10     3             LightGBM             0.403910\n",
       "11     3             CatBoost             0.446615\n",
       "12     4  Logistic Regression             0.345241\n",
       "13     4              XGBoost             0.333752\n",
       "14     4             LightGBM             0.358587\n",
       "15     4             CatBoost             0.420439\n",
       "16     5  Logistic Regression             0.434524\n",
       "17     5              XGBoost             0.431680\n",
       "18     5             LightGBM             0.475963\n",
       "19     5             CatBoost             0.422849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.431755</td>\n",
       "      <td>0.021786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.419253</td>\n",
       "      <td>0.055064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.455384</td>\n",
       "      <td>0.075415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.419302</td>\n",
       "      <td>0.061094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm      mean       std\n",
       "0             CatBoost  0.431755  0.021786\n",
       "1             LightGBM  0.419253  0.055064\n",
       "2  Logistic Regression  0.455384  0.075415\n",
       "3              XGBoost  0.419302  0.061094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# English: Prepare data for modeling\n",
    "X = dataset.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "y = dataset['stress_level']\n",
    "groups = dataset['user_id']\n",
    "\n",
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "n_splits = 5  # Using 2 splits for a quick demonstration; recommend 5 for final results\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "results_list = []\n",
    "\n",
    "# English: Define the models to be tested in a dictionary\n",
    "models_to_test = {\n",
    "    # English: Logistic Regression needs scaled data, so we use a Pipeline\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=42, max_iter=1000, solver='liblinear'))\n",
    "    ]),\n",
    "    # English: The \"big three\" of gradient boosting\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=42, verbose=0, iterations=200)\n",
    "}\n",
    "\n",
    "# --- 3. CROSS-VALIDATION LOOP ---\n",
    "print(f\"--- Starting cross-validation with {n_splits} folds ---\")\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} ---\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # English: Iterate through each model defined above\n",
    "    for name, model in models_to_test.items():\n",
    "        print(f\"  - Training {name}...\")\n",
    "        \n",
    "        # English: Fit the model on the training data for the current fold\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # English: Make predictions on the test data\n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        # English: Calculate the weighted F1-score\n",
    "        f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        # English: Store the results\n",
    "        results_list.append({\n",
    "            'Fold': fold + 1,\n",
    "            'Algorithm': name,\n",
    "            'F1-Score (weighted)': f1\n",
    "        })\n",
    "        print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "# --- 4. RESULTS PRESENTATION ---\n",
    "print(\"\\n--- Final Experiment Results ---\")\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n--- Average Performance Summary ---\")\n",
    "summary = results_df.groupby('Algorithm')['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      "--- Starting Experiment for Window Size: 3 ---\n",
      "========================================================\n",
      "\n",
      "--- Processing Fold 1/5 for window 3 ---\n",
      "  - Training gplearn...\n",
      "  - gplearn F1-Score: 0.1667\n",
      "  - Training PySR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28112/3629998003.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mpysr_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpysr_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             all_results_list.append({'Window Size': window_size, 'Fold': fold + 1, 'Algorithm': 'PySR',\n\u001b[1;32m     81\u001b[0m                                      \u001b[0;34m'F1-Score (weighted)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpysr_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                      'Best Formula': pysr_model.get_best()[\"equation\"] if pysr_model.get_best() else \"No formula found\"})\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - PySR F1-Score: {pysr_f1:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# --- 4. FINAL RESULTS PRESENTATION ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "window_sizes = [3, 4, 5]\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# English: This is the main list to collect results from ALL experiments\n",
    "all_results_list = []\n",
    "\n",
    "# --- 3. MAIN EXPERIMENT LOOP ---\n",
    "for window_size in window_sizes:\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"--- Starting Experiment for Window Size: {window_size} ---\")\n",
    "    print(f\"========================================================\")\n",
    "    \n",
    "    try:\n",
    "        # English: Load the dataset for the current window size\n",
    "        # NOTE: You must have these files in the specified path\n",
    "        # dataset = pd.read_csv(f'../data/augmented/studentlife_2014_{window_size}.csv')\n",
    "        \n",
    "\n",
    "        dataset = pd.read_csv(f'../data/augmented/studentlife_2014_{window_size}.csv')\n",
    "        # --- End of placeholder block ---\n",
    "\n",
    "        dataset.dropna(inplace=True)\n",
    "\n",
    "        # English: Prepare data for modeling\n",
    "        X = dataset.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "        y = dataset['stress_level']\n",
    "        groups = dataset['user_id']\n",
    "        min_class, max_class = y.min(), y.max()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file for window size {window_size} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Cross-validation loop for the current dataset ---\n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} for window {window_size} ---\")\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # --- Experiment A: gplearn ---\n",
    "        if True:\n",
    "            print(\"  - Training gplearn...\")\n",
    "            gp_model = SymbolicRegressor(population_size=1000, generations=10, \n",
    "                                       parsimony_coefficient=0.001, random_state=42, verbose=0)\n",
    "            gp_model.fit(X_train, y_train)\n",
    "            \n",
    "            raw_gp_preds = gp_model.predict(X_test)\n",
    "            rounded_gp_preds = np.round(raw_gp_preds)\n",
    "            gp_preds = np.clip(rounded_gp_preds, min_class, max_class).astype(int)\n",
    "            gp_f1 = f1_score(y_test, gp_preds, average='weighted', zero_division=0)\n",
    "            \n",
    "            all_results_list.append({'Window Size': window_size, 'Fold': fold + 1, 'Algorithm': 'gplearn', \n",
    "                                     'F1-Score (weighted)': gp_f1, 'Best Formula': str(gp_model._program)})\n",
    "            print(f\"  - gplearn F1-Score: {gp_f1:.4f}\")\n",
    "\n",
    "        # --- Experiment B: PySR ---\n",
    "        if True:\n",
    "            print(\"  - Training PySR...\")\n",
    "            pysr_model = PySRRegressor(niterations=10, binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n",
    "                                       model_selection=\"best\", procs=0, verbosity=0)\n",
    "            pysr_model.fit(X_train, y_train)\n",
    "            \n",
    "            raw_pysr_preds = pysr_model.predict(X_test)\n",
    "            rounded_pysr_preds = np.round(raw_pysr_preds)\n",
    "            pysr_preds = np.clip(rounded_pysr_preds, min_class, max_class).astype(int)\n",
    "            pysr_f1 = f1_score(y_test, pysr_preds, average='weighted', zero_division=0)\n",
    "            \n",
    "            all_results_list.append({'Window Size': window_size, 'Fold': fold + 1, 'Algorithm': 'PySR',\n",
    "                                     'F1-Score (weighted)': pysr_f1, \n",
    "                                     'Best Formula': pysr_model.get_best()[\"equation\"] if pysr_model.get_best() else \"No formula found\"})\n",
    "            print(f\"  - PySR F1-Score: {pysr_f1:.4f}\")\n",
    "\n",
    "# --- 4. FINAL RESULTS PRESENTATION ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Final Combined Experiment Results ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "if not all_results_list:\n",
    "    print(\"No results were generated. Please check data paths and library installations.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    \n",
    "    # English: Display the full results table\n",
    "    print(\"\\n--- Full Results Table ---\")\n",
    "    display(results_df)\n",
    "\n",
    "    # English: Display the summary table\n",
    "    print(\"\\n--- Average Performance Summary ---\")\n",
    "    summary = results_df.groupby(['Window Size', 'Algorithm'])['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      "--- Starting Experiment for Window Size: 3 ---\n",
      "========================================================\n",
      "\n",
      "--- Processing Fold 1/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4639\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:19:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.3838\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4006\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3884\n",
      "\n",
      "--- Processing Fold 2/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3906\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:19:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.5291\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4909\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.5376\n",
      "\n",
      "--- Processing Fold 3/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4723\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.4824\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5351\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.5474\n",
      "\n",
      "--- Processing Fold 4/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4176\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.3521\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3604\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3797\n",
      "\n",
      "--- Processing Fold 5/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3676\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.5325\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4970\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4717\n",
      "\n",
      "========================================================\n",
      "--- Starting Experiment for Window Size: 4 ---\n",
      "========================================================\n",
      "\n",
      "--- Processing Fold 1/5 for window 4 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4234\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.4539\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4006\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4069\n",
      "\n",
      "--- Processing Fold 2/5 for window 4 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4287\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.5611\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5186\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4576\n",
      "\n",
      "--- Processing Fold 3/5 for window 4 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3790\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.5442\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4966\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4439\n",
      "\n",
      "--- Processing Fold 4/5 for window 4 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3994\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.4520\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3701\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4104\n",
      "\n",
      "--- Processing Fold 5/5 for window 4 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3358\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:20:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.4445\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4603\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4062\n",
      "\n",
      "========================================================\n",
      "--- Starting Experiment for Window Size: 5 ---\n",
      "========================================================\n",
      "\n",
      "--- Processing Fold 1/5 for window 5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3747\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:21:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.3775\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3556\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4397\n",
      "\n",
      "--- Processing Fold 2/5 for window 5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4190\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:21:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.5625\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5589\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.5623\n",
      "\n",
      "--- Processing Fold 3/5 for window 5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3855\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:21:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.3861\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4268\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4548\n",
      "\n",
      "--- Processing Fold 4/5 for window 5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3469\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:21:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.4858\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3955\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4222\n",
      "\n",
      "--- Processing Fold 5/5 for window 5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3554\n",
      "  - Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:21:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XGBoost F1-Score: 0.4145\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3956\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4219\n",
      "\n",
      "\n",
      "================================================\n",
      "--- Final Combined Experiment Results ---\n",
      "================================================\n",
      "\n",
      "--- Full Results Table ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.463857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.383822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.400554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.388420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.390570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.529074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.537644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.472312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.482445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.535081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.547447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.417626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.352082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.360442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.379717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.367598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.532492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.497006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.471657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.423385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.453930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.400635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.406854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.428726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.561107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.518565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.457623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.379044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.544154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.496557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.443894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.399398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.452007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.370092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.410416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.335841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.444532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.460271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.406210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.374671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.377496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.355645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.439749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.419005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.562458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.558926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.562279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.385491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.386140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.426764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.454781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.346912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.485824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.395485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.422179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.355432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.414474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.395649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.421868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Window Size  Fold            Algorithm  F1-Score (weighted)\n",
       "0             3     1  Logistic Regression             0.463857\n",
       "1             3     1              XGBoost             0.383822\n",
       "2             3     1             LightGBM             0.400554\n",
       "3             3     1             CatBoost             0.388420\n",
       "4             3     2  Logistic Regression             0.390570\n",
       "5             3     2              XGBoost             0.529074\n",
       "6             3     2             LightGBM             0.490909\n",
       "7             3     2             CatBoost             0.537644\n",
       "8             3     3  Logistic Regression             0.472312\n",
       "9             3     3              XGBoost             0.482445\n",
       "10            3     3             LightGBM             0.535081\n",
       "11            3     3             CatBoost             0.547447\n",
       "12            3     4  Logistic Regression             0.417626\n",
       "13            3     4              XGBoost             0.352082\n",
       "14            3     4             LightGBM             0.360442\n",
       "15            3     4             CatBoost             0.379717\n",
       "16            3     5  Logistic Regression             0.367598\n",
       "17            3     5              XGBoost             0.532492\n",
       "18            3     5             LightGBM             0.497006\n",
       "19            3     5             CatBoost             0.471657\n",
       "20            4     1  Logistic Regression             0.423385\n",
       "21            4     1              XGBoost             0.453930\n",
       "22            4     1             LightGBM             0.400635\n",
       "23            4     1             CatBoost             0.406854\n",
       "24            4     2  Logistic Regression             0.428726\n",
       "25            4     2              XGBoost             0.561107\n",
       "26            4     2             LightGBM             0.518565\n",
       "27            4     2             CatBoost             0.457623\n",
       "28            4     3  Logistic Regression             0.379044\n",
       "29            4     3              XGBoost             0.544154\n",
       "30            4     3             LightGBM             0.496557\n",
       "31            4     3             CatBoost             0.443894\n",
       "32            4     4  Logistic Regression             0.399398\n",
       "33            4     4              XGBoost             0.452007\n",
       "34            4     4             LightGBM             0.370092\n",
       "35            4     4             CatBoost             0.410416\n",
       "36            4     5  Logistic Regression             0.335841\n",
       "37            4     5              XGBoost             0.444532\n",
       "38            4     5             LightGBM             0.460271\n",
       "39            4     5             CatBoost             0.406210\n",
       "40            5     1  Logistic Regression             0.374671\n",
       "41            5     1              XGBoost             0.377496\n",
       "42            5     1             LightGBM             0.355645\n",
       "43            5     1             CatBoost             0.439749\n",
       "44            5     2  Logistic Regression             0.419005\n",
       "45            5     2              XGBoost             0.562458\n",
       "46            5     2             LightGBM             0.558926\n",
       "47            5     2             CatBoost             0.562279\n",
       "48            5     3  Logistic Regression             0.385491\n",
       "49            5     3              XGBoost             0.386140\n",
       "50            5     3             LightGBM             0.426764\n",
       "51            5     3             CatBoost             0.454781\n",
       "52            5     4  Logistic Regression             0.346912\n",
       "53            5     4              XGBoost             0.485824\n",
       "54            5     4             LightGBM             0.395485\n",
       "55            5     4             CatBoost             0.422179\n",
       "56            5     5  Logistic Regression             0.355432\n",
       "57            5     5              XGBoost             0.414474\n",
       "58            5     5             LightGBM             0.395649\n",
       "59            5     5             CatBoost             0.421868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.464977</td>\n",
       "      <td>0.079462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.456799</td>\n",
       "      <td>0.073069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.422393</td>\n",
       "      <td>0.045412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.455983</td>\n",
       "      <td>0.083514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.024064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.449224</td>\n",
       "      <td>0.062836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.393279</td>\n",
       "      <td>0.037756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.491146</td>\n",
       "      <td>0.056556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.460171</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.426494</td>\n",
       "      <td>0.078216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.376302</td>\n",
       "      <td>0.028328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.445278</td>\n",
       "      <td>0.078128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Window Size            Algorithm      mean       std\n",
       "0             3             CatBoost  0.464977  0.079462\n",
       "1             3             LightGBM  0.456799  0.073069\n",
       "2             3  Logistic Regression  0.422393  0.045412\n",
       "3             3              XGBoost  0.455983  0.083514\n",
       "4             4             CatBoost  0.425000  0.024064\n",
       "5             4             LightGBM  0.449224  0.062836\n",
       "6             4  Logistic Regression  0.393279  0.037756\n",
       "7             4              XGBoost  0.491146  0.056556\n",
       "8             5             CatBoost  0.460171  0.058700\n",
       "9             5             LightGBM  0.426494  0.078216\n",
       "10            5  Logistic Regression  0.376302  0.028328\n",
       "11            5              XGBoost  0.445278  0.078128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# English: This script assumes you have already run the necessary import statements\n",
    "# for pandas, numpy, GroupKFold, f1_score, and all the required models.\n",
    "\n",
    "# --- 1. EXPERIMENT CONFIGURATION ---\n",
    "window_sizes = [3, 4, 5]\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# English: This is the main list to collect results from ALL experiments\n",
    "all_results_list = []\n",
    "\n",
    "# English: Define the models to be tested in a dictionary (outside the loop)\n",
    "models_to_test = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=42, max_iter=100000, solver='liblinear'))\n",
    "    ]),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, verbose=-1),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=42, verbose=0, iterations=200)\n",
    "}\n",
    "\n",
    "# --- 2. MAIN EXPERIMENT LOOP ---\n",
    "for window_size in window_sizes:\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"--- Starting Experiment for Window Size: {window_size} ---\")\n",
    "    print(f\"========================================================\")\n",
    "    \n",
    "    try:\n",
    "        # English: Load the dataset for the current window size\n",
    "        # NOTE: You must have these files in the specified path\n",
    "        # dataset = pd.read_csv(f'../data/augmented/studentlife_2014_{window_size}.csv')\n",
    "        \n",
    "        # --- This is a placeholder for your data loading. Remove for production. ---\n",
    "        # Creating a dummy dataframe for demonstration purposes as I can't access local files.\n",
    "        # Replace this block with your pd.read_csv line.\n",
    "        dataset = pd.read_csv(f'../data/augmented/studentlife_2014_{window_size}.csv')\n",
    "        # --- End of placeholder block ---\n",
    "\n",
    "        dataset.dropna(inplace=True)\n",
    "\n",
    "        # English: Prepare data for modeling\n",
    "        X = dataset.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "        y = dataset['stress_level']\n",
    "        groups = dataset['user_id']\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file for window size {window_size} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Cross-validation loop for the current dataset ---\n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} for window {window_size} ---\")\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # English: Iterate through each model defined above\n",
    "        for name, model in models_to_test.items():\n",
    "            print(f\"  - Training {name}...\")\n",
    "            \n",
    "            # English: Fit the model on the training data for the current fold\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # English: Make predictions on the test data\n",
    "            preds = model.predict(X_test)\n",
    "            \n",
    "            # English: Calculate the weighted F1-score\n",
    "            f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "            \n",
    "            # English: Store the results, including the window size\n",
    "            all_results_list.append({\n",
    "                'Window Size': window_size,\n",
    "                'Fold': fold + 1,\n",
    "                'Algorithm': name,\n",
    "                'F1-Score (weighted)': f1\n",
    "            })\n",
    "            print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "# --- 3. FINAL RESULTS PRESENTATION ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Final Combined Experiment Results ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "if not all_results_list:\n",
    "    print(\"No results were generated. Please check data paths.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    \n",
    "    # English: Display the full results table\n",
    "    print(\"\\n--- Full Results Table ---\")\n",
    "    display(results_df)\n",
    "\n",
    "    # English: Display the summary table, grouped by window size and algorithm\n",
    "    print(\"\\n--- Average Performance Summary ---\")\n",
    "    summary = results_df.groupby(['Window Size', 'Algorithm'])['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "    display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing data for window size: 3 ---\n",
      "Data loaded successfully.\n",
      "\n",
      "========================================================\n",
      "--- Starting Exhaustive GridSearchCV for XGBoost ---\n",
      "========================================================\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 87\u001b[0m\n\u001b[1;32m     76\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     77\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m     78\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m   \u001b[38;5;66;03m# Show detailed progress updates\u001b[39;00m\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# English: Run the grid search. This is the time-consuming part.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# The 'groups' parameter is passed to the splitter within GridSearchCV.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# English: Store the best results found by the search\u001b[39;00m\n\u001b[1;32m     90\u001b[0m all_results_list\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest F1-Score (weighted)\u001b[39m\u001b[38;5;124m'\u001b[39m: grid_search\u001b[38;5;241m.\u001b[39mbest_score_,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Parameters\u001b[39m\u001b[38;5;124m'\u001b[39m: grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     94\u001b[0m })\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:52] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:29:53] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:11] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:17] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:49] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:50] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:51] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:57] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:30:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:12] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:33] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sergio/.virtualenvs/context-stress/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [17:31:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.8; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.8; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.8; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.8; total time=  17.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.9; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.8; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.9; total time=  17.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.9; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.9; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=0.9; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=1.0; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=1.0; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=1.0; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=1.0; total time=  17.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=750, subsample=1.0; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=  13.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  13.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=  27.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=  29.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=  29.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=  28.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=  28.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.9; total time=  27.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.9; total time=  29.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.9; total time=  30.4s\n"
     ]
    }
   ],
   "source": [
    "# English: Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- 2. DATA LOADING & PREPARATION ---\n",
    "window_size = 3\n",
    "print(f\"--- Loading and preparing data for window size: {window_size} ---\")\n",
    "\n",
    "try:\n",
    "    # English: Load the specific dataset for the experiment\n",
    "    dataset = pd.read_csv(f'../data/augmented/studentlife_2014_{window_size}.csv')\n",
    "    dataset.dropna(inplace=True)\n",
    "\n",
    "    # English: Prepare data for modeling\n",
    "    X = dataset.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "    y = dataset['stress_level']\n",
    "    groups = dataset['user_id']\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file for window size {window_size} not found. Please check the path.\")\n",
    "    # Stop execution if data is not found\n",
    "    # In a real script, you might exit or raise an error here.\n",
    "    # For this example, we'll create dummy data to proceed.\n",
    "    print(\"Creating dummy data to continue demonstration...\")\n",
    "    num_samples = 150\n",
    "    X = pd.DataFrame(np.random.rand(num_samples, 20), columns=[f'feature_{i}' for i in range(20)])\n",
    "    y = pd.Series(np.random.randint(0, 3, num_samples))\n",
    "    groups = pd.Series(np.repeat(np.arange(10), num_samples // 10))\n",
    "\n",
    "# --- 3. EXPERIMENT CONFIGURATION ---\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# English: Define the models and their exhaustive parameter grids for GridSearchCV\n",
    "models_to_tune = [\n",
    "    {\n",
    "        \"name\": \"XGBoost\",\n",
    "        \"estimator\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        \"param_grid\": {\n",
    "            'n_estimators': [200, 500, 750],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "            'gamma': [0, 0.1, 0.5]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CatBoost\",\n",
    "        \"estimator\": CatBoostClassifier(random_state=42, verbose=0),\n",
    "        \"param_grid\": {\n",
    "            'iterations': [250, 500, 750],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'depth': [4, 6, 8],\n",
    "            'l2_leaf_reg': [1, 3, 5],\n",
    "            'border_count': [32, 64, 128]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# English: This list will store the final results of the grid searches\n",
    "all_results_list = []\n",
    "\n",
    "# --- 4. GRID SEARCH EXECUTION LOOP ---\n",
    "for config in models_to_tune:\n",
    "    model_name = config[\"name\"]\n",
    "    estimator = config[\"estimator\"]\n",
    "    param_grid = config[\"param_grid\"]\n",
    "    \n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"--- Starting Exhaustive GridSearchCV for {model_name} ---\")\n",
    "    print(f\"========================================================\")\n",
    "    \n",
    "    # English: Set up GridSearchCV\n",
    "    # It uses GroupKFold for the cross-validation strategy to respect user groups.\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1_weighted',\n",
    "        cv=gkf,\n",
    "        n_jobs=-1,  # Use all available CPU cores to speed up the process\n",
    "        verbose=2   # Show detailed progress updates\n",
    "    )\n",
    "    \n",
    "    # English: Run the grid search. This is the time-consuming part.\n",
    "    # The 'groups' parameter is passed to the splitter within GridSearchCV.\n",
    "    grid_search.fit(X, y, groups=groups)\n",
    "    \n",
    "    # English: Store the best results found by the search\n",
    "    all_results_list.append({\n",
    "        'Algorithm': model_name,\n",
    "        'Best F1-Score (weighted)': grid_search.best_score_,\n",
    "        'Best Parameters': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "# --- 5. FINAL RESULTS PRESENTATION ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Final GridSearchCV Results ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "if not all_results_list:\n",
    "    print(\"No results were generated. Please check the experiment setup.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    \n",
    "    # English: Display the summary table\n",
    "    # We use a custom print for better display of the 'Best Parameters' dictionary\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(f\"Algorithm: {row['Algorithm']}\")\n",
    "        print(f\"  - Best F1-Score (avg): {row['Best F1-Score (weighted)']:.4f}\")\n",
    "        print(f\"  - Best Hyperparameters: {row['Best Parameters']}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    results_df.to_csv('results/results_ws3_gscv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'date', 'stress_level', 'environmental_temperature_mean',\n",
       "       'environmental_temperature_max', 'environmental_temperature_min',\n",
       "       'environmental_humidity_mean', 'environmental_humidity_max',\n",
       "       'environmental_humidity_min', 'environmental_precipitation',\n",
       "       'environmental_cloudcover', 'individual_sleep_duration',\n",
       "       'individual_sleep_rate', 'organizational_social_interaction',\n",
       "       'organizational_social_voice_sum', 'organizational_social_voice_count',\n",
       "       'organizational_social_voice_mean', 'organizational_social_voice_max',\n",
       "       'individual_minutes_stationary', 'individual_minutes_walking',\n",
       "       'individual_minutes_running', 'individual_minutes_unknown',\n",
       "       'environmental_minutes_silence', 'environmental_minutes_voice',\n",
       "       'environmental_minutes_noise', 'environmental_minutes_unknown',\n",
       "       'organizational_work_hours', 'deadlines', 'days_until_next_deadline',\n",
       "       'weekday', 'individual_personality_extraversion',\n",
       "       'individual_personality_agreeableness',\n",
       "       'individual_personality_conscientiousness',\n",
       "       'individual_personality_neuroticism', 'individual_personality_openness',\n",
       "       'individual_flourishing_score', 'individual_loneliness_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    'deadlines': 'organizational_deadlines',\n",
    "    'days_until_next_deadline': 'organizational_days_until_next_deadline',\n",
    "    'weekday': 'environmental_weekday'\n",
    "}\n",
    "\n",
    "dataset = dataset.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_for_columns(df, feature_columns, window_size, feature_function):\n",
    "    \"\"\"\n",
    "    Applies a feature generation function to a list of specified columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe.\n",
    "    feature_columns : list\n",
    "        A list of column names to generate features for.\n",
    "    window_size : int\n",
    "        The rolling window size to use.\n",
    "    feature_function : function\n",
    "        The function to apply (e.g., add_stress_rolling_features).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The dataframe enriched with all the new features.\n",
    "    \"\"\"\n",
    "    df_enriched = df.copy()\n",
    "    \n",
    "    # Track original columns to avoid creating features on features\n",
    "    original_cols = set(df_enriched.columns)\n",
    "    \n",
    "    for col in feature_columns:\n",
    "        if col in original_cols:\n",
    "            print(f\"Generating features for column: '{col}' with window size {window_size}...\")\n",
    "            df_enriched = feature_function(df_enriched, window_size, col)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in the initial dataframe. Skipping.\")\n",
    "            \n",
    "    print(\"\\nFeature generation complete.\")\n",
    "    return df_enriched\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>environmental_cloudcover</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level_rolling_q75_3d</th>\n",
       "      <th>stress_level_rolling_range_3d</th>\n",
       "      <th>stress_level_rolling_iqr_3d</th>\n",
       "      <th>stress_level_rolling_cv_3d</th>\n",
       "      <th>stress_level_rolling_trend_slope_3d</th>\n",
       "      <th>stress_level_rolling_direction_changes_3d</th>\n",
       "      <th>stress_level_rolling_entropy_3d</th>\n",
       "      <th>stress_level_rolling_zscore_3d</th>\n",
       "      <th>stress_level_rolling_time_since_peak_3d</th>\n",
       "      <th>stress_level_rolling_time_since_trough_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>647.0</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.620370</td>\n",
       "      <td>1.154321</td>\n",
       "      <td>8.512854</td>\n",
       "      <td>14.699537</td>\n",
       "      <td>3.327778</td>\n",
       "      <td>68.407986</td>\n",
       "      <td>88.521605</td>\n",
       "      <td>43.833333</td>\n",
       "      <td>2.281636</td>\n",
       "      <td>48.630980</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268934</td>\n",
       "      <td>0.476043</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.442335</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418856</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.744977</td>\n",
       "      <td>0.765070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.982157</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>5.562435</td>\n",
       "      <td>6.753744</td>\n",
       "      <td>4.765486</td>\n",
       "      <td>12.982973</td>\n",
       "      <td>12.694466</td>\n",
       "      <td>13.079710</td>\n",
       "      <td>3.664127</td>\n",
       "      <td>31.175947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625293</td>\n",
       "      <td>0.603625</td>\n",
       "      <td>0.301813</td>\n",
       "      <td>0.581263</td>\n",
       "      <td>0.798468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493753</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.436211</td>\n",
       "      <td>0.424283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.525000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.100000</td>\n",
       "      <td>44.291667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.854167</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.454167</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>67.791667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>39.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>78.958333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>77.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stress_level  environmental_temperature_mean  \\\n",
       "count  648.000000    648.000000                      648.000000   \n",
       "mean    33.620370      1.154321                        8.512854   \n",
       "std     17.982157      0.742368                        5.562435   \n",
       "min      4.000000      0.000000                       -1.525000   \n",
       "25%     17.000000      1.000000                        3.854167   \n",
       "50%     33.000000      1.000000                        7.454167   \n",
       "75%     51.000000      2.000000                       13.508333   \n",
       "max     59.000000      2.000000                       18.450000   \n",
       "\n",
       "       environmental_temperature_max  environmental_temperature_min  \\\n",
       "count                     648.000000                     648.000000   \n",
       "mean                       14.699537                       3.327778   \n",
       "std                         6.753744                       4.765486   \n",
       "min                         1.000000                      -6.100000   \n",
       "25%                         9.000000                      -0.600000   \n",
       "50%                        14.100000                       2.800000   \n",
       "75%                        20.500000                       6.800000   \n",
       "max                        26.400000                      13.900000   \n",
       "\n",
       "       environmental_humidity_mean  environmental_humidity_max  \\\n",
       "count                   648.000000                  648.000000   \n",
       "mean                     68.407986                   88.521605   \n",
       "std                      12.982973                   12.694466   \n",
       "min                      44.291667                   53.000000   \n",
       "25%                      58.750000                   80.000000   \n",
       "50%                      67.791667                   94.000000   \n",
       "75%                      78.958333                   99.000000   \n",
       "max                      94.250000                  100.000000   \n",
       "\n",
       "       environmental_humidity_min  environmental_precipitation  \\\n",
       "count                  648.000000                   648.000000   \n",
       "mean                    43.833333                     2.281636   \n",
       "std                     13.079710                     3.664127   \n",
       "min                     19.000000                     0.000000   \n",
       "25%                     35.000000                     0.000000   \n",
       "50%                     40.000000                     0.100000   \n",
       "75%                     54.000000                     2.300000   \n",
       "max                     84.000000                    15.000000   \n",
       "\n",
       "       environmental_cloudcover  ...  stress_level_rolling_q75_3d  \\\n",
       "count                648.000000  ...                   647.000000   \n",
       "mean                  48.630980  ...                     1.268934   \n",
       "std                   31.175947  ...                     0.625293   \n",
       "min                    0.041667  ...                     0.000000   \n",
       "25%                   27.250000  ...                     0.750000   \n",
       "50%                   39.083333  ...                     1.000000   \n",
       "75%                   77.375000  ...                     1.750000   \n",
       "max                   99.916667  ...                     2.000000   \n",
       "\n",
       "       stress_level_rolling_range_3d  stress_level_rolling_iqr_3d  \\\n",
       "count                     647.000000                   647.000000   \n",
       "mean                        0.476043                     0.238022   \n",
       "std                         0.603625                     0.301813   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         0.000000                     0.000000   \n",
       "50%                         0.000000                     0.000000   \n",
       "75%                         1.000000                     0.500000   \n",
       "max                         2.000000                     1.000000   \n",
       "\n",
       "       stress_level_rolling_cv_3d  stress_level_rolling_trend_slope_3d  \\\n",
       "count                  600.000000                           600.000000   \n",
       "mean                     0.442335                             0.013333   \n",
       "std                      0.581263                             0.798468   \n",
       "min                      0.000000                            -2.000000   \n",
       "25%                      0.000000                             0.000000   \n",
       "50%                      0.000000                             0.000000   \n",
       "75%                      0.471405                             0.000000   \n",
       "max                      1.414214                             2.000000   \n",
       "\n",
       "       stress_level_rolling_direction_changes_3d  \\\n",
       "count                                      647.0   \n",
       "mean                                         0.0   \n",
       "std                                          0.0   \n",
       "min                                          0.0   \n",
       "25%                                          0.0   \n",
       "50%                                          0.0   \n",
       "75%                                          0.0   \n",
       "max                                          0.0   \n",
       "\n",
       "       stress_level_rolling_entropy_3d  stress_level_rolling_zscore_3d  \\\n",
       "count                       647.000000                      600.000000   \n",
       "mean                          0.418856                        0.015321   \n",
       "std                           0.493753                        0.475369   \n",
       "min                           0.000000                       -0.707107   \n",
       "25%                           0.000000                        0.000000   \n",
       "50%                           0.000000                        0.000000   \n",
       "75%                           1.000000                        0.000000   \n",
       "max                           1.000000                        0.707107   \n",
       "\n",
       "       stress_level_rolling_time_since_peak_3d  \\\n",
       "count                               647.000000   \n",
       "mean                                  0.744977   \n",
       "std                                   0.436211   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                   1.000000   \n",
       "75%                                   1.000000   \n",
       "max                                   1.000000   \n",
       "\n",
       "       stress_level_rolling_time_since_trough_3d  \n",
       "count                                 647.000000  \n",
       "mean                                    0.765070  \n",
       "std                                     0.424283  \n",
       "min                                     0.000000  \n",
       "25%                                     1.000000  \n",
       "50%                                     1.000000  \n",
       "75%                                     1.000000  \n",
       "max                                     1.000000  \n",
       "\n",
       "[8 rows x 468 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18 columns with zero or single unique values: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d']\n",
      "List of dropped columns: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d', 'environmental_temperature_mean_rolling_median_3d', 'environmental_temperature_mean_rolling_q25_3d', 'environmental_temperature_mean_rolling_q75_3d', 'environmental_temperature_mean_rolling_range_3d', 'environmental_temperature_mean_rolling_iqr_3d', 'environmental_temperature_max_rolling_mean_3d', 'environmental_temperature_max_rolling_q25_3d', 'environmental_temperature_max_rolling_q75_3d', 'environmental_temperature_max_rolling_range_3d', 'environmental_temperature_max_rolling_iqr_3d', 'environmental_temperature_min_rolling_q25_3d', 'environmental_temperature_min_rolling_q75_3d', 'environmental_temperature_min_rolling_range_3d', 'environmental_temperature_min_rolling_iqr_3d', 'environmental_humidity_mean_rolling_range_3d', 'environmental_humidity_mean_rolling_iqr_3d', 'environmental_humidity_max_rolling_range_3d', 'environmental_humidity_max_rolling_iqr_3d', 'environmental_humidity_max_rolling_cv_3d', 'environmental_humidity_min_rolling_range_3d', 'environmental_humidity_min_rolling_iqr_3d', 'environmental_precipitation_rolling_q75_3d', 'environmental_precipitation_rolling_range_3d', 'environmental_precipitation_rolling_iqr_3d', 'environmental_cloudcover_rolling_range_3d', 'environmental_cloudcover_rolling_iqr_3d', 'individual_sleep_duration_rolling_range_3d', 'individual_sleep_duration_rolling_iqr_3d', 'individual_sleep_rate_rolling_range_3d', 'individual_sleep_rate_rolling_iqr_3d', 'organizational_social_interaction_rolling_q25_3d', 'organizational_social_interaction_rolling_q75_3d', 'organizational_social_interaction_rolling_range_3d', 'organizational_social_interaction_rolling_iqr_3d', 'organizational_social_voice_sum_rolling_q75_3d', 'organizational_social_voice_sum_rolling_range_3d', 'organizational_social_voice_sum_rolling_iqr_3d', 'organizational_social_voice_count_rolling_range_3d', 'organizational_social_voice_count_rolling_iqr_3d', 'organizational_social_voice_mean_rolling_q75_3d', 'organizational_social_voice_mean_rolling_range_3d', 'organizational_social_voice_mean_rolling_iqr_3d', 'organizational_social_voice_max_rolling_range_3d', 'organizational_social_voice_max_rolling_iqr_3d', 'individual_minutes_stationary_rolling_q25_3d', 'individual_minutes_stationary_rolling_range_3d', 'individual_minutes_stationary_rolling_iqr_3d', 'individual_minutes_walking_rolling_q75_3d', 'individual_minutes_walking_rolling_range_3d', 'individual_minutes_walking_rolling_iqr_3d', 'individual_minutes_running_rolling_q75_3d', 'individual_minutes_running_rolling_range_3d', 'individual_minutes_running_rolling_iqr_3d', 'individual_minutes_unknown_rolling_q75_3d', 'individual_minutes_unknown_rolling_range_3d', 'individual_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_silence_rolling_range_3d', 'environmental_minutes_silence_rolling_iqr_3d', 'environmental_minutes_voice_rolling_range_3d', 'environmental_minutes_voice_rolling_iqr_3d', 'environmental_minutes_noise_rolling_q75_3d', 'environmental_minutes_noise_rolling_range_3d', 'environmental_minutes_noise_rolling_iqr_3d', 'organizational_work_hours_rolling_range_3d', 'organizational_work_hours_rolling_iqr_3d', 'organizational_deadlines_rolling_q75_3d', 'organizational_deadlines_rolling_range_3d', 'organizational_deadlines_rolling_iqr_3d', 'organizational_days_until_next_deadline_rolling_q75_3d', 'organizational_days_until_next_deadline_rolling_range_3d', 'organizational_days_until_next_deadline_rolling_iqr_3d', 'stress_level_rolling_median_3d', 'stress_level_rolling_q25_3d', 'stress_level_rolling_range_3d', 'stress_level_rolling_iqr_3d']\n",
      "--- STAGE 1: Finding the globally optimal set of features with RFECV ---\n",
      "\n",
      "--- Running RFECV for domain: environmental (155 features) ---\n",
      "Selected 2 features for environmental: ['environmental_minutes_voice_rolling_min_3d', 'environmental_minutes_voice_rolling_max_3d']\n",
      "\n",
      "--- Running RFECV for domain: individual (93 features) ---\n",
      "Selected 36 features for individual: ['individual_sleep_rate', 'individual_minutes_unknown', 'individual_personality_extraversion', 'individual_personality_agreeableness', 'individual_personality_conscientiousness', 'individual_personality_neuroticism', 'individual_personality_openness', 'individual_sleep_duration_rolling_mean_3d', 'individual_sleep_duration_rolling_std_3d', 'individual_sleep_duration_rolling_min_3d', 'individual_sleep_duration_rolling_trend_slope_3d', 'individual_sleep_duration_rolling_entropy_3d', 'individual_sleep_duration_rolling_zscore_3d', 'individual_sleep_rate_rolling_mean_3d', 'individual_sleep_rate_rolling_cv_3d', 'individual_sleep_rate_rolling_entropy_3d', 'individual_sleep_rate_rolling_zscore_3d', 'individual_minutes_stationary_rolling_mean_3d', 'individual_minutes_stationary_rolling_median_3d', 'individual_minutes_stationary_rolling_q75_3d', 'individual_minutes_walking_rolling_mean_3d', 'individual_minutes_walking_rolling_min_3d', 'individual_minutes_walking_rolling_q25_3d', 'individual_minutes_walking_rolling_cv_3d', 'individual_minutes_walking_rolling_trend_slope_3d', 'individual_minutes_running_rolling_mean_3d', 'individual_minutes_running_rolling_cv_3d', 'individual_minutes_running_rolling_zscore_3d', 'individual_minutes_unknown_rolling_mean_3d', 'individual_minutes_unknown_rolling_std_3d', 'individual_minutes_unknown_rolling_min_3d', 'individual_minutes_unknown_rolling_max_3d', 'individual_minutes_unknown_rolling_median_3d', 'individual_minutes_unknown_rolling_cv_3d', 'individual_minutes_unknown_rolling_zscore_3d', 'individual_minutes_unknown_rolling_time_since_trough_3d']\n",
      "\n",
      "--- Running RFECV for domain: organizational (114 features) ---\n",
      "Selected 30 features for organizational: ['organizational_social_voice_sum', 'organizational_social_voice_mean', 'organizational_days_until_next_deadline', 'organizational_social_interaction_rolling_mean_3d', 'organizational_social_interaction_rolling_min_3d', 'organizational_social_interaction_rolling_zscore_3d', 'organizational_social_voice_sum_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_min_3d', 'organizational_social_voice_count_rolling_median_3d', 'organizational_social_voice_count_rolling_entropy_3d', 'organizational_social_voice_count_rolling_zscore_3d', 'organizational_social_voice_mean_rolling_mean_3d', 'organizational_social_voice_mean_rolling_min_3d', 'organizational_social_voice_mean_rolling_max_3d', 'organizational_social_voice_mean_rolling_median_3d', 'organizational_social_voice_mean_rolling_cv_3d', 'organizational_social_voice_mean_rolling_trend_slope_3d', 'organizational_social_voice_mean_rolling_zscore_3d', 'organizational_social_voice_max_rolling_std_3d', 'organizational_social_voice_max_rolling_min_3d', 'organizational_social_voice_max_rolling_median_3d', 'organizational_social_voice_max_rolling_cv_3d', 'organizational_social_voice_max_rolling_zscore_3d', 'organizational_social_voice_max_rolling_time_since_peak_3d', 'organizational_work_hours_rolling_std_3d', 'organizational_work_hours_rolling_max_3d', 'organizational_deadlines_rolling_mean_3d', 'organizational_deadlines_rolling_std_3d', 'organizational_days_until_next_deadline_rolling_min_3d', 'organizational_days_until_next_deadline_rolling_trend_slope_3d']\n",
      "\n",
      "--- Running RFECV for domain: stress_history (11 features) ---\n",
      "Selected 2 features for stress_history: ['stress_level_rolling_mean_3d', 'stress_level_rolling_min_3d']\n",
      "\n",
      "--- Final combined set of 70 features ---\n",
      "['environmental_minutes_voice_rolling_min_3d', 'environmental_minutes_voice_rolling_max_3d', 'individual_sleep_rate', 'individual_minutes_unknown', 'individual_personality_extraversion', 'individual_personality_agreeableness', 'individual_personality_conscientiousness', 'individual_personality_neuroticism', 'individual_personality_openness', 'individual_sleep_duration_rolling_mean_3d', 'individual_sleep_duration_rolling_std_3d', 'individual_sleep_duration_rolling_min_3d', 'individual_sleep_duration_rolling_trend_slope_3d', 'individual_sleep_duration_rolling_entropy_3d', 'individual_sleep_duration_rolling_zscore_3d', 'individual_sleep_rate_rolling_mean_3d', 'individual_sleep_rate_rolling_cv_3d', 'individual_sleep_rate_rolling_entropy_3d', 'individual_sleep_rate_rolling_zscore_3d', 'individual_minutes_stationary_rolling_mean_3d', 'individual_minutes_stationary_rolling_median_3d', 'individual_minutes_stationary_rolling_q75_3d', 'individual_minutes_walking_rolling_mean_3d', 'individual_minutes_walking_rolling_min_3d', 'individual_minutes_walking_rolling_q25_3d', 'individual_minutes_walking_rolling_cv_3d', 'individual_minutes_walking_rolling_trend_slope_3d', 'individual_minutes_running_rolling_mean_3d', 'individual_minutes_running_rolling_cv_3d', 'individual_minutes_running_rolling_zscore_3d', 'individual_minutes_unknown_rolling_mean_3d', 'individual_minutes_unknown_rolling_std_3d', 'individual_minutes_unknown_rolling_min_3d', 'individual_minutes_unknown_rolling_max_3d', 'individual_minutes_unknown_rolling_median_3d', 'individual_minutes_unknown_rolling_cv_3d', 'individual_minutes_unknown_rolling_zscore_3d', 'individual_minutes_unknown_rolling_time_since_trough_3d', 'organizational_social_voice_sum', 'organizational_social_voice_mean', 'organizational_days_until_next_deadline', 'organizational_social_interaction_rolling_mean_3d', 'organizational_social_interaction_rolling_min_3d', 'organizational_social_interaction_rolling_zscore_3d', 'organizational_social_voice_sum_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_min_3d', 'organizational_social_voice_count_rolling_median_3d', 'organizational_social_voice_count_rolling_entropy_3d', 'organizational_social_voice_count_rolling_zscore_3d', 'organizational_social_voice_mean_rolling_mean_3d', 'organizational_social_voice_mean_rolling_min_3d', 'organizational_social_voice_mean_rolling_max_3d', 'organizational_social_voice_mean_rolling_median_3d', 'organizational_social_voice_mean_rolling_cv_3d', 'organizational_social_voice_mean_rolling_trend_slope_3d', 'organizational_social_voice_mean_rolling_zscore_3d', 'organizational_social_voice_max_rolling_std_3d', 'organizational_social_voice_max_rolling_min_3d', 'organizational_social_voice_max_rolling_median_3d', 'organizational_social_voice_max_rolling_cv_3d', 'organizational_social_voice_max_rolling_zscore_3d', 'organizational_social_voice_max_rolling_time_since_peak_3d', 'organizational_work_hours_rolling_std_3d', 'organizational_work_hours_rolling_max_3d', 'organizational_deadlines_rolling_mean_3d', 'organizational_deadlines_rolling_std_3d', 'organizational_days_until_next_deadline_rolling_min_3d', 'organizational_days_until_next_deadline_rolling_trend_slope_3d', 'stress_level_rolling_mean_3d', 'stress_level_rolling_min_3d']\n",
      "\n",
      "--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\n",
      "\n",
      "Best hyperparameters found: {'n_estimators': 200, 'learning_rate': 0.1484087283408702, 'max_depth': 10, 'subsample': 0.93331478524767, 'colsample_bytree': 0.7668736709223272, 'reg_alpha': 7.961374444864547e-05, 'reg_lambda': 3.8144514833385274e-08}\n",
      "\n",
      "--- STAGE 3: Final evaluation using 70 best features and optimal hyperparameters ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Fold Accuracy: 0.4400\n",
      "Fold F1-Score (Weighted): 0.4439\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Fold Accuracy: 0.4419\n",
      "Fold F1-Score (Weighted): 0.4247\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Fold Accuracy: 0.3816\n",
      "Fold F1-Score (Weighted): 0.4097\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Fold Accuracy: 0.4865\n",
      "Fold F1-Score (Weighted): 0.4617\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Fold Accuracy: 0.5000\n",
      "Fold F1-Score (Weighted): 0.4753\n",
      "\n",
      "--- Final Cross-Validation Results ---\n",
      "Mean Accuracy: 0.4500 ± 0.0417\n",
      "Mean F1-Score (Weighted): 0.4431 ± 0.0238\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24091993)\n",
    "\n",
    "# English: Suppress Optuna's trial logs for a cleaner output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# enriched_df = enriched_df[enriched_df['user_id'] != 59]# dataset.copy()\n",
    "\n",
    "# English: Filter out users who do not have all three stress classes\n",
    "#user_class_diversity = enriched_df.groupby('user_id')['stress_level'].nunique()\n",
    "#complete_users = user_class_diversity[user_class_diversity == 3].index\n",
    "#df_complete_stress = enriched_df[enriched_df['user_id'].isin(complete_users)].copy()\n",
    "\n",
    "# English: From the remaining users, select the top 20 by response count\n",
    "#user_counts_filtered = df_complete_stress['user_id'].value_counts()\n",
    "#num_top_users = min(20, len(user_counts_filtered))\n",
    "#top_users_from_complete = user_counts_filtered.head(num_top_users).index\n",
    "#df_final_selection = df_complete_stress[df_complete_stress['user_id'].isin(top_users_from_complete)].copy()\n",
    "\n",
    "# English: Now, handle NaNs and Infs\n",
    "enriched_df_filled = enriched_df.dropna()\n",
    "#enriched_df_filled.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_model = enriched_df_filled.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# English: Define X, Y, and groups for the entire process\n",
    "Y = df_model['stress_level']\n",
    "X = df_model.drop(columns=['stress_level', 'user_id', 'date'])\n",
    "\n",
    "correlation_threshold = 0.98\n",
    "\n",
    "# Apply the function\n",
    "X, dropped_columns = remove_highly_correlated_features(X, threshold=correlation_threshold)\n",
    "print(\"List of dropped columns:\", dropped_columns)\n",
    "\n",
    "groups = df_model['user_id']\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 1: GLOBAL FEATURE SELECTION WITH RFECV\n",
    "# ==============================================================================\n",
    "print(\"--- STAGE 1: Finding the globally optimal set of features with RFECV ---\")\n",
    "\n",
    "# English: Define your feature domains based on their prefixes\n",
    "# (Adjust these lists based on your actual column names)\n",
    "environmental_cols = [col for col in X.columns if 'environmental_' in col]\n",
    "individual_cols = [col for col in X.columns if 'individual_' in col]\n",
    "organizational_cols = [col for col in X.columns if 'organizational_' in col]\n",
    "stress_history_cols = [col for col in X.columns if 'stress_level_' in col] # Assuming lagged features start with this\n",
    "\n",
    "feature_domains = {\n",
    "    \"environmental\": environmental_cols,\n",
    "    \"individual\": individual_cols,\n",
    "    \"organizational\": organizational_cols,\n",
    "    \"stress_history\": stress_history_cols\n",
    "}\n",
    "\n",
    "best_features_per_domain = {}\n",
    "N_FEATURES_PER_DOMAIN = 1\n",
    "\n",
    "for domain, cols in feature_domains.items():\n",
    "    print(f\"\\n--- Running RFECV for domain: {domain} ({len(cols)} features) ---\")\n",
    "    if not cols:\n",
    "        print(\"No columns found for this domain. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    X_domain = X[cols]\n",
    "    \n",
    "    # Initialize RFECV for this domain\n",
    "    estimator = XGBClassifier(objective='multiclass', random_state=24091993, n_jobs=-1)\n",
    "    cv_strategy = GroupKFold(n_splits=5)\n",
    "    rfecv_domain = RFECV(\n",
    "        estimator=estimator,\n",
    "        step=1,\n",
    "        cv=cv_strategy,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        min_features_to_select=N_FEATURES_PER_DOMAIN # Select at least N\n",
    "    )\n",
    "    \n",
    "    # Fit on the domain-specific data\n",
    "    rfecv_domain.fit(X_domain, Y, groups=groups)\n",
    "    \n",
    "    # Store the best features for this domain\n",
    "    selected_cols = X_domain.columns[rfecv_domain.support_].tolist()\n",
    "    best_features_per_domain[domain] = selected_cols\n",
    "    print(f\"Selected {len(selected_cols)} features for {domain}: {selected_cols}\")\n",
    "\n",
    "# --- Combine the best features from all domains ---\n",
    "final_selected_features = []\n",
    "for domain_features in best_features_per_domain.values():\n",
    "    final_selected_features.extend(domain_features)\n",
    "\n",
    "# Remove duplicates if any feature was selected in multiple domains\n",
    "final_selected_features = list(dict.fromkeys(final_selected_features)) \n",
    "\n",
    "print(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "print(final_selected_features)\n",
    "\n",
    "# Now, use this `final_selected_features` list to create your final X,\n",
    "# and proceed with hyperparameter tuning and model evaluation.\n",
    "X_selected = X[final_selected_features]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 2: GLOBAL HYPERPARAMETER TUNING WITH OPTUNA (ON SELECTED FEATURES)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\")\n",
    "\n",
    "def objective(trial, x_data, y_data, group_data):\n",
    "    param = {\n",
    "        'verbosity': 0, 'objective': 'multiclass', 'random_state': 24091993,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    f1_scores = []\n",
    "    for train_idx, test_idx in gkf.split(x_data, y_data, groups=group_data):\n",
    "        X_train, X_test = x_data.iloc[train_idx], x_data.iloc[test_idx]\n",
    "        y_train, y_test = y_data.iloc[train_idx], y_data.iloc[test_idx]\n",
    "        \n",
    "        # English: Apply class weights inside the objective function\n",
    "        class_weights_fold = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        sample_weights_fold = np.array([class_weights_fold[cls] for cls in y_train])\n",
    "        \n",
    "        model = XGBClassifier(**param)\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weights_fold)\n",
    "        preds = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, preds, average='weighted', zero_division=0))\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# English: Run Optuna study on the data with ONLY the selected features\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_selected, Y, groups), n_trials=50)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\nBest hyperparameters found:\", best_params)\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 3: FINAL UNBIASED EVALUATION\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- STAGE 3: Final evaluation using {len(final_selected_features)} best features and optimal hyperparameters ---\")\n",
    "\n",
    "n_splits = 5\n",
    "gkf_final = GroupKFold(n_splits=n_splits)\n",
    "all_accuracies = []\n",
    "all_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf_final.split(X_selected, Y, groups=groups)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "    \n",
    "    # English: Use the pre-selected features (X_selected) for splitting\n",
    "    X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    # English: Compute sample weights for the current training fold\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(Y_train), y=Y_train)\n",
    "    sample_weights = np.array([class_weights[cls] for cls in Y_train])    \n",
    "\n",
    "    # English: Initialize model with the best global parameters\n",
    "    model = XGBClassifier(objective='multiclass', random_state=24091993, **best_params)\n",
    "    model.fit(X_train, Y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # English: Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    f1 = f1_score(Y_test, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    all_accuracies.append(accuracy)\n",
    "    all_f1_scores.append(f1)\n",
    "    \n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# English: Display final results\n",
    "print(\"\\n--- Final Cross-Validation Results ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending results to experiment_log.txt...\n",
      "Results successfully logged.\n"
     ]
    }
   ],
   "source": [
    "# English: Import the datetime library at the top of your script\n",
    "import datetime\n",
    "\n",
    "# --- Option 2: Append results to a log file with a timestamp ---\n",
    "\n",
    "# English: Define the output filename\n",
    "results_log_filename = 'experiment_log.txt'\n",
    "\n",
    "# English: Get the current timestamp\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# English: Open the file in append mode ('a') to add new results\n",
    "with open(results_log_filename, 'a') as f:\n",
    "    print(f\"Appending results to {results_log_filename}...\")\n",
    "    \n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    \n",
    "    # English: Write a separator and timestamp for this run\n",
    "    f.write(f\"\\n--- Experiment Run: {timestamp} ---\\n\")\n",
    "    \n",
    "    # English: Write the metrics\n",
    "    f.write(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\\n\")\n",
    "    f.write(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\\n\")\n",
    "    f.write(\"\\nBest hyperparameters found: \" + str(best_params))\n",
    "    f.write(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "    f.write(str(final_selected_features))\n",
    "    \n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "print(\"Results successfully logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18 columns with zero or single unique values: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d']\n",
      "List of dropped columns: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d', 'environmental_temperature_mean_rolling_median_3d', 'environmental_temperature_mean_rolling_q25_3d', 'environmental_temperature_mean_rolling_q75_3d', 'environmental_temperature_mean_rolling_range_3d', 'environmental_temperature_mean_rolling_iqr_3d', 'environmental_temperature_max_rolling_mean_3d', 'environmental_temperature_max_rolling_q25_3d', 'environmental_temperature_max_rolling_q75_3d', 'environmental_temperature_max_rolling_range_3d', 'environmental_temperature_max_rolling_iqr_3d', 'environmental_temperature_min_rolling_q25_3d', 'environmental_temperature_min_rolling_q75_3d', 'environmental_temperature_min_rolling_range_3d', 'environmental_temperature_min_rolling_iqr_3d', 'environmental_humidity_mean_rolling_range_3d', 'environmental_humidity_mean_rolling_iqr_3d', 'environmental_humidity_max_rolling_range_3d', 'environmental_humidity_max_rolling_iqr_3d', 'environmental_humidity_max_rolling_cv_3d', 'environmental_humidity_min_rolling_range_3d', 'environmental_humidity_min_rolling_iqr_3d', 'environmental_precipitation_rolling_q75_3d', 'environmental_precipitation_rolling_range_3d', 'environmental_precipitation_rolling_iqr_3d', 'environmental_cloudcover_rolling_range_3d', 'environmental_cloudcover_rolling_iqr_3d', 'individual_sleep_duration_rolling_range_3d', 'individual_sleep_duration_rolling_iqr_3d', 'individual_sleep_rate_rolling_range_3d', 'individual_sleep_rate_rolling_iqr_3d', 'organizational_social_interaction_rolling_q25_3d', 'organizational_social_interaction_rolling_q75_3d', 'organizational_social_interaction_rolling_range_3d', 'organizational_social_interaction_rolling_iqr_3d', 'organizational_social_voice_sum_rolling_q75_3d', 'organizational_social_voice_sum_rolling_range_3d', 'organizational_social_voice_sum_rolling_iqr_3d', 'organizational_social_voice_count_rolling_range_3d', 'organizational_social_voice_count_rolling_iqr_3d', 'organizational_social_voice_mean_rolling_q75_3d', 'organizational_social_voice_mean_rolling_range_3d', 'organizational_social_voice_mean_rolling_iqr_3d', 'organizational_social_voice_max_rolling_range_3d', 'organizational_social_voice_max_rolling_iqr_3d', 'individual_minutes_stationary_rolling_q25_3d', 'individual_minutes_stationary_rolling_range_3d', 'individual_minutes_stationary_rolling_iqr_3d', 'individual_minutes_walking_rolling_q75_3d', 'individual_minutes_walking_rolling_range_3d', 'individual_minutes_walking_rolling_iqr_3d', 'individual_minutes_running_rolling_q75_3d', 'individual_minutes_running_rolling_range_3d', 'individual_minutes_running_rolling_iqr_3d', 'individual_minutes_unknown_rolling_q75_3d', 'individual_minutes_unknown_rolling_range_3d', 'individual_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_silence_rolling_range_3d', 'environmental_minutes_silence_rolling_iqr_3d', 'environmental_minutes_voice_rolling_range_3d', 'environmental_minutes_voice_rolling_iqr_3d', 'environmental_minutes_noise_rolling_q75_3d', 'environmental_minutes_noise_rolling_range_3d', 'environmental_minutes_noise_rolling_iqr_3d', 'organizational_work_hours_rolling_range_3d', 'organizational_work_hours_rolling_iqr_3d', 'organizational_deadlines_rolling_q75_3d', 'organizational_deadlines_rolling_range_3d', 'organizational_deadlines_rolling_iqr_3d', 'organizational_days_until_next_deadline_rolling_q75_3d', 'organizational_days_until_next_deadline_rolling_range_3d', 'organizational_days_until_next_deadline_rolling_iqr_3d', 'stress_level_rolling_median_3d', 'stress_level_rolling_q25_3d', 'stress_level_rolling_range_3d', 'stress_level_rolling_iqr_3d']\n",
      "--- STAGE 1: Finding the globally optimal set of features with RFECV ---\n",
      "\n",
      "--- Final combined set of 27 features ---\n",
      "['environmental_temperature_mean', 'environmental_cloudcover', 'organizational_social_voice_sum', 'individual_minutes_walking', 'individual_minutes_unknown', 'individual_personality_agreeableness', 'individual_personality_conscientiousness', 'individual_personality_openness', 'individual_flourishing_score', 'environmental_cloudcover_rolling_std_3d', 'environmental_cloudcover_rolling_min_3d', 'environmental_cloudcover_rolling_trend_slope_3d', 'environmental_cloudcover_rolling_zscore_3d', 'individual_sleep_duration_rolling_q25_3d', 'organizational_social_voice_sum_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_min_3d', 'organizational_social_voice_count_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_zscore_3d', 'organizational_social_voice_mean_rolling_mean_3d', 'organizational_social_voice_mean_rolling_q25_3d', 'organizational_social_voice_max_rolling_trend_slope_3d', 'individual_minutes_walking_rolling_max_3d', 'individual_minutes_walking_rolling_q25_3d', 'individual_minutes_unknown_rolling_min_3d', 'environmental_minutes_noise_rolling_max_3d', 'organizational_deadlines_rolling_zscore_3d', 'stress_level_rolling_mean_3d']\n",
      "\n",
      "--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\n",
      "\n",
      "Best hyperparameters found: {'n_estimators': 120, 'learning_rate': 0.01595626609736153, 'max_depth': 8, 'subsample': 0.9908055748111488, 'colsample_bytree': 0.6259621351668307, 'reg_alpha': 0.00018273503800083003, 'reg_lambda': 0.5230354861971547}\n",
      "\n",
      "--- STAGE 3: Final evaluation using 27 best features and optimal hyperparameters ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Fold Accuracy: 0.5467\n",
      "Fold F1-Score (Weighted): 0.5288\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Fold Accuracy: 0.5000\n",
      "Fold F1-Score (Weighted): 0.4984\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Fold Accuracy: 0.4079\n",
      "Fold F1-Score (Weighted): 0.4448\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Fold Accuracy: 0.6081\n",
      "Fold F1-Score (Weighted): 0.5958\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Fold Accuracy: 0.5814\n",
      "Fold F1-Score (Weighted): 0.5649\n",
      "\n",
      "--- Final Cross-Validation Results ---\n",
      "Mean Accuracy: 0.5288 ± 0.0705\n",
      "Mean F1-Score (Weighted): 0.5265 ± 0.0524\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24091993)\n",
    "\n",
    "# English: Suppress Optuna's trial logs for a cleaner output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "enriched_df = enriched_df[enriched_df['user_id'] != 59]# dataset.copy()\n",
    "\n",
    "# English: Filter out users who do not have all three stress classes\n",
    "#user_class_diversity = enriched_df.groupby('user_id')['stress_level'].nunique()\n",
    "#complete_users = user_class_diversity[user_class_diversity == 3].index\n",
    "#df_complete_stress = enriched_df[enriched_df['user_id'].isin(complete_users)].copy()\n",
    "\n",
    "# English: From the remaining users, select the top 20 by response count\n",
    "#user_counts_filtered = df_complete_stress['user_id'].value_counts()\n",
    "#num_top_users = min(20, len(user_counts_filtered))\n",
    "#top_users_from_complete = user_counts_filtered.head(num_top_users).index\n",
    "#df_final_selection = df_complete_stress[df_complete_stress['user_id'].isin(top_users_from_complete)].copy()\n",
    "\n",
    "# English: Now, handle NaNs and Infs\n",
    "enriched_df_filled = enriched_df.dropna()\n",
    "#enriched_df_filled.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_model = enriched_df_filled.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# English: Define X, Y, and groups for the entire process\n",
    "Y = df_model['stress_level']\n",
    "X = df_model.drop(columns=['stress_level', 'user_id', 'date'])\n",
    "\n",
    "correlation_threshold = 0.98\n",
    "\n",
    "# Apply the function\n",
    "X, dropped_columns = remove_highly_correlated_features(X, threshold=correlation_threshold)\n",
    "print(\"List of dropped columns:\", dropped_columns)\n",
    "\n",
    "groups = df_model['user_id']\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 1: GLOBAL FEATURE SELECTION WITH RFECV\n",
    "# ==============================================================================\n",
    "print(\"--- STAGE 1: Finding the globally optimal set of features with RFECV ---\")\n",
    "        \n",
    "# Initialize RFECV for this domain\n",
    "estimator = XGBClassifier(objective='multiclass', random_state=24091993, n_jobs=-1)\n",
    "cv_strategy = GroupKFold(n_splits=5)\n",
    "rfecv = RFECV(\n",
    "    estimator=estimator,\n",
    "    step=1,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    min_features_to_select=1 # Select at least N\n",
    ")\n",
    "\n",
    "# Fit on the domain-specific data\n",
    "rfecv.fit(X, Y, groups=groups)\n",
    "\n",
    "# Store the best features for this domain\n",
    "selected_cols = X.columns[rfecv.support_].tolist()\n",
    "\n",
    "# Remove duplicates if any feature was selected in multiple domains\n",
    "final_selected_features = selected_cols\n",
    "\n",
    "print(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "print(final_selected_features)\n",
    "\n",
    "# Now, use this `final_selected_features` list to create your final X,\n",
    "# and proceed with hyperparameter tuning and model evaluation.\n",
    "X_selected = X[final_selected_features]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 2: GLOBAL HYPERPARAMETER TUNING WITH OPTUNA (ON SELECTED FEATURES)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\")\n",
    "\n",
    "def objective(trial, x_data, y_data, group_data):\n",
    "    param = {\n",
    "        'verbosity': 0, 'objective': 'multiclass', 'random_state': 24091993,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    f1_scores = []\n",
    "    for train_idx, test_idx in gkf.split(x_data, y_data, groups=group_data):\n",
    "        X_train, X_test = x_data.iloc[train_idx], x_data.iloc[test_idx]\n",
    "        y_train, y_test = y_data.iloc[train_idx], y_data.iloc[test_idx]\n",
    "        \n",
    "        # English: Apply class weights inside the objective function\n",
    "        class_weights_fold = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        sample_weights_fold = np.array([class_weights_fold[cls] for cls in y_train])\n",
    "        \n",
    "        model = XGBClassifier(**param)\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weights_fold)\n",
    "        preds = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, preds, average='weighted', zero_division=0))\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# English: Run Optuna study on the data with ONLY the selected features\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_selected, Y, groups), n_trials=50)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\nBest hyperparameters found:\", best_params)\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 3: FINAL UNBIASED EVALUATION\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- STAGE 3: Final evaluation using {len(final_selected_features)} best features and optimal hyperparameters ---\")\n",
    "\n",
    "n_splits = 5\n",
    "gkf_final = GroupKFold(n_splits=n_splits)\n",
    "all_accuracies = []\n",
    "all_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf_final.split(X_selected, Y, groups=groups)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "    \n",
    "    # English: Use the pre-selected features (X_selected) for splitting\n",
    "    X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    # English: Compute sample weights for the current training fold\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(Y_train), y=Y_train)\n",
    "    sample_weights = np.array([class_weights[cls] for cls in Y_train])    \n",
    "\n",
    "    # English: Initialize model with the best global parameters\n",
    "    model = XGBClassifier(objective='multiclass', random_state=24091993, **best_params)\n",
    "    model.fit(X_train, Y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # English: Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    f1 = f1_score(Y_test, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    all_accuracies.append(accuracy)\n",
    "    all_f1_scores.append(f1)\n",
    "    \n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# English: Display final results\n",
    "print(\"\\n--- Final Cross-Validation Results ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending results to experiment_log.txt...\n",
      "Results successfully logged.\n"
     ]
    }
   ],
   "source": [
    "# English: Import the datetime library at the top of your script\n",
    "import datetime\n",
    "\n",
    "# --- Option 2: Append results to a log file with a timestamp ---\n",
    "\n",
    "# English: Define the output filename\n",
    "results_log_filename = 'experiment_log.txt'\n",
    "\n",
    "# English: Get the current timestamp\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# English: Open the file in append mode ('a') to add new results\n",
    "with open(results_log_filename, 'a') as f:\n",
    "    print(f\"Appending results to {results_log_filename}...\")\n",
    "    \n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    # English: Write a separator and timestamp for this run\n",
    "    f.write(f\"\\n--- Experiment Run: {timestamp} ---\\n\")\n",
    "    \n",
    "    # English: Write the metrics\n",
    "    f.write(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\\n\")\n",
    "    f.write(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\\n\")\n",
    "    f.write(\"\\nBest hyperparameters found: \" + str(best_params))\n",
    "    f.write(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "    f.write(str(final_selected_features))\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "print(\"Results successfully logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5158066523448012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level_rolling_q75_3d</th>\n",
       "      <th>stress_level_rolling_range_3d</th>\n",
       "      <th>stress_level_rolling_iqr_3d</th>\n",
       "      <th>stress_level_rolling_cv_3d</th>\n",
       "      <th>stress_level_rolling_trend_slope_3d</th>\n",
       "      <th>stress_level_rolling_direction_changes_3d</th>\n",
       "      <th>stress_level_rolling_entropy_3d</th>\n",
       "      <th>stress_level_rolling_zscore_3d</th>\n",
       "      <th>stress_level_rolling_time_since_peak_3d</th>\n",
       "      <th>stress_level_rolling_time_since_trough_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>3.354167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.150000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1.929167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>47.041667</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>2</td>\n",
       "      <td>3.525000</td>\n",
       "      <td>9.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>58.875000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>1</td>\n",
       "      <td>18.033333</td>\n",
       "      <td>24.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>87.875000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-22</td>\n",
       "      <td>1</td>\n",
       "      <td>14.208333</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>87.708333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>88.083333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>2</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>19.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>2</td>\n",
       "      <td>9.662500</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.041667</td>\n",
       "      <td>95.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id        date  stress_level  environmental_temperature_mean  \\\n",
       "3          4  2013-03-28             0                        3.450000   \n",
       "4          4  2013-03-29             1                        3.354167   \n",
       "2          4  2013-04-03             2                       -1.150000   \n",
       "5          4  2013-04-04             0                        1.929167   \n",
       "6          4  2013-04-05             2                        3.525000   \n",
       "..       ...         ...           ...                             ...   \n",
       "643       59  2013-05-21             1                       18.033333   \n",
       "644       59  2013-05-22             1                       14.208333   \n",
       "645       59  2013-05-23             1                       18.450000   \n",
       "646       59  2013-05-24             2                       13.508333   \n",
       "647       59  2013-05-27             2                        9.662500   \n",
       "\n",
       "     environmental_temperature_max  environmental_temperature_min  \\\n",
       "3                              8.0                            0.9   \n",
       "4                              8.6                           -1.6   \n",
       "2                              4.0                           -4.2   \n",
       "5                              8.6                           -2.2   \n",
       "6                              9.9                           -2.0   \n",
       "..                             ...                            ...   \n",
       "643                           24.4                           13.9   \n",
       "644                           24.5                            8.5   \n",
       "645                           24.7                           13.7   \n",
       "646                           19.4                            6.9   \n",
       "647                           17.4                            2.3   \n",
       "\n",
       "     environmental_humidity_mean  environmental_humidity_max  \\\n",
       "3                      76.333333                        95.0   \n",
       "4                      75.833333                        95.0   \n",
       "2                      45.833333                        58.0   \n",
       "5                      47.041667                        58.0   \n",
       "6                      58.875000                        78.0   \n",
       "..                           ...                         ...   \n",
       "643                    87.875000                        97.0   \n",
       "644                    87.708333                        99.0   \n",
       "645                    88.083333                        99.0   \n",
       "646                    94.250000                       100.0   \n",
       "647                    69.041667                        95.0   \n",
       "\n",
       "     environmental_humidity_min  environmental_precipitation  ...  \\\n",
       "3                          47.0                          1.5  ...   \n",
       "4                          55.0                          1.3  ...   \n",
       "2                          29.0                          0.0  ...   \n",
       "5                          33.0                          0.0  ...   \n",
       "6                          40.0                          0.0  ...   \n",
       "..                          ...                          ...  ...   \n",
       "643                        67.0                          5.5  ...   \n",
       "644                        63.0                          6.2  ...   \n",
       "645                        68.0                          1.9  ...   \n",
       "646                        84.0                         11.7  ...   \n",
       "647                        38.0                          0.0  ...   \n",
       "\n",
       "     stress_level_rolling_q75_3d  stress_level_rolling_range_3d  \\\n",
       "3                           0.75                            1.0   \n",
       "4                           1.00                            0.0   \n",
       "2                           0.00                            0.0   \n",
       "5                           1.75                            1.0   \n",
       "6                           1.50                            2.0   \n",
       "..                           ...                            ...   \n",
       "643                         1.75                            1.0   \n",
       "644                         1.00                            0.0   \n",
       "645                         1.00                            0.0   \n",
       "646                         1.00                            0.0   \n",
       "647                         1.75                            1.0   \n",
       "\n",
       "     stress_level_rolling_iqr_3d  stress_level_rolling_cv_3d  \\\n",
       "3                            0.5                    1.414214   \n",
       "4                            0.0                    0.000000   \n",
       "2                            0.0                    0.000000   \n",
       "5                            0.5                    0.471405   \n",
       "6                            1.0                    1.414214   \n",
       "..                           ...                         ...   \n",
       "643                          0.5                    0.471405   \n",
       "644                          0.0                    0.000000   \n",
       "645                          0.0                    0.000000   \n",
       "646                          0.0                    0.000000   \n",
       "647                          0.5                    0.471405   \n",
       "\n",
       "     stress_level_rolling_trend_slope_3d  \\\n",
       "3                                    1.0   \n",
       "4                                    0.0   \n",
       "2                                    0.0   \n",
       "5                                    1.0   \n",
       "6                                   -2.0   \n",
       "..                                   ...   \n",
       "643                                 -1.0   \n",
       "644                                  0.0   \n",
       "645                                  0.0   \n",
       "646                                  0.0   \n",
       "647                                  1.0   \n",
       "\n",
       "     stress_level_rolling_direction_changes_3d  \\\n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "2                                          0.0   \n",
       "5                                          0.0   \n",
       "6                                          0.0   \n",
       "..                                         ...   \n",
       "643                                        0.0   \n",
       "644                                        0.0   \n",
       "645                                        0.0   \n",
       "646                                        0.0   \n",
       "647                                        0.0   \n",
       "\n",
       "     stress_level_rolling_entropy_3d  stress_level_rolling_zscore_3d  \\\n",
       "3                                1.0                   -7.071068e-01   \n",
       "4                                0.0                   -1.000000e+08   \n",
       "2                                0.0                    1.000000e+08   \n",
       "5                                1.0                    7.071068e-01   \n",
       "6                                1.0                   -7.071068e-01   \n",
       "..                               ...                             ...   \n",
       "643                              1.0                   -7.071068e-01   \n",
       "644                              0.0                    0.000000e+00   \n",
       "645                              0.0                    0.000000e+00   \n",
       "646                              0.0                    0.000000e+00   \n",
       "647                              1.0                    7.071068e-01   \n",
       "\n",
       "     stress_level_rolling_time_since_peak_3d  \\\n",
       "3                                        0.0   \n",
       "4                                        1.0   \n",
       "2                                        1.0   \n",
       "5                                        0.0   \n",
       "6                                        1.0   \n",
       "..                                       ...   \n",
       "643                                      1.0   \n",
       "644                                      1.0   \n",
       "645                                      1.0   \n",
       "646                                      1.0   \n",
       "647                                      0.0   \n",
       "\n",
       "     stress_level_rolling_time_since_trough_3d  \n",
       "3                                          1.0  \n",
       "4                                          1.0  \n",
       "2                                          1.0  \n",
       "5                                          1.0  \n",
       "6                                          0.0  \n",
       "..                                         ...  \n",
       "643                                        0.0  \n",
       "644                                        1.0  \n",
       "645                                        1.0  \n",
       "646                                        1.0  \n",
       "647                                        1.0  \n",
       "\n",
       "[544 rows x 445 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context-stress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
