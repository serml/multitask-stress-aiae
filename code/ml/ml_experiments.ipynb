{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/studentlife2014_interpolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stress_level</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>individual_sleep_duration</th>\n",
       "      <th>individual_sleep_rate</th>\n",
       "      <th>organizational_social_interaction</th>\n",
       "      <th>organizational_deadlines</th>\n",
       "      <th>organizational_days_until_next_deadline</th>\n",
       "      <th>individual_minutes_stationary</th>\n",
       "      <th>individual_minutes_walking</th>\n",
       "      <th>individual_minutes_running</th>\n",
       "      <th>environmental_minutes_silence</th>\n",
       "      <th>environmental_minutes_voice</th>\n",
       "      <th>environmental_minutes_noise</th>\n",
       "      <th>organizational_social_voice_sum</th>\n",
       "      <th>organizational_social_voice_count</th>\n",
       "      <th>environmental_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>25142.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>25256.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>28051.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>17375.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>26301.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>11873.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>2.0</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>30018.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2.0</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>22226.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-26</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>14204.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>24044.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stress_level  user_id        date  individual_sleep_duration  \\\n",
       "0             1.0        4  2013-03-27                        6.0   \n",
       "1             2.0        4  2013-03-28                        6.0   \n",
       "2             2.0        4  2013-03-29                        6.0   \n",
       "3             2.0        4  2013-03-30                        7.0   \n",
       "4             2.0        4  2013-03-31                        7.0   \n",
       "..            ...      ...         ...                        ...   \n",
       "851           1.0       59  2013-05-23                        2.0   \n",
       "852           2.0       59  2013-05-24                        8.0   \n",
       "853           2.0       59  2013-05-25                       12.0   \n",
       "854           1.0       59  2013-05-26                       16.0   \n",
       "855           1.0       59  2013-05-27                       10.0   \n",
       "\n",
       "     individual_sleep_rate  organizational_social_interaction  \\\n",
       "0                      2.0                                3.0   \n",
       "1                      2.0                                3.0   \n",
       "2                      2.0                                3.0   \n",
       "3                      3.0                                3.0   \n",
       "4                      3.0                                3.0   \n",
       "..                     ...                                ...   \n",
       "851                    2.0                                4.0   \n",
       "852                    2.0                                4.0   \n",
       "853                    2.0                                4.0   \n",
       "854                    1.0                                4.0   \n",
       "855                    1.0                                4.0   \n",
       "\n",
       "     organizational_deadlines  organizational_days_until_next_deadline  \\\n",
       "0                         0.0                                     12.0   \n",
       "1                         0.0                                     11.0   \n",
       "2                         0.0                                     10.0   \n",
       "3                         0.0                                      9.0   \n",
       "4                         0.0                                      8.0   \n",
       "..                        ...                                      ...   \n",
       "851                       0.0                                      1.0   \n",
       "852                       1.0                                      5.0   \n",
       "853                       0.0                                      4.0   \n",
       "854                       0.0                                      3.0   \n",
       "855                       0.0                                      2.0   \n",
       "\n",
       "     individual_minutes_stationary  individual_minutes_walking  \\\n",
       "0                            505.0                        39.0   \n",
       "1                            633.0                        57.0   \n",
       "2                            592.0                        76.0   \n",
       "3                            593.0                        49.0   \n",
       "4                            621.0                        68.0   \n",
       "..                             ...                         ...   \n",
       "851                          555.0                        53.0   \n",
       "852                         1330.0                        46.0   \n",
       "853                         1319.0                        74.0   \n",
       "854                         1062.0                       185.0   \n",
       "855                         1295.0                        84.0   \n",
       "\n",
       "     individual_minutes_running  environmental_minutes_silence  \\\n",
       "0                          19.0                          352.0   \n",
       "1                          29.0                          410.0   \n",
       "2                          42.0                          368.0   \n",
       "3                          23.0                          493.0   \n",
       "4                          17.0                          413.0   \n",
       "..                          ...                            ...   \n",
       "851                         7.0                          203.0   \n",
       "852                        12.0                          399.0   \n",
       "853                        14.0                          306.0   \n",
       "854                        14.0                          299.0   \n",
       "855                        35.0                          541.0   \n",
       "\n",
       "     environmental_minutes_voice  environmental_minutes_noise  \\\n",
       "0                          179.0                        277.0   \n",
       "1                          268.0                        255.0   \n",
       "2                          293.0                        288.0   \n",
       "3                          136.0                        230.0   \n",
       "4                          240.0                        281.0   \n",
       "..                           ...                          ...   \n",
       "851                         47.0                        370.0   \n",
       "852                        178.0                        836.0   \n",
       "853                        148.0                        975.0   \n",
       "854                         77.0                        898.0   \n",
       "855                        152.0                        739.0   \n",
       "\n",
       "     organizational_social_voice_sum  organizational_social_voice_count  \\\n",
       "0                            25142.0                               41.0   \n",
       "1                            25256.0                               37.0   \n",
       "2                            28051.0                               39.0   \n",
       "3                            17375.0                               33.0   \n",
       "4                            26301.0                               37.0   \n",
       "..                               ...                                ...   \n",
       "851                          11873.0                               53.0   \n",
       "852                          30018.0                               92.0   \n",
       "853                          22226.0                               69.0   \n",
       "854                          14204.0                               46.0   \n",
       "855                          24044.0                              100.0   \n",
       "\n",
       "     environmental_weekday  \n",
       "0                        2  \n",
       "1                        3  \n",
       "2                        4  \n",
       "3                        5  \n",
       "4                        6  \n",
       "..                     ...  \n",
       "851                      3  \n",
       "852                      4  \n",
       "853                      5  \n",
       "854                      6  \n",
       "855                      0  \n",
       "\n",
       "[856 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9731184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_stress_features(df, user_col='user_id', date_col='date', stress_col='stress_level'):\n",
    "    \"\"\"\n",
    "    Adds two new columns to the dataframe:\n",
    "    1. individual_previous_stress_level: The previous stress level for the same user.\n",
    "    2. days_since_previous_measurement: The number of days passed since the last measurement.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataframe, which must contain user ID, date, and stress level columns.\n",
    "    user_col : str\n",
    "        The name of the user identifier column.\n",
    "    date_col : str\n",
    "        The name of the date column (must be a datetime type).\n",
    "    stress_col : str\n",
    "        The name of the stress level column.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A new dataframe with the two added features.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Ensure data is sorted chronologically for each user\n",
    "    df_copy = df_copy.sort_values(by=[user_col, date_col])\n",
    "\n",
    "    # --- Create the new features using groupby and shift ---\n",
    "\n",
    "    # 1. Get the previous stress level for each user (lag of 1)\n",
    "    df_copy['individual_previous_stress_level'] = df_copy.groupby(user_col)[stress_col].shift(1)\n",
    "\n",
    "    # 2. Calculate the days since the last measurement\n",
    "    # First, get the previous date for each user\n",
    "    previous_date = df_copy.groupby(user_col)[date_col].shift(1)\n",
    "    # Then, calculate the difference in days\n",
    "    # df_copy['individual_days_since_previous_stress_measurement'] = (df_copy[date_col] - previous_date).dt.days\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a28781",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = False\n",
    "if binary:\n",
    "    data['stress_level'] = data['stress_level'].apply(lambda x: 0 if x < 2 else 1)\n",
    "else:\n",
    "    data['stress_level'] = data['stress_level'].apply(lambda x: 0 if x == 1 else 1 if x == 2 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b168baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_previous_stress_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stress_level', 'user_id', 'date', 'individual_sleep_duration',\n",
       "       'individual_sleep_rate', 'organizational_social_interaction',\n",
       "       'organizational_deadlines', 'organizational_days_until_next_deadline',\n",
       "       'individual_minutes_stationary', 'individual_minutes_walking',\n",
       "       'individual_minutes_running', 'environmental_minutes_silence',\n",
       "       'environmental_minutes_voice', 'environmental_minutes_noise',\n",
       "       'organizational_social_voice_sum', 'organizational_social_voice_count',\n",
       "       'environmental_weekday', 'individual_previous_stress_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e22db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Filtering for the top 20 users with the most responses ---\n",
      "Original number of users: 22\n",
      "Number of users after filtering: 20\n",
      "--- Starting cross-validation with 5 folds ---\n",
      "\n",
      "--- Processing Fold 1/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3706\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.3853\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3872\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4214\n",
      "\n",
      "--- Processing Fold 2/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3750\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.3871\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3701\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3791\n",
      "\n",
      "--- Processing Fold 3/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4606\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.4656\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4731\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4697\n",
      "\n",
      "--- Processing Fold 4/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3996\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.3729\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4085\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3908\n",
      "\n",
      "--- Processing Fold 5/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3811\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.3523\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3666\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3362\n",
      "\n",
      "--- Final Experiment Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.370602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.385267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.387167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.421396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.375010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.387081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.370146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.379123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.460639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.465616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.473141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.469745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.399587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.372862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.408543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.390765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.381109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.352261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.366563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.336227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fold            Algorithm  F1-Score (weighted)\n",
       "0      1  Logistic Regression             0.370602\n",
       "1      1              XGBoost             0.385267\n",
       "2      1             LightGBM             0.387167\n",
       "3      1             CatBoost             0.421396\n",
       "4      2  Logistic Regression             0.375010\n",
       "5      2              XGBoost             0.387081\n",
       "6      2             LightGBM             0.370146\n",
       "7      2             CatBoost             0.379123\n",
       "8      3  Logistic Regression             0.460639\n",
       "9      3              XGBoost             0.465616\n",
       "10     3             LightGBM             0.473141\n",
       "11     3             CatBoost             0.469745\n",
       "12     4  Logistic Regression             0.399587\n",
       "13     4              XGBoost             0.372862\n",
       "14     4             LightGBM             0.408543\n",
       "15     4             CatBoost             0.390765\n",
       "16     5  Logistic Regression             0.381109\n",
       "17     5              XGBoost             0.352261\n",
       "18     5             LightGBM             0.366563\n",
       "19     5             CatBoost             0.336227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>0.049771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.043561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.397389</td>\n",
       "      <td>0.037043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.392618</td>\n",
       "      <td>0.043106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm      mean       std\n",
       "0             CatBoost  0.399451  0.049771\n",
       "1             LightGBM  0.401112  0.043561\n",
       "2  Logistic Regression  0.397389  0.037043\n",
       "3              XGBoost  0.392618  0.043106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. DATA PREPARATION ---\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, GroupShuffleSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import optuna\n",
    "import warnings\n",
    "from gplearn.genetic import SymbolicRegressor, SymbolicClassifier\n",
    "from pysr import PySRRegressor\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# English: Import models and tools\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- 1. DATA PREPARATION ---\n",
    "\n",
    "# --- THE FIX: Add a control flag for the filtering logic ---\n",
    "FILTER_FOR_TOP_USERS = True # Set to False to use all users\n",
    "\n",
    "# English: Initial data cleaning\n",
    "df = data.copy()#dataset.drop(columns=['individual_previous_stress_level', 'individual_days_since_previous_stress_measurement'])\n",
    "# map stress levels from 1 2 3 to 0 1 2\n",
    "\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "random_seed= 3052011\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "# English: Optional filtering block\n",
    "if FILTER_FOR_TOP_USERS:\n",
    "    print(\"--- Filtering for the top 20 users with the most responses ---\")\n",
    "    \n",
    "    # Step 1: Get the response counts for each user\n",
    "    user_counts = df['user_id'].value_counts()\n",
    "    \n",
    "    # Step 2: Get the list of the top 20 user IDs\n",
    "    # We use .index to get the user_id values\n",
    "    top_20_users = user_counts.head(20).index\n",
    "    \n",
    "    # Step 3: Filter the dataframe to keep only these top users\n",
    "    # .isin() checks which rows have a 'user_id' that is in our list\n",
    "    df_filtered = df[df['user_id'].isin(top_20_users)].copy()\n",
    "    \n",
    "    print(f\"Original number of users: {df['user_id'].nunique()}\")\n",
    "    print(f\"Number of users after filtering: {df_filtered['user_id'].nunique()}\")\n",
    "    \n",
    "    # English: Prepare data for modeling using the filtered dataframe\n",
    "    X = df_filtered.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "    y = df_filtered['stress_level']\n",
    "    groups = df_filtered['user_id']\n",
    "    \n",
    "else:\n",
    "    print(\"--- Using all available users (no filtering) ---\")\n",
    "    \n",
    "    # English: Prepare data for modeling using the original dataframe\n",
    "    X = df[['individual_previous_stress_level']]#df.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "    y = df['stress_level']\n",
    "    groups = df['user_id']\n",
    "\n",
    "\n",
    "# --- The rest of your experiment pipeline remains exactly the same ---\n",
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "# n_splits = ...\n",
    "# models_to_test = { ... }\n",
    "# ...\n",
    "\n",
    "\n",
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "results_list = []\n",
    "\n",
    "# --- THE FIX: Add class weighting parameters to the models ---\n",
    "# English: Define the models to be tested in a dictionary\n",
    "models_to_test = {\n",
    "    # English: For scikit-learn compatible models like Logistic Regression, we use the `class_weight` parameter.\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=random_seed, max_iter=10000, solver='liblinear', class_weight='balanced'))\n",
    "    ]),\n",
    "    \n",
    "    # English: For XGBoost, the parameter is `scale_pos_weight`, but it's more complex for multiclass.\n",
    "    # The best approach for XGBoost is to calculate weights manually and pass them to .fit().\n",
    "    # However, we will handle this inside the loop for a more robust calculation per fold.\n",
    "    \"XGBoost\": XGBClassifier(random_state=random_seed),\n",
    "    \n",
    "    # English: For LightGBM, the parameter is `class_weight`.\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_seed, verbose=-1, class_weight='balanced'),\n",
    "    \n",
    "    # English: For CatBoost, the parameter is `auto_class_weights`.\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=random_seed, verbose=0, auto_class_weights='Balanced')\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. CROSS-VALIDATION LOOP ---\n",
    "print(f\"--- Starting cross-validation with {n_splits} folds ---\")\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} ---\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --- THE FIX for XGBoost: Calculate sample weights for the current training fold ---\n",
    "    # This is the most robust way to handle class imbalance with XGBoost in a CV setting.\n",
    "    xgb_sample_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    # English: Iterate through each model defined above\n",
    "    for name, model in models_to_test.items():\n",
    "        print(f\"  - Training {name}...\")\n",
    "        \n",
    "        # English: Fit the model on the training data for the current fold\n",
    "        if name == \"XGBoost\":\n",
    "            # Pass the calculated sample weights to the fit method for XGBoost\n",
    "            model.fit(X_train, y_train, sample_weight=xgb_sample_weights)\n",
    "        else:\n",
    "            # Other models handle balancing internally via their parameters\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # (The rest of the prediction and evaluation logic remains the same)\n",
    "        preds = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "        results_list.append({'Fold': fold + 1, 'Algorithm': name, 'F1-Score (weighted)': f1})\n",
    "        print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# --- 4. RESULTS PRESENTATION ---\n",
    "print(\"\\n--- Final Experiment Results ---\")\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n--- Average Performance Summary ---\")\n",
    "summary = results_df.groupby('Algorithm')['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paso 1: Iniciando la ingeniería de características avanzadas ---\n",
      "Calculando características de ventana deslizante (rolling features)...\n",
      "Seleccionando el conjunto final de características...\n",
      "Preparación finalizada. Entrenando con 44 características.\n",
      "Número de muestras válidas tras crear rolling features: 7422\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Paso 2: Configurando el experimento de validación cruzada ---\n",
      "Modelos a comparar: ['XGBoost', 'CatBoost']\n",
      "Estrategia de validación: GroupKFold con 5 splits.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Paso 3: Iniciando validación cruzada... ---\n",
      "\n",
      "Fold 1/5:\n",
      "  Train users: 19, Test users: 5, Overlap: 0\n",
      "  - XGBoost F1-Score: 0.4033\n",
      "  - CatBoost F1-Score: 0.4461\n",
      "\n",
      "Fold 2/5:\n",
      "  Train users: 19, Test users: 5, Overlap: 0\n",
      "  - XGBoost F1-Score: 0.4168\n",
      "  - CatBoost F1-Score: 0.4973\n",
      "\n",
      "Fold 3/5:\n",
      "  Train users: 20, Test users: 4, Overlap: 0\n",
      "  - XGBoost F1-Score: 0.4927\n",
      "  - CatBoost F1-Score: 0.5043\n",
      "\n",
      "Fold 4/5:\n",
      "  Train users: 19, Test users: 5, Overlap: 0\n",
      "  - XGBoost F1-Score: 0.5206\n",
      "  - CatBoost F1-Score: 0.5426\n",
      "\n",
      "Fold 5/5:\n",
      "  Train users: 19, Test users: 5, Overlap: 0\n",
      "  - XGBoost F1-Score: 0.5778\n",
      "  - CatBoost F1-Score: 0.5549\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Paso 4: Resumen de rendimiento promedio en validación cruzada ---\n",
      "Algorithm  F1-Score Medio  Desv. Estándar\n",
      " CatBoost        0.509023        0.042864\n",
      "  XGBoost        0.482250        0.072822\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Paso 5: Análisis final del mejor modelo en un conjunto de prueba aislado ---\n",
      "Mejor modelo identificado: CatBoost (F1-Score Promedio: 0.5090)\n",
      "\n",
      "Separación final de datos: 5695 muestras de entrenamiento, 1727 de prueba.\n",
      "Usuarios para entrenamiento: 18, Usuarios para prueba: 6\n",
      "\n",
      "Re-entrenando CatBoost en el conjunto de entrenamiento final...\n",
      "\n",
      "--- Reporte de Clasificación Final ---\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "Sin Cambio de Estrés (0)       0.62      0.81      0.71      1018\n",
      "Con Cambio de Estrés (1)       0.52      0.30      0.38       709\n",
      "\n",
      "                accuracy                           0.60      1727\n",
      "               macro avg       0.57      0.55      0.54      1727\n",
      "            weighted avg       0.58      0.60      0.57      1727\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import warnings\n",
    "\n",
    "# --- 0. CONFIGURACIÓN INICIAL ---\n",
    "warnings.filterwarnings('ignore')\n",
    "# Suponemos que el DataFrame original se llama 'df_original'\n",
    "# df_original = pd.read_csv('tu_archivo_de_datos.csv') \n",
    "\n",
    "# --- 1. INGENIERÍA Y PREPARACIÓN DE CARACTERÍSTICAS (VERSIÓN AVANZADA CON ROLLING FEATURES) ---\n",
    "print(\"--- Paso 1: Iniciando la ingeniería de características avanzadas ---\")\n",
    "\n",
    "# Usar una copia para evitar modificar el dataframe original\n",
    "df = data.copy() # Asumiendo que el dataframe se llama 'data'\n",
    "\n",
    "# 1.1. Pre-procesamiento básico\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['user_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# 1.2. Creación de la variable objetivo 'stress_change'\n",
    "df['stress_change'] = np.where(df['stress_level'] != df['individual_previous_stress_level'], 1, 0)\n",
    "df.loc[df['individual_previous_stress_level'].isna(), 'stress_change'] = np.nan\n",
    "\n",
    "# 1.3. Creación de características de diferencia (cambio inmediato)\n",
    "features_to_diff = [\n",
    "    'environmental_temperature_mean', 'environmental_humidity_mean', 'environmental_precipitation',\n",
    "    'individual_sleep_duration', 'organizational_work_hours', 'organizational_days_until_next_deadline'\n",
    "]\n",
    "for col in features_to_diff:\n",
    "    df[f'{col}_diff_1d'] = df.groupby('user_id')[col].diff() # Nombramos como _diff_1d para claridad\n",
    "\n",
    "# 1.4. Creación de características de ventana deslizante (tendencias, volatilidad, acumulación)\n",
    "print(\"Calculando características de ventana deslizante (rolling features)...\")\n",
    "window_size = '3D'  # Ventana de 3 días\n",
    "\n",
    "features_for_rolling = [\n",
    "    'individual_sleep_duration',\n",
    "    'organizational_work_hours',\n",
    "    'environmental_temperature_mean',\n",
    "    'environmental_precipitation',\n",
    "    'individual_minutes_walking',\n",
    "    'individual_minutes_stationary'\n",
    "]\n",
    "\n",
    "# Definimos las agregaciones que queremos calcular en la ventana\n",
    "aggregations = {\n",
    "    'mean', # Tendencia\n",
    "    'std',  # Volatilidad\n",
    "    'sum',  # Acumulación\n",
    "    'min',  # Mínimo en el periodo\n",
    "    'max'   # Máximo en el periodo\n",
    "}\n",
    "\n",
    "# El cálculo se hace por grupo de usuario para no mezclar datos\n",
    "# Usamos un índice temporal para que .rolling() funcione correctamente\n",
    "df_rolling_features = df.set_index('date').groupby('user_id')[features_for_rolling].rolling(window=window_size).agg(aggregations)\n",
    "\n",
    "# Limpiamos los nombres de las nuevas columnas (ej. de ('individual_sleep_duration', 'mean') a 'individual_sleep_duration_rolling_3d_mean')\n",
    "df_rolling_features.columns = [f'{col[0]}_rolling_{window_size}_{col[1]}' for col in df_rolling_features.columns]\n",
    "\n",
    "# Eliminamos el multi-índice para poder unirlo al dataframe principal\n",
    "df_rolling_features = df_rolling_features.reset_index(level='user_id', drop=True)\n",
    "\n",
    "# Unimos las nuevas características al dataframe principal\n",
    "df = df.set_index('date').join(df_rolling_features).reset_index()\n",
    "df = df.sort_values(['user_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 1.5. Selección final de características y limpieza\n",
    "print(\"Seleccionando el conjunto final de características...\")\n",
    "final_features = [\n",
    "    # Rasgos de personalidad (estáticos)\n",
    "    'individual_personality_extraversion', 'individual_personality_agreeableness',\n",
    "    'individual_personality_conscientiousness', 'individual_personality_neuroticism',\n",
    "    'individual_personality_openness',\n",
    "    \n",
    "    # Contexto temporal y organizacional (no-diferenciadas)\n",
    "    'individual_days_since_previous_stress_measurement',\n",
    "    'environmental_weekday',\n",
    "    'organizational_deadlines',\n",
    "\n",
    "    # Características de cambio inmediato (diferencia 1 día)\n",
    "    *[f'{col}_diff_1d' for col in features_to_diff],\n",
    "    \n",
    "    # NUEVAS Características de ventana deslizante\n",
    "    *df_rolling_features.columns.tolist()\n",
    "]\n",
    "\n",
    "# Creamos el DataFrame final para el modelo\n",
    "df_model = df[['user_id', 'stress_change'] + final_features].copy()\n",
    "\n",
    "# Eliminamos todas las filas que tengan NaN en la columna objetivo o en las nuevas características.\n",
    "# Esto elimina la primera fila de cada usuario (por el _diff) y las primeras N filas (por el rolling)\n",
    "df_model.dropna(subset=['stress_change'], inplace=True)\n",
    "df_model.dropna(subset=df_rolling_features.columns.tolist(), inplace=True)\n",
    "\n",
    "# Rellenamos cualquier otro posible NaN con 0 (estrategia conservadora)\n",
    "df_model.fillna(0, inplace=True)\n",
    "\n",
    "# Convertimos el target a entero\n",
    "df_model['stress_change'] = df_model['stress_change'].astype(int)\n",
    "\n",
    "# 1.6. Preparar datos para el modelado\n",
    "X = df_model[final_features]\n",
    "y = df_model['stress_change']\n",
    "groups = df_model['user_id']\n",
    "\n",
    "print(f\"Preparación finalizada. Entrenando con {len(X.columns)} características.\")\n",
    "print(f\"Número de muestras válidas tras crear rolling features: {len(df_model)}\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- LOS PASOS 2, 3, 4 y 5 CONTINÚAN EXACTAMENTE IGUAL ---\n",
    "# (Pega aquí el resto de tu script desde \"--- 2. CONFIGURACIÓN DEL EXPERIMENTO...\")\n",
    "# ...\n",
    "\n",
    "\n",
    "# --- 2. CONFIGURACIÓN DEL EXPERIMENTO DE VALIDACIÓN CRUZADA ---\n",
    "print(\"--- Paso 2: Configurando el experimento de validación cruzada ---\")\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "n_splits = 5  # Usamos 5 folds, un estándar robusto\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "results_list = []\n",
    "\n",
    "# Definimos los modelos a probar\n",
    "models_to_test = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(random_state=random_seed, use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"CatBoost\": catb.CatBoostClassifier(random_state=random_seed, verbose=0, auto_class_weights='Balanced')\n",
    "}\n",
    "print(f\"Modelos a comparar: {list(models_to_test.keys())}\")\n",
    "print(f\"Estrategia de validación: GroupKFold con {n_splits} splits.\")\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- 3. BUCLE DE VALIDACIÓN CRUZADA (GroupKFold) ---\n",
    "print(f\"--- Paso 3: Iniciando validación cruzada... ---\")\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Obtenemos los IDs de los participantes en cada conjunto para verificar que no hay solapamiento\n",
    "    train_groups = set(groups.iloc[train_idx])\n",
    "    test_groups = set(groups.iloc[test_idx])\n",
    "    \n",
    "    print(f\"\\nFold {fold+1}/{n_splits}:\")\n",
    "    print(f\"  Train users: {len(train_groups)}, Test users: {len(test_groups)}, Overlap: {len(train_groups.intersection(test_groups))}\")\n",
    "\n",
    "    for name, model in models_to_test.items():\n",
    "        if name == \"XGBoost\":\n",
    "            # XGBoost requiere que los pesos se calculen y pasen explícitamente\n",
    "            sample_weights = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        else:\n",
    "            # CatBoost gestiona los pesos internamente con auto_class_weights='Balanced'\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        preds = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "        results_list.append({'Fold': fold+1, 'Algorithm': name, 'F1-Score (weighted)': f1})\n",
    "        print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- 4. PRESENTACIÓN DE RESULTADOS DE LA VALIDACIÓN CRUZADA ---\n",
    "print(\"--- Paso 4: Resumen de rendimiento promedio en validación cruzada ---\")\n",
    "results_df = pd.DataFrame(results_list)\n",
    "summary = results_df.groupby('Algorithm')['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "summary.rename(columns={'mean': 'F1-Score Medio', 'std': 'Desv. Estándar'}, inplace=True)\n",
    "print(summary.to_string(index=False))\n",
    "print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- 5. ANÁLISIS DETALLADO Y EVALUACIÓN FINAL DEL MEJOR MODELO ---\n",
    "print(\"--- Paso 5: Análisis final del mejor modelo en un conjunto de prueba aislado ---\")\n",
    "best_model_name = summary.loc[summary['F1-Score Medio'].idxmax()]['Algorithm']\n",
    "best_model_score = summary.loc[summary['F1-Score Medio'].idxmax()]['F1-Score Medio']\n",
    "print(f\"Mejor modelo identificado: {best_model_name} (F1-Score Promedio: {best_model_score:.4f})\")\n",
    "\n",
    "# Separación final usando GroupShuffleSplit para crear un conjunto de prueba con participantes no vistos\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=random_seed)\n",
    "final_train_idx, final_test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train_final, X_test_final = X.iloc[final_train_idx], X.iloc[final_test_idx]\n",
    "y_train_final, y_test_final = y.iloc[final_train_idx], y.iloc[final_test_idx]\n",
    "\n",
    "print(f\"\\nSeparación final de datos: {len(X_train_final)} muestras de entrenamiento, {len(X_test_final)} de prueba.\")\n",
    "print(f\"Usuarios para entrenamiento: {len(set(groups.iloc[final_train_idx]))}, Usuarios para prueba: {len(set(groups.iloc[final_test_idx]))}\")\n",
    "\n",
    "# Re-entrenamos el mejor modelo con el conjunto de entrenamiento final\n",
    "best_model_config = models_to_test[best_model_name]\n",
    "\n",
    "print(f\"\\nRe-entrenando {best_model_name} en el conjunto de entrenamiento final...\")\n",
    "if best_model_name == \"XGBoost\":\n",
    "    final_weights = class_weight.compute_sample_weight('balanced', y=y_train_final)\n",
    "    best_model_config.fit(X_train_final, y_train_final, sample_weight=final_weights)\n",
    "else:\n",
    "    best_model_config.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluación final\n",
    "print(\"\\n--- Reporte de Clasificación Final ---\")\n",
    "final_predictions = best_model_config.predict(X_test_final)\n",
    "target_names = ['Sin Cambio de Estrés (0)', 'Con Cambio de Estrés (1)']\n",
    "report = classification_report(y_test_final, final_predictions, target_names=target_names)\n",
    "print(report)\n",
    "print(\"==================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context-stress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
