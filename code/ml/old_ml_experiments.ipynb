{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, GroupShuffleSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import optuna\n",
    "import warnings\n",
    "from gplearn.genetic import SymbolicRegressor, SymbolicClassifier\n",
    "from pysr import PySRRegressor\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# English: Import models and tools\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(df, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Finds and removes one of each pair of highly correlated features in a dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe with numerical features.\n",
    "    threshold : float, optional\n",
    "        The correlation threshold above which a feature is considered redundant. \n",
    "        Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        A new dataframe with highly correlated features removed.\n",
    "    list\n",
    "        A list of the column names that were dropped.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # --- Step 1: Remove zero-variance columns ---\n",
    "    # These columns have no predictive power and can cause issues with correlation calculation.\n",
    "    cols_to_drop_zerovar = df_copy.columns[df_copy.nunique() <= 1]\n",
    "    if not cols_to_drop_zerovar.empty:\n",
    "        df_copy.drop(columns=cols_to_drop_zerovar, inplace=True)\n",
    "        print(f\"Removed {len(cols_to_drop_zerovar)} columns with zero or single unique values: {cols_to_drop_zerovar.tolist()}\")\n",
    "    \n",
    "    # --- Step 2: Calculate the correlation matrix ---\n",
    "    # Use .abs() because a strong negative correlation (-0.95) is as redundant as a strong positive one.\n",
    "    corr_matrix = df_copy.corr().abs()\n",
    "    \n",
    "    # --- Step 3: Identify one of each highly correlated pair ---\n",
    "    # Select the upper triangle of the correlation matrix to avoid duplicates\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find features with correlation greater than the threshold\n",
    "    cols_to_drop_corr = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    # --- Step 4: Drop the identified features ---\n",
    "    df_reduced = df_copy.drop(columns=cols_to_drop_corr)\n",
    "    \n",
    "    # Combine all dropped columns for the report\n",
    "    all_dropped_cols = cols_to_drop_zerovar.tolist() + cols_to_drop_corr\n",
    "    \n",
    "    return df_reduced, all_dropped_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/processed/studentlife_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'date', 'stress_level', 'environmental_temperature_mean',\n",
       "       'environmental_temperature_max', 'environmental_temperature_min',\n",
       "       'environmental_humidity_mean', 'environmental_humidity_max',\n",
       "       'environmental_humidity_min', 'environmental_precipitation',\n",
       "       'environmental_cloudcover', 'individual_sleep_duration',\n",
       "       'individual_sleep_rate', 'organizational_social_interaction',\n",
       "       'organizational_social_voice_sum', 'organizational_social_voice_count',\n",
       "       'organizational_social_voice_mean', 'organizational_social_voice_max',\n",
       "       'individual_minutes_stationary', 'individual_minutes_walking',\n",
       "       'individual_minutes_running', 'individual_minutes_unknown',\n",
       "       'environmental_minutes_silence', 'environmental_minutes_voice',\n",
       "       'environmental_minutes_noise', 'environmental_minutes_unknown',\n",
       "       'organizational_work_hours', 'organizational_deadlines',\n",
       "       'organizational_days_until_next_deadline', 'environmental_weekday',\n",
       "       'individual_personality_extraversion',\n",
       "       'individual_personality_agreeableness',\n",
       "       'individual_personality_conscientiousness',\n",
       "       'individual_personality_neuroticism', 'individual_personality_openness',\n",
       "       'individual_previous_stress_level',\n",
       "       'individual_days_since_previous_stress_measurement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only from stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment Setup: Training on 1 inertia-based features only. ---\n",
      "Number of samples after dropping NaNs: 624\n",
      "--- Starting cross-validation with 5 folds ---\n",
      "\n",
      "--- Average Performance Summary (Inertia Features Only) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.073767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.073767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.073767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.073767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm      mean       std\n",
       "0             CatBoost  0.564583  0.073767\n",
       "1             LightGBM  0.564583  0.073767\n",
       "2  Logistic Regression  0.564583  0.073767\n",
       "3              XGBoost  0.564583  0.073767"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================\n",
      "--- Detailed Analysis of the Best Performing Model (Inertia Features) ---\n",
      "================================================\n",
      "Best performing model identified: CatBoost (Average F1-Score: 0.5646)\n",
      "\n",
      "--- Retraining CatBoost on the final training set ---\n",
      "\n",
      "--- Final Classification Report ---\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Stress Level 0       0.46      0.50      0.48        22\n",
      "Stress Level 1       0.64      0.63      0.64        79\n",
      "Stress Level 2       0.62      0.61      0.62        62\n",
      "\n",
      "      accuracy                           0.61       163\n",
      "     macro avg       0.57      0.58      0.58       163\n",
      "  weighted avg       0.61      0.61      0.61       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. DATA PREPARATION FOR THE INERTIA-ONLY EXPERIMENT ---\n",
    "# English: Define the two features of interest for this baseline model\n",
    "features_of_interest = [\n",
    "    'individual_previous_stress_level',\n",
    "]\n",
    "\n",
    "# English: Select only the necessary columns and drop rows with missing values\n",
    "# (the first entry for each user will be NaN for these features)\n",
    "df_inertia = dataset[['user_id', 'stress_level'] + features_of_interest].copy()\n",
    "df_inertia.dropna(inplace=True)\n",
    "\n",
    "# English: Prepare data for modeling using only the inertia features\n",
    "X = df_inertia[features_of_interest]\n",
    "y = df_inertia['stress_level']\n",
    "groups = df_inertia['user_id']\n",
    "\n",
    "print(f\"--- Experiment Setup: Training on {len(X.columns)} inertia-based features only. ---\")\n",
    "print(f\"Number of samples after dropping NaNs: {len(df_inertia)}\")\n",
    "\n",
    "\n",
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "random_seed = 3052011\n",
    "np.random.seed(random_seed)\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "results_list = []\n",
    "\n",
    "# English: Define the models to be tested\n",
    "models_to_test = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=random_seed, max_iter=10000, class_weight='balanced'))\n",
    "    ]),\n",
    "    \"XGBoost\": XGBClassifier(random_state=random_seed),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_seed, verbose=-1, class_weight='balanced'),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=random_seed, verbose=0, auto_class_weights='Balanced')\n",
    "}\n",
    "\n",
    "# --- 3. CROSS-VALIDATION LOOP ---\n",
    "print(f\"--- Starting cross-validation with {n_splits} folds ---\")\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    xgb_sample_weights = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "    for name, model in models_to_test.items():\n",
    "        if name == \"XGBoost\":\n",
    "            model.fit(X_train, y_train, sample_weight=xgb_sample_weights)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        preds = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "        results_list.append({'Fold': fold, 'Algorithm': name, 'F1-Score (weighted)': f1})\n",
    "\n",
    "# --- 4. RESULTS PRESENTATION ---\n",
    "print(\"\\n--- Average Performance Summary (Inertia Features Only) ---\")\n",
    "results_df = pd.DataFrame(results_list)\n",
    "summary = results_df.groupby('Algorithm')['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "display(summary)\n",
    "\n",
    "\n",
    "# --- 5. DETAILED ANALYSIS OF THE BEST MODEL ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Detailed Analysis of the Best Performing Model (Inertia Features) ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "best_model_name = summary.loc[summary['mean'].idxmax()]['Algorithm']\n",
    "best_model_score = summary.loc[summary['mean'].idxmax()]['mean']\n",
    "print(f\"Best performing model identified: {best_model_name} (Average F1-Score: {best_model_score:.4f})\")\n",
    "\n",
    "best_model_config = models_to_test[best_model_name]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=random_seed)\n",
    "final_train_idx, final_test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train_final, X_test_final = X.iloc[final_train_idx], X.iloc[final_test_idx]\n",
    "y_train_final, y_test_final = y.iloc[final_train_idx], y.iloc[final_test_idx]\n",
    "\n",
    "print(f\"\\n--- Retraining {best_model_name} on the final training set ---\")\n",
    "if best_model_name == \"XGBoost\":\n",
    "    final_xgb_weights = class_weight.compute_sample_weight('balanced', y=y_train_final)\n",
    "    best_model_config.fit(X_train_final, y_train_final, sample_weight=final_xgb_weights)\n",
    "else:\n",
    "    best_model_config.fit(X_train_final, y_train_final)\n",
    "\n",
    "print(\"\\n--- Final Classification Report ---\")\n",
    "final_predictions = best_model_config.predict(X_test_final)\n",
    "target_names = [f'Stress Level {i}' for i in sorted(y.unique())]\n",
    "report = classification_report(y_test_final, final_predictions, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================\n",
      "--- Sanity Check: Performance of a Naive Persistence Model ---\n",
      "================================================\n",
      "F1-Score of Naive Persistence Model (predicting yesterday's stress): 0.6083\n",
      "F1-Score of your Best ML Model (CatBoost): 0.6083\n",
      "\n",
      "Conclusion: WARNING! Your ML model is NOT outperforming a simple persistence baseline.\n",
      "\n",
      "--- Classification Report for Naive Persistence Model ---\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Stress Level 0       0.46      0.50      0.48        22\n",
      "Stress Level 1       0.64      0.63      0.64        79\n",
      "Stress Level 2       0.62      0.61      0.62        62\n",
      "\n",
      "      accuracy                           0.61       163\n",
      "     macro avg       0.57      0.58      0.58       163\n",
      "  weighted avg       0.61      0.61      0.61       163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# English: This code block should be added at the end of your previous script,\n",
    "# after you have generated the classification report for your best model.\n",
    "\n",
    "# --- 6. SANITY CHECK: COMPARE AGAINST A NAIVE PERSISTENCE MODEL ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Sanity Check: Performance of a Naive Persistence Model ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "# English: The persistence model's predictions are simply the previous day's stress levels.\n",
    "# We will use the same final test set for a fair comparison.\n",
    "# X_test_final and y_test_final are available from the previous step.\n",
    "\n",
    "# English: Get the 'individual_previous_stress_level' for the test set.\n",
    "# We need to select it from the original dataframe using the test index.\n",
    "persistence_preds = X_test_final['individual_previous_stress_level'].astype(int)\n",
    "\n",
    "# English: Calculate the F1-score for this naive model\n",
    "persistence_f1_score = f1_score(y_test_final, persistence_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"F1-Score of Naive Persistence Model (predicting yesterday's stress): {persistence_f1_score:.4f}\")\n",
    "\n",
    "# English: Retrieve the score of your best ML model for direct comparison\n",
    "# This assumes 'final_predictions' holds the predictions from your best ML model\n",
    "best_model_f1_score = f1_score(y_test_final, final_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"F1-Score of your Best ML Model ({best_model_name}): {best_model_f1_score:.4f}\")\n",
    "\n",
    "# English: Conclude based on the comparison\n",
    "if best_model_f1_score > persistence_f1_score:\n",
    "    print(\"\\nConclusion: Your ML model IS learning patterns beyond simple persistence. It provides value.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: WARNING! Your ML model is NOT outperforming a simple persistence baseline.\")\n",
    "    \n",
    "# English: You can also print the classification report for the persistence model to see its weaknesses\n",
    "print(\"\\n--- Classification Report for Naive Persistence Model ---\")\n",
    "persistence_report = classification_report(y_test_final, persistence_preds, target_names=target_names)\n",
    "print(persistence_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================\n",
      "--- Qualitative Analysis of Model Predictions ---\n",
      "================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# English: Create a comparison dataframe\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m comparison_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_persistence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersistence_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_model_pred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_predictions\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# English: Find cases where the model correctly predicted a CHANGE in stress\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model_is_smart \u001b[38;5;241m=\u001b[39m comparison_df[\n\u001b[1;32m     16\u001b[0m     (comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_persistence\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m  \u001b[38;5;66;03m# Stress level changed\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     (comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_model_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])   \u001b[38;5;66;03m# Model predicted it correctly\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.virtualenvs/context-stress/lib/python3.10/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# English: This code can also be run at the end of your script.\n",
    "\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Qualitative Analysis of Model Predictions ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "# English: Create a comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'y_true': y_test_final,\n",
    "    'y_persistence': persistence_preds,\n",
    "    'y_model_pred': final_predictions\n",
    "})\n",
    "\n",
    "# English: Find cases where the model correctly predicted a CHANGE in stress\n",
    "model_is_smart = comparison_df[\n",
    "    (comparison_df['y_true'] != comparison_df['y_persistence']) &  # Stress level changed\n",
    "    (comparison_df['y_true'] == comparison_df['y_model_pred'])   # Model predicted it correctly\n",
    "]\n",
    "\n",
    "print(f\"\\nModel correctly predicted a change in stress {len(model_is_smart)} times.\")\n",
    "if not model_is_smart.empty:\n",
    "    print(\"Examples where the model was smart:\")\n",
    "    display(model_is_smart.head())\n",
    "\n",
    "# English: Find cases where the model failed to predict a change that persistence would have missed anyway\n",
    "model_missed_change = comparison_df[\n",
    "    (comparison_df['y_true'] != comparison_df['y_persistence']) &  # Stress level changed\n",
    "    (comparison_df['y_true'] != comparison_df['y_model_pred'])   # Model also missed it\n",
    "]\n",
    "print(f\"\\nModel failed to predict a change in stress {len(model_missed_change)} times.\")\n",
    "if not model_missed_change.empty:\n",
    "    print(\"Examples where the model missed a change:\")\n",
    "    display(model_missed_change.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress + metrics derived from stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/processed/studentlife_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>environmental_cloudcover</th>\n",
       "      <th>individual_sleep_duration</th>\n",
       "      <th>individual_sleep_rate</th>\n",
       "      <th>organizational_social_interaction</th>\n",
       "      <th>organizational_social_voice_sum</th>\n",
       "      <th>organizational_social_voice_count</th>\n",
       "      <th>organizational_social_voice_mean</th>\n",
       "      <th>organizational_social_voice_max</th>\n",
       "      <th>individual_minutes_stationary</th>\n",
       "      <th>individual_minutes_walking</th>\n",
       "      <th>individual_minutes_running</th>\n",
       "      <th>individual_minutes_unknown</th>\n",
       "      <th>environmental_minutes_silence</th>\n",
       "      <th>environmental_minutes_voice</th>\n",
       "      <th>environmental_minutes_noise</th>\n",
       "      <th>environmental_minutes_unknown</th>\n",
       "      <th>organizational_work_hours</th>\n",
       "      <th>organizational_deadlines</th>\n",
       "      <th>organizational_days_until_next_deadline</th>\n",
       "      <th>environmental_weekday</th>\n",
       "      <th>individual_personality_extraversion</th>\n",
       "      <th>individual_personality_agreeableness</th>\n",
       "      <th>individual_personality_conscientiousness</th>\n",
       "      <th>individual_personality_neuroticism</th>\n",
       "      <th>individual_personality_openness</th>\n",
       "      <th>individual_previous_stress_level</th>\n",
       "      <th>individual_days_since_previous_stress_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>64.125000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.791667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25142.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>613.219512</td>\n",
       "      <td>3469.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>84.541667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25256.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>682.594595</td>\n",
       "      <td>3328.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>3.354167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28051.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>719.256410</td>\n",
       "      <td>4280.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.525000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>44.291667</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>582.333333</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.150000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.583333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29059.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>581.180000</td>\n",
       "      <td>2884.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>0</td>\n",
       "      <td>18.033333</td>\n",
       "      <td>24.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>87.875000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>59.125000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31359.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>402.038462</td>\n",
       "      <td>3528.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-22</td>\n",
       "      <td>0</td>\n",
       "      <td>14.208333</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>87.708333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18770.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>383.061224</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>0</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>88.083333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11873.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>224.018868</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>19.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>99.708333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30018.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>326.282609</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>0</td>\n",
       "      <td>9.662500</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.041667</td>\n",
       "      <td>95.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24044.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>240.440000</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id        date  stress_level  environmental_temperature_mean  \\\n",
       "0          4  2013-03-27             0                        0.466667   \n",
       "1          4  2013-03-28             1                        3.450000   \n",
       "2          4  2013-03-29             1                        3.354167   \n",
       "3          4  2013-04-02             1                       -1.525000   \n",
       "4          4  2013-04-03             1                       -1.150000   \n",
       "..       ...         ...           ...                             ...   \n",
       "643       59  2013-05-21             0                       18.033333   \n",
       "644       59  2013-05-22             0                       14.208333   \n",
       "645       59  2013-05-23             0                       18.450000   \n",
       "646       59  2013-05-24             1                       13.508333   \n",
       "647       59  2013-05-27             0                        9.662500   \n",
       "\n",
       "     environmental_temperature_max  environmental_temperature_min  \\\n",
       "0                              7.2                           -6.1   \n",
       "1                              8.0                            0.9   \n",
       "2                              8.6                           -1.6   \n",
       "3                              1.0                           -3.6   \n",
       "4                              4.0                           -4.2   \n",
       "..                             ...                            ...   \n",
       "643                           24.4                           13.9   \n",
       "644                           24.5                            8.5   \n",
       "645                           24.7                           13.7   \n",
       "646                           19.4                            6.9   \n",
       "647                           17.4                            2.3   \n",
       "\n",
       "     environmental_humidity_mean  environmental_humidity_max  \\\n",
       "0                      64.125000                        75.0   \n",
       "1                      76.333333                        95.0   \n",
       "2                      75.833333                        95.0   \n",
       "3                      44.291667                        53.0   \n",
       "4                      45.833333                        58.0   \n",
       "..                           ...                         ...   \n",
       "643                    87.875000                        97.0   \n",
       "644                    87.708333                        99.0   \n",
       "645                    88.083333                        99.0   \n",
       "646                    94.250000                       100.0   \n",
       "647                    69.041667                        95.0   \n",
       "\n",
       "     environmental_humidity_min  environmental_precipitation  \\\n",
       "0                          46.0                          0.0   \n",
       "1                          47.0                          1.5   \n",
       "2                          55.0                          1.3   \n",
       "3                          32.0                          0.0   \n",
       "4                          29.0                          0.0   \n",
       "..                          ...                          ...   \n",
       "643                        67.0                          5.5   \n",
       "644                        63.0                          6.2   \n",
       "645                        68.0                          1.9   \n",
       "646                        84.0                         11.7   \n",
       "647                        38.0                          0.0   \n",
       "\n",
       "     environmental_cloudcover  individual_sleep_duration  \\\n",
       "0                   27.791667                        6.0   \n",
       "1                   84.541667                        6.0   \n",
       "2                   27.250000                        6.0   \n",
       "3                   37.500000                        8.0   \n",
       "4                   28.583333                        8.0   \n",
       "..                        ...                        ...   \n",
       "643                 59.125000                        2.0   \n",
       "644                 96.000000                        2.0   \n",
       "645                 93.666667                        2.0   \n",
       "646                 99.708333                        8.0   \n",
       "647                  1.833333                       10.0   \n",
       "\n",
       "     individual_sleep_rate  organizational_social_interaction  \\\n",
       "0                      2.0                                3.0   \n",
       "1                      2.0                                3.0   \n",
       "2                      2.0                                3.0   \n",
       "3                      2.0                                3.0   \n",
       "4                      2.0                                3.0   \n",
       "..                     ...                                ...   \n",
       "643                    2.0                                4.0   \n",
       "644                    2.0                                4.0   \n",
       "645                    2.0                                4.0   \n",
       "646                    2.0                                4.0   \n",
       "647                    1.0                                4.0   \n",
       "\n",
       "     organizational_social_voice_sum  organizational_social_voice_count  \\\n",
       "0                            25142.0                               41.0   \n",
       "1                            25256.0                               37.0   \n",
       "2                            28051.0                               39.0   \n",
       "3                            20964.0                               36.0   \n",
       "4                            29059.0                               50.0   \n",
       "..                               ...                                ...   \n",
       "643                          31359.0                               78.0   \n",
       "644                          18770.0                               49.0   \n",
       "645                          11873.0                               53.0   \n",
       "646                          30018.0                               92.0   \n",
       "647                          24044.0                              100.0   \n",
       "\n",
       "     organizational_social_voice_mean  organizational_social_voice_max  \\\n",
       "0                          613.219512                           3469.0   \n",
       "1                          682.594595                           3328.0   \n",
       "2                          719.256410                           4280.0   \n",
       "3                          582.333333                           4034.0   \n",
       "4                          581.180000                           2884.0   \n",
       "..                                ...                              ...   \n",
       "643                        402.038462                           3528.0   \n",
       "644                        383.061224                           2638.0   \n",
       "645                        224.018868                           2518.0   \n",
       "646                        326.282609                           3195.0   \n",
       "647                        240.440000                           1092.0   \n",
       "\n",
       "     individual_minutes_stationary  individual_minutes_walking  \\\n",
       "0                            505.0                        39.0   \n",
       "1                            633.0                        57.0   \n",
       "2                            592.0                        76.0   \n",
       "3                            635.0                        53.0   \n",
       "4                            564.0                        57.0   \n",
       "..                             ...                         ...   \n",
       "643                         1346.0                        55.0   \n",
       "644                         1344.0                        61.0   \n",
       "645                          555.0                        53.0   \n",
       "646                         1330.0                        46.0   \n",
       "647                         1295.0                        84.0   \n",
       "\n",
       "     individual_minutes_running  individual_minutes_unknown  \\\n",
       "0                          19.0                         5.0   \n",
       "1                          29.0                         3.0   \n",
       "2                          42.0                        10.0   \n",
       "3                          28.0                         4.0   \n",
       "4                          23.0                         2.0   \n",
       "..                          ...                         ...   \n",
       "643                        28.0                        11.0   \n",
       "644                        14.0                        16.0   \n",
       "645                         7.0                         5.0   \n",
       "646                        12.0                        24.0   \n",
       "647                        35.0                        17.0   \n",
       "\n",
       "     environmental_minutes_silence  environmental_minutes_voice  \\\n",
       "0                            352.0                        179.0   \n",
       "1                            410.0                        268.0   \n",
       "2                            368.0                        293.0   \n",
       "3                            518.0                        195.0   \n",
       "4                            387.0                        300.0   \n",
       "..                             ...                          ...   \n",
       "643                          468.0                        189.0   \n",
       "644                          462.0                        124.0   \n",
       "645                          203.0                         47.0   \n",
       "646                          399.0                        178.0   \n",
       "647                          541.0                        152.0   \n",
       "\n",
       "     environmental_minutes_noise  environmental_minutes_unknown  \\\n",
       "0                          277.0                            0.0   \n",
       "1                          255.0                            0.0   \n",
       "2                          288.0                            0.0   \n",
       "3                          176.0                            0.0   \n",
       "4                          269.0                            0.0   \n",
       "..                           ...                            ...   \n",
       "643                        783.0                            0.0   \n",
       "644                        849.0                            0.0   \n",
       "645                        370.0                            0.0   \n",
       "646                        836.0                            0.0   \n",
       "647                        739.0                            0.0   \n",
       "\n",
       "     organizational_work_hours  organizational_deadlines  \\\n",
       "0                          5.0                       0.0   \n",
       "1                          5.0                       0.0   \n",
       "2                          3.0                       0.0   \n",
       "3                          4.0                       0.0   \n",
       "4                          3.0                       0.0   \n",
       "..                         ...                       ...   \n",
       "643                        3.0                       0.0   \n",
       "644                        1.0                       0.0   \n",
       "645                        2.0                       0.0   \n",
       "646                        2.0                       1.0   \n",
       "647                        2.0                       0.0   \n",
       "\n",
       "     organizational_days_until_next_deadline  environmental_weekday  \\\n",
       "0                                       12.0                      2   \n",
       "1                                       11.0                      3   \n",
       "2                                       10.0                      4   \n",
       "3                                        6.0                      1   \n",
       "4                                        5.0                      2   \n",
       "..                                       ...                    ...   \n",
       "643                                      3.0                      1   \n",
       "644                                      2.0                      2   \n",
       "645                                      1.0                      3   \n",
       "646                                      5.0                      4   \n",
       "647                                      2.0                      0   \n",
       "\n",
       "     individual_personality_extraversion  \\\n",
       "0                                      1   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "..                                   ...   \n",
       "643                                   14   \n",
       "644                                   14   \n",
       "645                                   14   \n",
       "646                                   14   \n",
       "647                                   14   \n",
       "\n",
       "     individual_personality_agreeableness  \\\n",
       "0                                       4   \n",
       "1                                       4   \n",
       "2                                       4   \n",
       "3                                       4   \n",
       "4                                       4   \n",
       "..                                    ...   \n",
       "643                                    13   \n",
       "644                                    13   \n",
       "645                                    13   \n",
       "646                                    13   \n",
       "647                                    13   \n",
       "\n",
       "     individual_personality_conscientiousness  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "..                                        ...   \n",
       "643                                        -1   \n",
       "644                                        -1   \n",
       "645                                        -1   \n",
       "646                                        -1   \n",
       "647                                        -1   \n",
       "\n",
       "     individual_personality_neuroticism  individual_personality_openness  \\\n",
       "0                                    15                               17   \n",
       "1                                    15                               17   \n",
       "2                                    15                               17   \n",
       "3                                    15                               17   \n",
       "4                                    15                               17   \n",
       "..                                  ...                              ...   \n",
       "643                                   5                               23   \n",
       "644                                   5                               23   \n",
       "645                                   5                               23   \n",
       "646                                   5                               23   \n",
       "647                                   5                               23   \n",
       "\n",
       "     individual_previous_stress_level  \\\n",
       "0                                 NaN   \n",
       "1                                 0.0   \n",
       "2                                 1.0   \n",
       "3                                 1.0   \n",
       "4                                 1.0   \n",
       "..                                ...   \n",
       "643                               0.0   \n",
       "644                               0.0   \n",
       "645                               0.0   \n",
       "646                               0.0   \n",
       "647                               1.0   \n",
       "\n",
       "     individual_days_since_previous_stress_measurement  \n",
       "0                                                  NaN  \n",
       "1                                                  1.0  \n",
       "2                                                  1.0  \n",
       "3                                                  4.0  \n",
       "4                                                  1.0  \n",
       "..                                                 ...  \n",
       "643                                                1.0  \n",
       "644                                                1.0  \n",
       "645                                                1.0  \n",
       "646                                                1.0  \n",
       "647                                                3.0  \n",
       "\n",
       "[648 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>environmental_cloudcover</th>\n",
       "      <th>individual_sleep_duration</th>\n",
       "      <th>individual_sleep_rate</th>\n",
       "      <th>organizational_social_interaction</th>\n",
       "      <th>organizational_social_voice_sum</th>\n",
       "      <th>organizational_social_voice_count</th>\n",
       "      <th>organizational_social_voice_mean</th>\n",
       "      <th>organizational_social_voice_max</th>\n",
       "      <th>individual_minutes_stationary</th>\n",
       "      <th>individual_minutes_walking</th>\n",
       "      <th>individual_minutes_running</th>\n",
       "      <th>individual_minutes_unknown</th>\n",
       "      <th>environmental_minutes_silence</th>\n",
       "      <th>environmental_minutes_voice</th>\n",
       "      <th>environmental_minutes_noise</th>\n",
       "      <th>environmental_minutes_unknown</th>\n",
       "      <th>organizational_work_hours</th>\n",
       "      <th>organizational_deadlines</th>\n",
       "      <th>organizational_days_until_next_deadline</th>\n",
       "      <th>environmental_weekday</th>\n",
       "      <th>individual_personality_extraversion</th>\n",
       "      <th>individual_personality_agreeableness</th>\n",
       "      <th>individual_personality_conscientiousness</th>\n",
       "      <th>individual_personality_neuroticism</th>\n",
       "      <th>individual_personality_openness</th>\n",
       "      <th>individual_previous_stress_level</th>\n",
       "      <th>individual_days_since_previous_stress_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.0</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.620370</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>8.512854</td>\n",
       "      <td>14.699537</td>\n",
       "      <td>3.327778</td>\n",
       "      <td>68.407986</td>\n",
       "      <td>88.521605</td>\n",
       "      <td>43.833333</td>\n",
       "      <td>2.281636</td>\n",
       "      <td>48.630980</td>\n",
       "      <td>7.063272</td>\n",
       "      <td>1.935185</td>\n",
       "      <td>3.038580</td>\n",
       "      <td>19066.973765</td>\n",
       "      <td>31.466049</td>\n",
       "      <td>662.832093</td>\n",
       "      <td>3804.962963</td>\n",
       "      <td>650.459877</td>\n",
       "      <td>34.279321</td>\n",
       "      <td>9.324074</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>552.192901</td>\n",
       "      <td>184.385802</td>\n",
       "      <td>130.234568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.408951</td>\n",
       "      <td>0.461929</td>\n",
       "      <td>7.020305</td>\n",
       "      <td>2.016975</td>\n",
       "      <td>4.040123</td>\n",
       "      <td>8.822531</td>\n",
       "      <td>7.192901</td>\n",
       "      <td>6.439815</td>\n",
       "      <td>23.845679</td>\n",
       "      <td>0.804487</td>\n",
       "      <td>2.049679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.982157</td>\n",
       "      <td>0.399612</td>\n",
       "      <td>5.562435</td>\n",
       "      <td>6.753744</td>\n",
       "      <td>4.765486</td>\n",
       "      <td>12.982973</td>\n",
       "      <td>12.694466</td>\n",
       "      <td>13.079710</td>\n",
       "      <td>3.664127</td>\n",
       "      <td>31.175947</td>\n",
       "      <td>2.448987</td>\n",
       "      <td>0.846191</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>9815.475593</td>\n",
       "      <td>16.103378</td>\n",
       "      <td>458.478208</td>\n",
       "      <td>2391.010654</td>\n",
       "      <td>155.752454</td>\n",
       "      <td>23.720502</td>\n",
       "      <td>21.754139</td>\n",
       "      <td>32.386909</td>\n",
       "      <td>132.500263</td>\n",
       "      <td>110.337319</td>\n",
       "      <td>118.209585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.820677</td>\n",
       "      <td>0.718866</td>\n",
       "      <td>5.758966</td>\n",
       "      <td>1.375887</td>\n",
       "      <td>5.984389</td>\n",
       "      <td>5.860115</td>\n",
       "      <td>6.387402</td>\n",
       "      <td>6.269039</td>\n",
       "      <td>4.994056</td>\n",
       "      <td>0.396913</td>\n",
       "      <td>1.985283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.525000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.100000</td>\n",
       "      <td>44.291667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.854167</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12022.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>408.991935</td>\n",
       "      <td>2353.500000</td>\n",
       "      <td>614.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.454167</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>67.791667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>39.083333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18763.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>602.978865</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>179.500000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>78.958333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>77.375000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25406.750000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>4661.750000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>262.250000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56133.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>8578.000000</td>\n",
       "      <td>22576.000000</td>\n",
       "      <td>1346.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stress_level  environmental_temperature_mean  \\\n",
       "count  648.000000    648.000000                      648.000000   \n",
       "mean    33.620370      0.800926                        8.512854   \n",
       "std     17.982157      0.399612                        5.562435   \n",
       "min      4.000000      0.000000                       -1.525000   \n",
       "25%     17.000000      1.000000                        3.854167   \n",
       "50%     33.000000      1.000000                        7.454167   \n",
       "75%     51.000000      1.000000                       13.508333   \n",
       "max     59.000000      1.000000                       18.450000   \n",
       "\n",
       "       environmental_temperature_max  environmental_temperature_min  \\\n",
       "count                     648.000000                     648.000000   \n",
       "mean                       14.699537                       3.327778   \n",
       "std                         6.753744                       4.765486   \n",
       "min                         1.000000                      -6.100000   \n",
       "25%                         9.000000                      -0.600000   \n",
       "50%                        14.100000                       2.800000   \n",
       "75%                        20.500000                       6.800000   \n",
       "max                        26.400000                      13.900000   \n",
       "\n",
       "       environmental_humidity_mean  environmental_humidity_max  \\\n",
       "count                   648.000000                  648.000000   \n",
       "mean                     68.407986                   88.521605   \n",
       "std                      12.982973                   12.694466   \n",
       "min                      44.291667                   53.000000   \n",
       "25%                      58.750000                   80.000000   \n",
       "50%                      67.791667                   94.000000   \n",
       "75%                      78.958333                   99.000000   \n",
       "max                      94.250000                  100.000000   \n",
       "\n",
       "       environmental_humidity_min  environmental_precipitation  \\\n",
       "count                  648.000000                   648.000000   \n",
       "mean                    43.833333                     2.281636   \n",
       "std                     13.079710                     3.664127   \n",
       "min                     19.000000                     0.000000   \n",
       "25%                     35.000000                     0.000000   \n",
       "50%                     40.000000                     0.100000   \n",
       "75%                     54.000000                     2.300000   \n",
       "max                     84.000000                    15.000000   \n",
       "\n",
       "       environmental_cloudcover  individual_sleep_duration  \\\n",
       "count                648.000000                 648.000000   \n",
       "mean                  48.630980                   7.063272   \n",
       "std                   31.175947                   2.448987   \n",
       "min                    0.041667                   0.000000   \n",
       "25%                   27.250000                   6.000000   \n",
       "50%                   39.083333                   7.000000   \n",
       "75%                   77.375000                   8.000000   \n",
       "max                   99.916667                  17.000000   \n",
       "\n",
       "       individual_sleep_rate  organizational_social_interaction  \\\n",
       "count             648.000000                         648.000000   \n",
       "mean                1.935185                           3.038580   \n",
       "std                 0.846191                           0.988368   \n",
       "min                 1.000000                           1.000000   \n",
       "25%                 1.000000                           2.000000   \n",
       "50%                 2.000000                           3.000000   \n",
       "75%                 2.000000                           4.000000   \n",
       "max                 4.000000                           5.000000   \n",
       "\n",
       "       organizational_social_voice_sum  organizational_social_voice_count  \\\n",
       "count                       648.000000                         648.000000   \n",
       "mean                      19066.973765                          31.466049   \n",
       "std                        9815.475593                          16.103378   \n",
       "min                         161.000000                           1.000000   \n",
       "25%                       12022.000000                          22.000000   \n",
       "50%                       18763.000000                          30.000000   \n",
       "75%                       25406.750000                          40.000000   \n",
       "max                       56133.000000                         109.000000   \n",
       "\n",
       "       organizational_social_voice_mean  organizational_social_voice_max  \\\n",
       "count                        648.000000                       648.000000   \n",
       "mean                         662.832093                      3804.962963   \n",
       "std                          458.478208                      2391.010654   \n",
       "min                           80.500000                        91.000000   \n",
       "25%                          408.991935                      2353.500000   \n",
       "50%                          602.978865                      3534.000000   \n",
       "75%                          795.750000                      4661.750000   \n",
       "max                         8578.000000                     22576.000000   \n",
       "\n",
       "       individual_minutes_stationary  individual_minutes_walking  \\\n",
       "count                     648.000000                  648.000000   \n",
       "mean                      650.459877                   34.279321   \n",
       "std                       155.752454                   23.720502   \n",
       "min                        20.000000                    0.000000   \n",
       "25%                       614.750000                   19.000000   \n",
       "50%                       655.000000                   30.000000   \n",
       "75%                       677.000000                   43.000000   \n",
       "max                      1346.000000                  194.000000   \n",
       "\n",
       "       individual_minutes_running  individual_minutes_unknown  \\\n",
       "count                  648.000000                  648.000000   \n",
       "mean                     9.324074                   14.166667   \n",
       "std                     21.754139                   32.386909   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      1.000000                    3.000000   \n",
       "50%                      4.000000                    6.000000   \n",
       "75%                     13.000000                   12.000000   \n",
       "max                    424.000000                  375.000000   \n",
       "\n",
       "       environmental_minutes_silence  environmental_minutes_voice  \\\n",
       "count                     648.000000                   648.000000   \n",
       "mean                      552.192901                   184.385802   \n",
       "std                       132.500263                   110.337319   \n",
       "min                        37.000000                     0.000000   \n",
       "25%                       482.000000                   101.000000   \n",
       "50%                       565.000000                   179.500000   \n",
       "75%                       630.000000                   262.250000   \n",
       "max                      1075.000000                   615.000000   \n",
       "\n",
       "       environmental_minutes_noise  environmental_minutes_unknown  \\\n",
       "count                   648.000000                          648.0   \n",
       "mean                    130.234568                            0.0   \n",
       "std                     118.209585                            0.0   \n",
       "min                       0.000000                            0.0   \n",
       "25%                      52.000000                            0.0   \n",
       "50%                     103.000000                            0.0   \n",
       "75%                     172.000000                            0.0   \n",
       "max                     849.000000                            0.0   \n",
       "\n",
       "       organizational_work_hours  organizational_deadlines  \\\n",
       "count                 648.000000                591.000000   \n",
       "mean                    4.408951                  0.461929   \n",
       "std                     3.820677                  0.718866   \n",
       "min                     1.000000                  0.000000   \n",
       "25%                     1.000000                  0.000000   \n",
       "50%                     3.000000                  0.000000   \n",
       "75%                     6.000000                  1.000000   \n",
       "max                    12.000000                  3.000000   \n",
       "\n",
       "       organizational_days_until_next_deadline  environmental_weekday  \\\n",
       "count                               591.000000             648.000000   \n",
       "mean                                  7.020305               2.016975   \n",
       "std                                   5.758966               1.375887   \n",
       "min                                   1.000000               0.000000   \n",
       "25%                                   3.000000               1.000000   \n",
       "50%                                   5.000000               2.000000   \n",
       "75%                                   9.000000               3.000000   \n",
       "max                                  33.000000               4.000000   \n",
       "\n",
       "       individual_personality_extraversion  \\\n",
       "count                           648.000000   \n",
       "mean                              4.040123   \n",
       "std                               5.984389   \n",
       "min                              -5.000000   \n",
       "25%                              -1.000000   \n",
       "50%                               3.000000   \n",
       "75%                               9.000000   \n",
       "max                              16.000000   \n",
       "\n",
       "       individual_personality_agreeableness  \\\n",
       "count                            648.000000   \n",
       "mean                               8.822531   \n",
       "std                                5.860115   \n",
       "min                              -12.000000   \n",
       "25%                                6.000000   \n",
       "50%                               10.000000   \n",
       "75%                               13.000000   \n",
       "max                               15.000000   \n",
       "\n",
       "       individual_personality_conscientiousness  \\\n",
       "count                                648.000000   \n",
       "mean                                   7.192901   \n",
       "std                                    6.387402   \n",
       "min                                   -7.000000   \n",
       "25%                                    3.000000   \n",
       "50%                                    8.000000   \n",
       "75%                                   10.000000   \n",
       "max                                   19.000000   \n",
       "\n",
       "       individual_personality_neuroticism  individual_personality_openness  \\\n",
       "count                          648.000000                       648.000000   \n",
       "mean                             6.439815                        23.845679   \n",
       "std                              6.269039                         4.994056   \n",
       "min                             -4.000000                        11.000000   \n",
       "25%                              2.000000                        21.000000   \n",
       "50%                              5.000000                        24.000000   \n",
       "75%                             11.000000                        26.000000   \n",
       "max                             18.000000                        34.000000   \n",
       "\n",
       "       individual_previous_stress_level  \\\n",
       "count                        624.000000   \n",
       "mean                           0.804487   \n",
       "std                            0.396913   \n",
       "min                            0.000000   \n",
       "25%                            1.000000   \n",
       "50%                            1.000000   \n",
       "75%                            1.000000   \n",
       "max                            1.000000   \n",
       "\n",
       "       individual_days_since_previous_stress_measurement  \n",
       "count                                         624.000000  \n",
       "mean                                            2.049679  \n",
       "std                                             1.985283  \n",
       "min                                             1.000000  \n",
       "25%                                             1.000000  \n",
       "50%                                             1.000000  \n",
       "75%                                             3.000000  \n",
       "max                                            15.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>environmental_cloudcover</th>\n",
       "      <th>individual_sleep_duration</th>\n",
       "      <th>individual_sleep_rate</th>\n",
       "      <th>organizational_social_interaction</th>\n",
       "      <th>organizational_social_voice_sum</th>\n",
       "      <th>organizational_social_voice_count</th>\n",
       "      <th>organizational_social_voice_mean</th>\n",
       "      <th>organizational_social_voice_max</th>\n",
       "      <th>individual_minutes_stationary</th>\n",
       "      <th>individual_minutes_walking</th>\n",
       "      <th>individual_minutes_running</th>\n",
       "      <th>individual_minutes_unknown</th>\n",
       "      <th>environmental_minutes_silence</th>\n",
       "      <th>environmental_minutes_voice</th>\n",
       "      <th>environmental_minutes_noise</th>\n",
       "      <th>environmental_minutes_unknown</th>\n",
       "      <th>organizational_work_hours</th>\n",
       "      <th>organizational_deadlines</th>\n",
       "      <th>organizational_days_until_next_deadline</th>\n",
       "      <th>environmental_weekday</th>\n",
       "      <th>individual_personality_extraversion</th>\n",
       "      <th>individual_personality_agreeableness</th>\n",
       "      <th>individual_personality_conscientiousness</th>\n",
       "      <th>individual_personality_neuroticism</th>\n",
       "      <th>individual_personality_openness</th>\n",
       "      <th>individual_previous_stress_level</th>\n",
       "      <th>individual_days_since_previous_stress_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>64.125000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.791667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25142.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>613.219512</td>\n",
       "      <td>3469.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>84.541667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25256.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>682.594595</td>\n",
       "      <td>3328.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>3.354167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28051.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>719.256410</td>\n",
       "      <td>4280.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.525000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>44.291667</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>582.333333</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.150000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.583333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29059.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>581.180000</td>\n",
       "      <td>2884.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>0</td>\n",
       "      <td>18.033333</td>\n",
       "      <td>24.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>87.875000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>59.125000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31359.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>402.038462</td>\n",
       "      <td>3528.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-22</td>\n",
       "      <td>0</td>\n",
       "      <td>14.208333</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>87.708333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18770.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>383.061224</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>0</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>88.083333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11873.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>224.018868</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>19.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>99.708333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30018.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>326.282609</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>0</td>\n",
       "      <td>9.662500</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.041667</td>\n",
       "      <td>95.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24044.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>240.440000</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id        date  stress_level  environmental_temperature_mean  \\\n",
       "0          4  2013-03-27             0                        0.466667   \n",
       "1          4  2013-03-28             1                        3.450000   \n",
       "2          4  2013-03-29             1                        3.354167   \n",
       "3          4  2013-04-02             1                       -1.525000   \n",
       "4          4  2013-04-03             1                       -1.150000   \n",
       "..       ...         ...           ...                             ...   \n",
       "643       59  2013-05-21             0                       18.033333   \n",
       "644       59  2013-05-22             0                       14.208333   \n",
       "645       59  2013-05-23             0                       18.450000   \n",
       "646       59  2013-05-24             1                       13.508333   \n",
       "647       59  2013-05-27             0                        9.662500   \n",
       "\n",
       "     environmental_temperature_max  environmental_temperature_min  \\\n",
       "0                              7.2                           -6.1   \n",
       "1                              8.0                            0.9   \n",
       "2                              8.6                           -1.6   \n",
       "3                              1.0                           -3.6   \n",
       "4                              4.0                           -4.2   \n",
       "..                             ...                            ...   \n",
       "643                           24.4                           13.9   \n",
       "644                           24.5                            8.5   \n",
       "645                           24.7                           13.7   \n",
       "646                           19.4                            6.9   \n",
       "647                           17.4                            2.3   \n",
       "\n",
       "     environmental_humidity_mean  environmental_humidity_max  \\\n",
       "0                      64.125000                        75.0   \n",
       "1                      76.333333                        95.0   \n",
       "2                      75.833333                        95.0   \n",
       "3                      44.291667                        53.0   \n",
       "4                      45.833333                        58.0   \n",
       "..                           ...                         ...   \n",
       "643                    87.875000                        97.0   \n",
       "644                    87.708333                        99.0   \n",
       "645                    88.083333                        99.0   \n",
       "646                    94.250000                       100.0   \n",
       "647                    69.041667                        95.0   \n",
       "\n",
       "     environmental_humidity_min  environmental_precipitation  \\\n",
       "0                          46.0                          0.0   \n",
       "1                          47.0                          1.5   \n",
       "2                          55.0                          1.3   \n",
       "3                          32.0                          0.0   \n",
       "4                          29.0                          0.0   \n",
       "..                          ...                          ...   \n",
       "643                        67.0                          5.5   \n",
       "644                        63.0                          6.2   \n",
       "645                        68.0                          1.9   \n",
       "646                        84.0                         11.7   \n",
       "647                        38.0                          0.0   \n",
       "\n",
       "     environmental_cloudcover  individual_sleep_duration  \\\n",
       "0                   27.791667                        6.0   \n",
       "1                   84.541667                        6.0   \n",
       "2                   27.250000                        6.0   \n",
       "3                   37.500000                        8.0   \n",
       "4                   28.583333                        8.0   \n",
       "..                        ...                        ...   \n",
       "643                 59.125000                        2.0   \n",
       "644                 96.000000                        2.0   \n",
       "645                 93.666667                        2.0   \n",
       "646                 99.708333                        8.0   \n",
       "647                  1.833333                       10.0   \n",
       "\n",
       "     individual_sleep_rate  organizational_social_interaction  \\\n",
       "0                      2.0                                3.0   \n",
       "1                      2.0                                3.0   \n",
       "2                      2.0                                3.0   \n",
       "3                      2.0                                3.0   \n",
       "4                      2.0                                3.0   \n",
       "..                     ...                                ...   \n",
       "643                    2.0                                4.0   \n",
       "644                    2.0                                4.0   \n",
       "645                    2.0                                4.0   \n",
       "646                    2.0                                4.0   \n",
       "647                    1.0                                4.0   \n",
       "\n",
       "     organizational_social_voice_sum  organizational_social_voice_count  \\\n",
       "0                            25142.0                               41.0   \n",
       "1                            25256.0                               37.0   \n",
       "2                            28051.0                               39.0   \n",
       "3                            20964.0                               36.0   \n",
       "4                            29059.0                               50.0   \n",
       "..                               ...                                ...   \n",
       "643                          31359.0                               78.0   \n",
       "644                          18770.0                               49.0   \n",
       "645                          11873.0                               53.0   \n",
       "646                          30018.0                               92.0   \n",
       "647                          24044.0                              100.0   \n",
       "\n",
       "     organizational_social_voice_mean  organizational_social_voice_max  \\\n",
       "0                          613.219512                           3469.0   \n",
       "1                          682.594595                           3328.0   \n",
       "2                          719.256410                           4280.0   \n",
       "3                          582.333333                           4034.0   \n",
       "4                          581.180000                           2884.0   \n",
       "..                                ...                              ...   \n",
       "643                        402.038462                           3528.0   \n",
       "644                        383.061224                           2638.0   \n",
       "645                        224.018868                           2518.0   \n",
       "646                        326.282609                           3195.0   \n",
       "647                        240.440000                           1092.0   \n",
       "\n",
       "     individual_minutes_stationary  individual_minutes_walking  \\\n",
       "0                            505.0                        39.0   \n",
       "1                            633.0                        57.0   \n",
       "2                            592.0                        76.0   \n",
       "3                            635.0                        53.0   \n",
       "4                            564.0                        57.0   \n",
       "..                             ...                         ...   \n",
       "643                         1346.0                        55.0   \n",
       "644                         1344.0                        61.0   \n",
       "645                          555.0                        53.0   \n",
       "646                         1330.0                        46.0   \n",
       "647                         1295.0                        84.0   \n",
       "\n",
       "     individual_minutes_running  individual_minutes_unknown  \\\n",
       "0                          19.0                         5.0   \n",
       "1                          29.0                         3.0   \n",
       "2                          42.0                        10.0   \n",
       "3                          28.0                         4.0   \n",
       "4                          23.0                         2.0   \n",
       "..                          ...                         ...   \n",
       "643                        28.0                        11.0   \n",
       "644                        14.0                        16.0   \n",
       "645                         7.0                         5.0   \n",
       "646                        12.0                        24.0   \n",
       "647                        35.0                        17.0   \n",
       "\n",
       "     environmental_minutes_silence  environmental_minutes_voice  \\\n",
       "0                            352.0                        179.0   \n",
       "1                            410.0                        268.0   \n",
       "2                            368.0                        293.0   \n",
       "3                            518.0                        195.0   \n",
       "4                            387.0                        300.0   \n",
       "..                             ...                          ...   \n",
       "643                          468.0                        189.0   \n",
       "644                          462.0                        124.0   \n",
       "645                          203.0                         47.0   \n",
       "646                          399.0                        178.0   \n",
       "647                          541.0                        152.0   \n",
       "\n",
       "     environmental_minutes_noise  environmental_minutes_unknown  \\\n",
       "0                          277.0                            0.0   \n",
       "1                          255.0                            0.0   \n",
       "2                          288.0                            0.0   \n",
       "3                          176.0                            0.0   \n",
       "4                          269.0                            0.0   \n",
       "..                           ...                            ...   \n",
       "643                        783.0                            0.0   \n",
       "644                        849.0                            0.0   \n",
       "645                        370.0                            0.0   \n",
       "646                        836.0                            0.0   \n",
       "647                        739.0                            0.0   \n",
       "\n",
       "     organizational_work_hours  organizational_deadlines  \\\n",
       "0                          5.0                       0.0   \n",
       "1                          5.0                       0.0   \n",
       "2                          3.0                       0.0   \n",
       "3                          4.0                       0.0   \n",
       "4                          3.0                       0.0   \n",
       "..                         ...                       ...   \n",
       "643                        3.0                       0.0   \n",
       "644                        1.0                       0.0   \n",
       "645                        2.0                       0.0   \n",
       "646                        2.0                       1.0   \n",
       "647                        2.0                       0.0   \n",
       "\n",
       "     organizational_days_until_next_deadline  environmental_weekday  \\\n",
       "0                                       12.0                      2   \n",
       "1                                       11.0                      3   \n",
       "2                                       10.0                      4   \n",
       "3                                        6.0                      1   \n",
       "4                                        5.0                      2   \n",
       "..                                       ...                    ...   \n",
       "643                                      3.0                      1   \n",
       "644                                      2.0                      2   \n",
       "645                                      1.0                      3   \n",
       "646                                      5.0                      4   \n",
       "647                                      2.0                      0   \n",
       "\n",
       "     individual_personality_extraversion  \\\n",
       "0                                      1   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "..                                   ...   \n",
       "643                                   14   \n",
       "644                                   14   \n",
       "645                                   14   \n",
       "646                                   14   \n",
       "647                                   14   \n",
       "\n",
       "     individual_personality_agreeableness  \\\n",
       "0                                       4   \n",
       "1                                       4   \n",
       "2                                       4   \n",
       "3                                       4   \n",
       "4                                       4   \n",
       "..                                    ...   \n",
       "643                                    13   \n",
       "644                                    13   \n",
       "645                                    13   \n",
       "646                                    13   \n",
       "647                                    13   \n",
       "\n",
       "     individual_personality_conscientiousness  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "..                                        ...   \n",
       "643                                        -1   \n",
       "644                                        -1   \n",
       "645                                        -1   \n",
       "646                                        -1   \n",
       "647                                        -1   \n",
       "\n",
       "     individual_personality_neuroticism  individual_personality_openness  \\\n",
       "0                                    15                               17   \n",
       "1                                    15                               17   \n",
       "2                                    15                               17   \n",
       "3                                    15                               17   \n",
       "4                                    15                               17   \n",
       "..                                  ...                              ...   \n",
       "643                                   5                               23   \n",
       "644                                   5                               23   \n",
       "645                                   5                               23   \n",
       "646                                   5                               23   \n",
       "647                                   5                               23   \n",
       "\n",
       "     individual_previous_stress_level  \\\n",
       "0                                 NaN   \n",
       "1                                 0.0   \n",
       "2                                 1.0   \n",
       "3                                 1.0   \n",
       "4                                 1.0   \n",
       "..                                ...   \n",
       "643                               0.0   \n",
       "644                               0.0   \n",
       "645                               0.0   \n",
       "646                               0.0   \n",
       "647                               1.0   \n",
       "\n",
       "     individual_days_since_previous_stress_measurement  \n",
       "0                                                  NaN  \n",
       "1                                                  1.0  \n",
       "2                                                  1.0  \n",
       "3                                                  4.0  \n",
       "4                                                  1.0  \n",
       "..                                                 ...  \n",
       "643                                                1.0  \n",
       "644                                                1.0  \n",
       "645                                                1.0  \n",
       "646                                                1.0  \n",
       "647                                                3.0  \n",
       "\n",
       "[648 rows x 37 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using all available users (no filtering) ---\n",
      "--- Starting cross-validation with 5 folds ---\n",
      "\n",
      "--- Processing Fold 1/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.5937\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.5690\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5672\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.5336\n",
      "\n",
      "--- Processing Fold 2/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.7259\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.7752\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.7711\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.8049\n",
      "\n",
      "--- Processing Fold 3/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.7699\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.8328\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.8067\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.7910\n",
      "\n",
      "--- Processing Fold 4/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.6108\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.5063\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5294\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.5304\n",
      "\n",
      "--- Processing Fold 5/5 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.5625\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.7750\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.7586\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.7072\n",
      "\n",
      "--- Final Experiment Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.593683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.569032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.567177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.725876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.775155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.771054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.804926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.769912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.832838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.806706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.791047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.610789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.506275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.529403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.530357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.562541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.774964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.758599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.707182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fold            Algorithm  F1-Score (weighted)\n",
       "0      1  Logistic Regression             0.593683\n",
       "1      1              XGBoost             0.569032\n",
       "2      1             LightGBM             0.567177\n",
       "3      1             CatBoost             0.533600\n",
       "4      2  Logistic Regression             0.725876\n",
       "5      2              XGBoost             0.775155\n",
       "6      2             LightGBM             0.771054\n",
       "7      2             CatBoost             0.804926\n",
       "8      3  Logistic Regression             0.769912\n",
       "9      3              XGBoost             0.832838\n",
       "10     3             LightGBM             0.806706\n",
       "11     3             CatBoost             0.791047\n",
       "12     4  Logistic Regression             0.610789\n",
       "13     4              XGBoost             0.506275\n",
       "14     4             LightGBM             0.529403\n",
       "15     4             CatBoost             0.530357\n",
       "16     5  Logistic Regression             0.562541\n",
       "17     5              XGBoost             0.774964\n",
       "18     5             LightGBM             0.758599\n",
       "19     5             CatBoost             0.707182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.673422</td>\n",
       "      <td>0.134431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.686588</td>\n",
       "      <td>0.128174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.652560</td>\n",
       "      <td>0.090085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.691653</td>\n",
       "      <td>0.144263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm      mean       std\n",
       "0             CatBoost  0.673422  0.134431\n",
       "1             LightGBM  0.686588  0.128174\n",
       "2  Logistic Regression  0.652560  0.090085\n",
       "3              XGBoost  0.691653  0.144263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. DATA PREPARATION ---\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# --- 1. DATA PREPARATION ---\n",
    "\n",
    "# --- THE FIX: Add a control flag for the filtering logic ---\n",
    "FILTER_FOR_TOP_USERS = False # Set to False to use all users\n",
    "\n",
    "# English: Initial data cleaning\n",
    "df = dataset.drop(columns=['individual_previous_stress_level', 'individual_days_since_previous_stress_measurement'])\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "random_seed= 3052011\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "# English: Optional filtering block\n",
    "if FILTER_FOR_TOP_USERS:\n",
    "    print(\"--- Filtering for the top 20 users with the most responses ---\")\n",
    "    \n",
    "    # Step 1: Get the response counts for each user\n",
    "    user_counts = df['user_id'].value_counts()\n",
    "    \n",
    "    # Step 2: Get the list of the top 20 user IDs\n",
    "    # We use .index to get the user_id values\n",
    "    top_20_users = user_counts.head(20).index\n",
    "    \n",
    "    # Step 3: Filter the dataframe to keep only these top users\n",
    "    # .isin() checks which rows have a 'user_id' that is in our list\n",
    "    df_filtered = df[df['user_id'].isin(top_20_users)].copy()\n",
    "    \n",
    "    print(f\"Original number of users: {df['user_id'].nunique()}\")\n",
    "    print(f\"Number of users after filtering: {df_filtered['user_id'].nunique()}\")\n",
    "    \n",
    "    # English: Prepare data for modeling using the filtered dataframe\n",
    "    X = df_filtered.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "    y = df_filtered['stress_level']\n",
    "    groups = df_filtered['user_id']\n",
    "    \n",
    "else:\n",
    "    print(\"--- Using all available users (no filtering) ---\")\n",
    "    \n",
    "    # English: Prepare data for modeling using the original dataframe\n",
    "    X = df.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "    y = df['stress_level']\n",
    "    groups = df['user_id']\n",
    "\n",
    "\n",
    "# --- The rest of your experiment pipeline remains exactly the same ---\n",
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "# n_splits = ...\n",
    "# models_to_test = { ... }\n",
    "# ...\n",
    "\n",
    "\n",
    "# --- 2. EXPERIMENT CONFIGURATION ---\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "results_list = []\n",
    "\n",
    "# --- THE FIX: Add class weighting parameters to the models ---\n",
    "# English: Define the models to be tested in a dictionary\n",
    "models_to_test = {\n",
    "    # English: For scikit-learn compatible models like Logistic Regression, we use the `class_weight` parameter.\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=random_seed, max_iter=10000, solver='liblinear', class_weight='balanced'))\n",
    "    ]),\n",
    "    \n",
    "    # English: For XGBoost, the parameter is `scale_pos_weight`, but it's more complex for multiclass.\n",
    "    # The best approach for XGBoost is to calculate weights manually and pass them to .fit().\n",
    "    # However, we will handle this inside the loop for a more robust calculation per fold.\n",
    "    \"XGBoost\": XGBClassifier(random_state=random_seed),\n",
    "    \n",
    "    # English: For LightGBM, the parameter is `class_weight`.\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_seed, verbose=-1, class_weight='balanced'),\n",
    "    \n",
    "    # English: For CatBoost, the parameter is `auto_class_weights`.\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=random_seed, verbose=0, auto_class_weights='Balanced')\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. CROSS-VALIDATION LOOP ---\n",
    "print(f\"--- Starting cross-validation with {n_splits} folds ---\")\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} ---\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # --- THE FIX for XGBoost: Calculate sample weights for the current training fold ---\n",
    "    # This is the most robust way to handle class imbalance with XGBoost in a CV setting.\n",
    "    xgb_sample_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    # English: Iterate through each model defined above\n",
    "    for name, model in models_to_test.items():\n",
    "        print(f\"  - Training {name}...\")\n",
    "        \n",
    "        # English: Fit the model on the training data for the current fold\n",
    "        if name == \"XGBoost\":\n",
    "            # Pass the calculated sample weights to the fit method for XGBoost\n",
    "            model.fit(X_train, y_train, sample_weight=xgb_sample_weights)\n",
    "        else:\n",
    "            # Other models handle balancing internally via their parameters\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # (The rest of the prediction and evaluation logic remains the same)\n",
    "        preds = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "        results_list.append({'Fold': fold + 1, 'Algorithm': name, 'F1-Score (weighted)': f1})\n",
    "        print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# --- 4. RESULTS PRESENTATION ---\n",
    "print(\"\\n--- Final Experiment Results ---\")\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n--- Average Performance Summary ---\")\n",
    "summary = results_df.groupby('Algorithm')['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================\n",
      "--- Detailed Analysis of the Best Performing Model ---\n",
      "================================================\n",
      "Best performing model identified: XGBoost (Average F1-Score: 0.6917)\n",
      "\n",
      "--- Performing a final train-test split for unbiased evaluation ---\n",
      "Final training set size: 422 samples\n",
      "Final test set size: 169 samples\n",
      "\n",
      "--- Retraining XGBoost on the final training set ---\n",
      "\n",
      "--- Final Classification Report ---\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Stress Level 0       0.19      0.22      0.21        32\n",
      "Stress Level 1       0.81      0.79      0.80       137\n",
      "\n",
      "      accuracy                           0.68       169\n",
      "     macro avg       0.50      0.50      0.50       169\n",
      "  weighted avg       0.70      0.68      0.69       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. DETAILED ANALYSIS OF THE BEST MODEL ---\n",
    "# This is the new section you requested.\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Detailed Analysis of the Best Performing Model ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "# English: Step 1: Identify the best model from the summary\n",
    "best_model_name = summary.loc[summary['mean'].idxmax()]['Algorithm']\n",
    "best_model_score = summary.loc[summary['mean'].idxmax()]['mean']\n",
    "print(f\"Best performing model identified: {best_model_name} (Average F1-Score: {best_model_score:.4f})\")\n",
    "\n",
    "# English: Get the untrained model configuration\n",
    "best_model_config = models_to_test[best_model_name]\n",
    "\n",
    "# English: Step 2: Perform a final, single train-test split that respects user groups\n",
    "print(\"\\n--- Performing a final train-test split for unbiased evaluation ---\")\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=random_seed)\n",
    "final_train_idx, final_test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train_final, X_test_final = X.iloc[final_train_idx], X.iloc[final_test_idx]\n",
    "y_train_final, y_test_final = y.iloc[final_train_idx], y.iloc[final_test_idx]\n",
    "\n",
    "print(f\"Final training set size: {len(X_train_final)} samples\")\n",
    "print(f\"Final test set size: {len(X_test_final)} samples\")\n",
    "\n",
    "# English: Step 3: Retrain the best model on the new, larger training set\n",
    "print(f\"\\n--- Retraining {best_model_name} on the final training set ---\")\n",
    "if best_model_name == \"XGBoost\":\n",
    "    final_xgb_weights = class_weight.compute_sample_weight('balanced', y=y_train_final)\n",
    "    best_model_config.fit(X_train_final, y_train_final, sample_weight=final_xgb_weights)\n",
    "else:\n",
    "    best_model_config.fit(X_train_final, y_train_final)\n",
    "\n",
    "# English: Step 4: Generate and display the final classification report\n",
    "print(\"\\n--- Final Classification Report ---\")\n",
    "final_predictions = best_model_config.predict(X_test_final)\n",
    "\n",
    "# English: Define class names for a more readable report\n",
    "target_names = [f'Stress Level {i}' for i in sorted(y.unique())]\n",
    "report = classification_report(y_test_final, final_predictions, target_names=target_names)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      "--- Starting Experiment for Window Size: 3 ---\n",
      "========================================================\n",
      "\n",
      "--- Processing Fold 1/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.6390\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.7714\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.7517\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.8048\n",
      "\n",
      "--- Processing Fold 2/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.5765\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.6573\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5714\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.6457\n",
      "\n",
      "--- Processing Fold 3/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.5354\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.7181\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.7076\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.7520\n",
      "\n",
      "--- Processing Fold 4/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.6065\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.6164\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.7153\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.7635\n",
      "\n",
      "--- Processing Fold 5/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.6107\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.6342\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.6421\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.6342\n",
      "\n",
      "\n",
      "================================================\n",
      "--- Final Combined Experiment Results ---\n",
      "================================================\n",
      "\n",
      "--- Full Results Table ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.639037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.751673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.804765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.576485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.657313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.571387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.645719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.535413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.718095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.707591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.752001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.606476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.616410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.715323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.763541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.610666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.634199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.642059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.634199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Window Size  Fold            Algorithm  F1-Score (weighted)\n",
       "0             3     1  Logistic Regression             0.639037\n",
       "1             3     1              XGBoost             0.771429\n",
       "2             3     1             LightGBM             0.751673\n",
       "3             3     1             CatBoost             0.804765\n",
       "4             3     2  Logistic Regression             0.576485\n",
       "5             3     2              XGBoost             0.657313\n",
       "6             3     2             LightGBM             0.571387\n",
       "7             3     2             CatBoost             0.645719\n",
       "8             3     3  Logistic Regression             0.535413\n",
       "9             3     3              XGBoost             0.718095\n",
       "10            3     3             LightGBM             0.707591\n",
       "11            3     3             CatBoost             0.752001\n",
       "12            3     4  Logistic Regression             0.606476\n",
       "13            3     4              XGBoost             0.616410\n",
       "14            3     4             LightGBM             0.715323\n",
       "15            3     4             CatBoost             0.763541\n",
       "16            3     5  Logistic Regression             0.610666\n",
       "17            3     5              XGBoost             0.634199\n",
       "18            3     5             LightGBM             0.642059\n",
       "19            3     5             CatBoost             0.634199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.720045</td>\n",
       "      <td>0.075803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.677607</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.593616</td>\n",
       "      <td>0.039371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.679489</td>\n",
       "      <td>0.064159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Window Size            Algorithm      mean       std\n",
       "0            3             CatBoost  0.720045  0.075803\n",
       "1            3             LightGBM  0.677607  0.071333\n",
       "2            3  Logistic Regression  0.593616  0.039371\n",
       "3            3              XGBoost  0.679489  0.064159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# English: This script assumes you have already run the necessary import statements\n",
    "# for pandas, numpy, GroupKFold, f1_score, and all the required models.\n",
    "# It is also assumed that the 'dataset' variable is loaded.\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- 1. EXPERIMENT CONFIGURATION ---\n",
    "window_sizes = [3]\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# English: This is the main list to collect results from ALL experiments\n",
    "all_results_list = []\n",
    "\n",
    "# --- THE FIX: Add class weighting parameters to the models ---\n",
    "\n",
    "\n",
    "random_seed= 3052011\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# English: Define the models to be tested in a dictionary\n",
    "models_to_test = {\n",
    "    # English: For scikit-learn compatible models, we use the `class_weight` parameter.\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=random_seed, max_iter=100000, solver='liblinear', class_weight='balanced'))\n",
    "    ]),\n",
    "    \n",
    "    # English: XGBoost is a special case. We will handle its weighting inside the loop.\n",
    "    \"XGBoost\": XGBClassifier(random_state=random_seed),\n",
    "    \n",
    "    # English: LightGBM also has a `class_weight` parameter.\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_seed, verbose=-1, class_weight='balanced'),\n",
    "    \n",
    "    # English: CatBoost has its own specific parameter for automatic weighting.\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=random_seed, verbose=0, iterations=200, auto_class_weights='Balanced')\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. MAIN EXPERIMENT LOOP ---\n",
    "for window_size in window_sizes:\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"--- Starting Experiment for Window Size: {window_size} ---\")\n",
    "    print(f\"========================================================\")\n",
    "    \n",
    "    try:\n",
    "        # Creating a dummy dataframe for demonstration purposes as I can't access local files.\n",
    "        # Replace this block with your pd.read_csv line.\n",
    "        dataset = pd.read_csv(f'../data/augmented/studentlife_2014_{window_size}.csv')\n",
    "        dataset = dataset.drop(columns=['individual_previous_stress_level', 'individual_days_since_previous_stress_measurement'])\n",
    "        dataset.dropna(inplace=True)\n",
    "        # --- End of placeholder block ---\n",
    "\n",
    "        # English: Prepare data for modeling\n",
    "        X = dataset.drop(columns=['user_id', 'stress_level', 'date'])\n",
    "        y = dataset['stress_level']\n",
    "        groups = dataset['user_id']\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file for window size {window_size} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Cross-validation loop for the current dataset ---\n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} for window {window_size} ---\")\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # --- THE FIX for XGBoost: Calculate sample weights for the current training fold ---\n",
    "        # This is the most robust way to handle class imbalance with XGBoost in a CV setting.\n",
    "        xgb_sample_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "        # English: Iterate through each model defined above\n",
    "        for name, model in models_to_test.items():\n",
    "            print(f\"  - Training {name}...\")\n",
    "            \n",
    "            # English: Fit the model on the training data for the current fold\n",
    "            if name == \"XGBoost\":\n",
    "                # Pass the calculated sample weights to the fit method for XGBoost\n",
    "                model.fit(X_train, y_train, sample_weight=xgb_sample_weights)\n",
    "            else:\n",
    "                # Other models handle balancing internally via their initialization parameters\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            # English: Make predictions on the test data\n",
    "            preds = model.predict(X_test)\n",
    "            \n",
    "            # English: Calculate the weighted F1-score\n",
    "            f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "            \n",
    "            # English: Store the results, including the window size\n",
    "            all_results_list.append({\n",
    "                'Window Size': window_size,\n",
    "                'Fold': fold + 1,\n",
    "                'Algorithm': name,\n",
    "                'F1-Score (weighted)': f1\n",
    "            })\n",
    "            print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "# --- 3. FINAL RESULTS PRESENTATION ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Final Combined Experiment Results ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "if not all_results_list:\n",
    "    print(\"No results were generated. Please check data paths.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    \n",
    "    # English: Display the full results table\n",
    "    print(\"\\n--- Full Results Table ---\")\n",
    "    display(results_df)\n",
    "\n",
    "    # English: Display the summary table, grouped by window size and algorithm\n",
    "    print(\"\\n--- Average Performance Summary ---\")\n",
    "    summary = results_df.groupby(['Window Size', 'Algorithm'])['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "    display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      "--- Starting Experiment for Window Size: 3 ---\n",
      "========================================================\n",
      "--- Experiment Setup: Training on 135 interaction features only. ---\n",
      "\n",
      "--- Processing Fold 1/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3647\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.3406\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.4008\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3822\n",
      "\n",
      "--- Processing Fold 2/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.4782\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.4103\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3840\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.3753\n",
      "\n",
      "--- Processing Fold 3/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3821\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.5411\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.5191\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4644\n",
      "\n",
      "--- Processing Fold 4/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3210\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.2977\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.2911\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.2892\n",
      "\n",
      "--- Processing Fold 5/5 for window 3 ---\n",
      "  - Training Logistic Regression...\n",
      "  - Logistic Regression F1-Score: 0.3908\n",
      "  - Training XGBoost...\n",
      "  - XGBoost F1-Score: 0.3964\n",
      "  - Training LightGBM...\n",
      "  - LightGBM F1-Score: 0.3906\n",
      "  - Training CatBoost...\n",
      "  - CatBoost F1-Score: 0.4352\n",
      "\n",
      "\n",
      "================================================\n",
      "--- Final Combined Experiment Results (Interaction Features Only) ---\n",
      "================================================\n",
      "\n",
      "--- Full Results Table ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1-Score (weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.364657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.340621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.400751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.382153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.478192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.410332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.384029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.375335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.382073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.541086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.519072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.464405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.320982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.297719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.291114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.289208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.390764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.396352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.390568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.435249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Window Size  Fold            Algorithm  F1-Score (weighted)\n",
       "0             3     1  Logistic Regression             0.364657\n",
       "1             3     1              XGBoost             0.340621\n",
       "2             3     1             LightGBM             0.400751\n",
       "3             3     1             CatBoost             0.382153\n",
       "4             3     2  Logistic Regression             0.478192\n",
       "5             3     2              XGBoost             0.410332\n",
       "6             3     2             LightGBM             0.384029\n",
       "7             3     2             CatBoost             0.375335\n",
       "8             3     3  Logistic Regression             0.382073\n",
       "9             3     3              XGBoost             0.541086\n",
       "10            3     3             LightGBM             0.519072\n",
       "11            3     3             CatBoost             0.464405\n",
       "12            3     4  Logistic Regression             0.320982\n",
       "13            3     4              XGBoost             0.297719\n",
       "14            3     4             LightGBM             0.291114\n",
       "15            3     4             CatBoost             0.289208\n",
       "16            3     5  Logistic Regression             0.390764\n",
       "17            3     5              XGBoost             0.396352\n",
       "18            3     5             LightGBM             0.390568\n",
       "19            3     5             CatBoost             0.435249"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Average Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.389270</td>\n",
       "      <td>0.067113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.397107</td>\n",
       "      <td>0.081144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.387333</td>\n",
       "      <td>0.057470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.092160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Window Size            Algorithm      mean       std\n",
       "0            3             CatBoost  0.389270  0.067113\n",
       "1            3             LightGBM  0.397107  0.081144\n",
       "2            3  Logistic Regression  0.387333  0.057470\n",
       "3            3              XGBoost  0.397222  0.092160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# English: This script assumes you have already run the necessary import statements\n",
    "# for pandas, numpy, GroupKFold, f1_score, and all the required models.\n",
    "# It is also assumed that the 'dataset' variable is loaded.\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- 1. EXPERIMENT CONFIGURATION ---\n",
    "window_sizes = [3]\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# English: This is the main list to collect results from ALL experiments\n",
    "all_results_list = []\n",
    "\n",
    "random_seed = 3052011\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# English: Define the models to be tested in a dictionary\n",
    "models_to_test = {\n",
    "    # English: Logistic Regression still benefits from a scaler even if inputs are 0-1\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=random_seed, max_iter=100000, solver='liblinear', class_weight='balanced'))\n",
    "    ]),\n",
    "    \"XGBoost\": XGBClassifier(random_state=random_seed),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=random_seed, verbose=-1, class_weight='balanced'),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=random_seed, verbose=0, iterations=200, auto_class_weights='Balanced')\n",
    "}\n",
    "\n",
    "# --- 2. MAIN EXPERIMENT LOOP ---\n",
    "for window_size in window_sizes:\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"--- Starting Experiment for Window Size: {window_size} ---\")\n",
    "    print(f\"========================================================\")\n",
    "    \n",
    "    try:\n",
    "        # Creating a dummy dataframe for demonstration purposes.\n",
    "        # Replace this block with your actual pd.read_csv line.\n",
    "        dataset = pd.read_csv(f'../data/augmented/studentlife_2014_interactions.csv')\n",
    "        dataset = dataset.drop(columns=['individual_previous_stress_level', 'individual_days_since_previous_stress_measurement'])\n",
    "        dataset.dropna(inplace=True)\n",
    "        # --- End of placeholder block ---\n",
    "\n",
    "        # --- THE FIX: Select ONLY the interaction features ---\n",
    "        # English: Use a list comprehension to get all column names that start with 'interaction_'\n",
    "        interaction_features = [col for col in dataset.columns if col.startswith('interaction_')]\n",
    "        \n",
    "        # English: Prepare data for modeling using only these selected features\n",
    "        X = dataset[interaction_features]\n",
    "        y = dataset['stress_level']\n",
    "        groups = dataset['user_id']\n",
    "        \n",
    "        print(f\"--- Experiment Setup: Training on {len(X.columns)} interaction features only. ---\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file 'studentlife_2014_interactions.csv' not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Cross-validation loop for the current dataset ---\n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        print(f\"\\n--- Processing Fold {fold + 1}/{n_splits} for window {window_size} ---\")\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # English: Calculate sample weights for the current training fold\n",
    "        xgb_sample_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "        # English: Iterate through each model defined above\n",
    "        for name, model in models_to_test.items():\n",
    "            print(f\"  - Training {name}...\")\n",
    "            \n",
    "            # English: Fit the model on the training data for the current fold\n",
    "            if name == \"XGBoost\":\n",
    "                model.fit(X_train, y_train, sample_weight=xgb_sample_weights)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            # English: Make predictions on the test data\n",
    "            preds = model.predict(X_test)\n",
    "            \n",
    "            # English: Calculate the weighted F1-score\n",
    "            f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "            \n",
    "            # English: Store the results\n",
    "            all_results_list.append({\n",
    "                'Window Size': window_size,\n",
    "                'Fold': fold + 1,\n",
    "                'Algorithm': name,\n",
    "                'F1-Score (weighted)': f1\n",
    "            })\n",
    "            print(f\"  - {name} F1-Score: {f1:.4f}\")\n",
    "\n",
    "# --- 3. FINAL RESULTS PRESENTATION ---\n",
    "print(\"\\n\\n================================================\")\n",
    "print(\"--- Final Combined Experiment Results (Interaction Features Only) ---\")\n",
    "print(\"================================================\")\n",
    "\n",
    "if not all_results_list:\n",
    "    print(\"No results were generated. Please check data paths.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    \n",
    "    # English: Display the full results table\n",
    "    print(\"\\n--- Full Results Table ---\")\n",
    "    display(results_df)\n",
    "\n",
    "    # English: Display the summary table\n",
    "    print(\"\\n--- Average Performance Summary ---\")\n",
    "    summary = results_df.groupby(['Window Size', 'Algorithm'])['F1-Score (weighted)'].agg(['mean', 'std']).reset_index()\n",
    "    display(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'date', 'stress_level', 'environmental_temperature_mean',\n",
       "       'environmental_temperature_max', 'environmental_temperature_min',\n",
       "       'environmental_humidity_mean', 'environmental_humidity_max',\n",
       "       'environmental_humidity_min', 'environmental_precipitation',\n",
       "       'environmental_cloudcover', 'individual_sleep_duration',\n",
       "       'individual_sleep_rate', 'organizational_social_interaction',\n",
       "       'organizational_social_voice_sum', 'organizational_social_voice_count',\n",
       "       'organizational_social_voice_mean', 'organizational_social_voice_max',\n",
       "       'individual_minutes_stationary', 'individual_minutes_walking',\n",
       "       'individual_minutes_running', 'individual_minutes_unknown',\n",
       "       'environmental_minutes_silence', 'environmental_minutes_voice',\n",
       "       'environmental_minutes_noise', 'environmental_minutes_unknown',\n",
       "       'organizational_work_hours', 'deadlines', 'days_until_next_deadline',\n",
       "       'weekday', 'individual_personality_extraversion',\n",
       "       'individual_personality_agreeableness',\n",
       "       'individual_personality_conscientiousness',\n",
       "       'individual_personality_neuroticism', 'individual_personality_openness',\n",
       "       'individual_flourishing_score', 'individual_loneliness_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    'deadlines': 'organizational_deadlines',\n",
    "    'days_until_next_deadline': 'organizational_days_until_next_deadline',\n",
    "    'weekday': 'environmental_weekday'\n",
    "}\n",
    "\n",
    "dataset = dataset.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_for_columns(df, feature_columns, window_size, feature_function):\n",
    "    \"\"\"\n",
    "    Applies a feature generation function to a list of specified columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe.\n",
    "    feature_columns : list\n",
    "        A list of column names to generate features for.\n",
    "    window_size : int\n",
    "        The rolling window size to use.\n",
    "    feature_function : function\n",
    "        The function to apply (e.g., add_stress_rolling_features).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The dataframe enriched with all the new features.\n",
    "    \"\"\"\n",
    "    df_enriched = df.copy()\n",
    "    \n",
    "    # Track original columns to avoid creating features on features\n",
    "    original_cols = set(df_enriched.columns)\n",
    "    \n",
    "    for col in feature_columns:\n",
    "        if col in original_cols:\n",
    "            print(f\"Generating features for column: '{col}' with window size {window_size}...\")\n",
    "            df_enriched = feature_function(df_enriched, window_size, col)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in the initial dataframe. Skipping.\")\n",
    "            \n",
    "    print(\"\\nFeature generation complete.\")\n",
    "    return df_enriched\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>environmental_cloudcover</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level_rolling_q75_3d</th>\n",
       "      <th>stress_level_rolling_range_3d</th>\n",
       "      <th>stress_level_rolling_iqr_3d</th>\n",
       "      <th>stress_level_rolling_cv_3d</th>\n",
       "      <th>stress_level_rolling_trend_slope_3d</th>\n",
       "      <th>stress_level_rolling_direction_changes_3d</th>\n",
       "      <th>stress_level_rolling_entropy_3d</th>\n",
       "      <th>stress_level_rolling_zscore_3d</th>\n",
       "      <th>stress_level_rolling_time_since_peak_3d</th>\n",
       "      <th>stress_level_rolling_time_since_trough_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>647.0</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.620370</td>\n",
       "      <td>1.154321</td>\n",
       "      <td>8.512854</td>\n",
       "      <td>14.699537</td>\n",
       "      <td>3.327778</td>\n",
       "      <td>68.407986</td>\n",
       "      <td>88.521605</td>\n",
       "      <td>43.833333</td>\n",
       "      <td>2.281636</td>\n",
       "      <td>48.630980</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268934</td>\n",
       "      <td>0.476043</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.442335</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418856</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.744977</td>\n",
       "      <td>0.765070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.982157</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>5.562435</td>\n",
       "      <td>6.753744</td>\n",
       "      <td>4.765486</td>\n",
       "      <td>12.982973</td>\n",
       "      <td>12.694466</td>\n",
       "      <td>13.079710</td>\n",
       "      <td>3.664127</td>\n",
       "      <td>31.175947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625293</td>\n",
       "      <td>0.603625</td>\n",
       "      <td>0.301813</td>\n",
       "      <td>0.581263</td>\n",
       "      <td>0.798468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493753</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.436211</td>\n",
       "      <td>0.424283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.525000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.100000</td>\n",
       "      <td>44.291667</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.854167</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.454167</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>67.791667</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>39.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>78.958333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>77.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stress_level  environmental_temperature_mean  \\\n",
       "count  648.000000    648.000000                      648.000000   \n",
       "mean    33.620370      1.154321                        8.512854   \n",
       "std     17.982157      0.742368                        5.562435   \n",
       "min      4.000000      0.000000                       -1.525000   \n",
       "25%     17.000000      1.000000                        3.854167   \n",
       "50%     33.000000      1.000000                        7.454167   \n",
       "75%     51.000000      2.000000                       13.508333   \n",
       "max     59.000000      2.000000                       18.450000   \n",
       "\n",
       "       environmental_temperature_max  environmental_temperature_min  \\\n",
       "count                     648.000000                     648.000000   \n",
       "mean                       14.699537                       3.327778   \n",
       "std                         6.753744                       4.765486   \n",
       "min                         1.000000                      -6.100000   \n",
       "25%                         9.000000                      -0.600000   \n",
       "50%                        14.100000                       2.800000   \n",
       "75%                        20.500000                       6.800000   \n",
       "max                        26.400000                      13.900000   \n",
       "\n",
       "       environmental_humidity_mean  environmental_humidity_max  \\\n",
       "count                   648.000000                  648.000000   \n",
       "mean                     68.407986                   88.521605   \n",
       "std                      12.982973                   12.694466   \n",
       "min                      44.291667                   53.000000   \n",
       "25%                      58.750000                   80.000000   \n",
       "50%                      67.791667                   94.000000   \n",
       "75%                      78.958333                   99.000000   \n",
       "max                      94.250000                  100.000000   \n",
       "\n",
       "       environmental_humidity_min  environmental_precipitation  \\\n",
       "count                  648.000000                   648.000000   \n",
       "mean                    43.833333                     2.281636   \n",
       "std                     13.079710                     3.664127   \n",
       "min                     19.000000                     0.000000   \n",
       "25%                     35.000000                     0.000000   \n",
       "50%                     40.000000                     0.100000   \n",
       "75%                     54.000000                     2.300000   \n",
       "max                     84.000000                    15.000000   \n",
       "\n",
       "       environmental_cloudcover  ...  stress_level_rolling_q75_3d  \\\n",
       "count                648.000000  ...                   647.000000   \n",
       "mean                  48.630980  ...                     1.268934   \n",
       "std                   31.175947  ...                     0.625293   \n",
       "min                    0.041667  ...                     0.000000   \n",
       "25%                   27.250000  ...                     0.750000   \n",
       "50%                   39.083333  ...                     1.000000   \n",
       "75%                   77.375000  ...                     1.750000   \n",
       "max                   99.916667  ...                     2.000000   \n",
       "\n",
       "       stress_level_rolling_range_3d  stress_level_rolling_iqr_3d  \\\n",
       "count                     647.000000                   647.000000   \n",
       "mean                        0.476043                     0.238022   \n",
       "std                         0.603625                     0.301813   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         0.000000                     0.000000   \n",
       "50%                         0.000000                     0.000000   \n",
       "75%                         1.000000                     0.500000   \n",
       "max                         2.000000                     1.000000   \n",
       "\n",
       "       stress_level_rolling_cv_3d  stress_level_rolling_trend_slope_3d  \\\n",
       "count                  600.000000                           600.000000   \n",
       "mean                     0.442335                             0.013333   \n",
       "std                      0.581263                             0.798468   \n",
       "min                      0.000000                            -2.000000   \n",
       "25%                      0.000000                             0.000000   \n",
       "50%                      0.000000                             0.000000   \n",
       "75%                      0.471405                             0.000000   \n",
       "max                      1.414214                             2.000000   \n",
       "\n",
       "       stress_level_rolling_direction_changes_3d  \\\n",
       "count                                      647.0   \n",
       "mean                                         0.0   \n",
       "std                                          0.0   \n",
       "min                                          0.0   \n",
       "25%                                          0.0   \n",
       "50%                                          0.0   \n",
       "75%                                          0.0   \n",
       "max                                          0.0   \n",
       "\n",
       "       stress_level_rolling_entropy_3d  stress_level_rolling_zscore_3d  \\\n",
       "count                       647.000000                      600.000000   \n",
       "mean                          0.418856                        0.015321   \n",
       "std                           0.493753                        0.475369   \n",
       "min                           0.000000                       -0.707107   \n",
       "25%                           0.000000                        0.000000   \n",
       "50%                           0.000000                        0.000000   \n",
       "75%                           1.000000                        0.000000   \n",
       "max                           1.000000                        0.707107   \n",
       "\n",
       "       stress_level_rolling_time_since_peak_3d  \\\n",
       "count                               647.000000   \n",
       "mean                                  0.744977   \n",
       "std                                   0.436211   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                   1.000000   \n",
       "75%                                   1.000000   \n",
       "max                                   1.000000   \n",
       "\n",
       "       stress_level_rolling_time_since_trough_3d  \n",
       "count                                 647.000000  \n",
       "mean                                    0.765070  \n",
       "std                                     0.424283  \n",
       "min                                     0.000000  \n",
       "25%                                     1.000000  \n",
       "50%                                     1.000000  \n",
       "75%                                     1.000000  \n",
       "max                                     1.000000  \n",
       "\n",
       "[8 rows x 468 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18 columns with zero or single unique values: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d']\n",
      "List of dropped columns: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d', 'environmental_temperature_mean_rolling_median_3d', 'environmental_temperature_mean_rolling_q25_3d', 'environmental_temperature_mean_rolling_q75_3d', 'environmental_temperature_mean_rolling_range_3d', 'environmental_temperature_mean_rolling_iqr_3d', 'environmental_temperature_max_rolling_mean_3d', 'environmental_temperature_max_rolling_q25_3d', 'environmental_temperature_max_rolling_q75_3d', 'environmental_temperature_max_rolling_range_3d', 'environmental_temperature_max_rolling_iqr_3d', 'environmental_temperature_min_rolling_q25_3d', 'environmental_temperature_min_rolling_q75_3d', 'environmental_temperature_min_rolling_range_3d', 'environmental_temperature_min_rolling_iqr_3d', 'environmental_humidity_mean_rolling_range_3d', 'environmental_humidity_mean_rolling_iqr_3d', 'environmental_humidity_max_rolling_range_3d', 'environmental_humidity_max_rolling_iqr_3d', 'environmental_humidity_max_rolling_cv_3d', 'environmental_humidity_min_rolling_range_3d', 'environmental_humidity_min_rolling_iqr_3d', 'environmental_precipitation_rolling_q75_3d', 'environmental_precipitation_rolling_range_3d', 'environmental_precipitation_rolling_iqr_3d', 'environmental_cloudcover_rolling_range_3d', 'environmental_cloudcover_rolling_iqr_3d', 'individual_sleep_duration_rolling_range_3d', 'individual_sleep_duration_rolling_iqr_3d', 'individual_sleep_rate_rolling_range_3d', 'individual_sleep_rate_rolling_iqr_3d', 'organizational_social_interaction_rolling_q25_3d', 'organizational_social_interaction_rolling_q75_3d', 'organizational_social_interaction_rolling_range_3d', 'organizational_social_interaction_rolling_iqr_3d', 'organizational_social_voice_sum_rolling_q75_3d', 'organizational_social_voice_sum_rolling_range_3d', 'organizational_social_voice_sum_rolling_iqr_3d', 'organizational_social_voice_count_rolling_range_3d', 'organizational_social_voice_count_rolling_iqr_3d', 'organizational_social_voice_mean_rolling_q75_3d', 'organizational_social_voice_mean_rolling_range_3d', 'organizational_social_voice_mean_rolling_iqr_3d', 'organizational_social_voice_max_rolling_range_3d', 'organizational_social_voice_max_rolling_iqr_3d', 'individual_minutes_stationary_rolling_q25_3d', 'individual_minutes_stationary_rolling_range_3d', 'individual_minutes_stationary_rolling_iqr_3d', 'individual_minutes_walking_rolling_q75_3d', 'individual_minutes_walking_rolling_range_3d', 'individual_minutes_walking_rolling_iqr_3d', 'individual_minutes_running_rolling_q75_3d', 'individual_minutes_running_rolling_range_3d', 'individual_minutes_running_rolling_iqr_3d', 'individual_minutes_unknown_rolling_q75_3d', 'individual_minutes_unknown_rolling_range_3d', 'individual_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_silence_rolling_range_3d', 'environmental_minutes_silence_rolling_iqr_3d', 'environmental_minutes_voice_rolling_range_3d', 'environmental_minutes_voice_rolling_iqr_3d', 'environmental_minutes_noise_rolling_q75_3d', 'environmental_minutes_noise_rolling_range_3d', 'environmental_minutes_noise_rolling_iqr_3d', 'organizational_work_hours_rolling_range_3d', 'organizational_work_hours_rolling_iqr_3d', 'organizational_deadlines_rolling_q75_3d', 'organizational_deadlines_rolling_range_3d', 'organizational_deadlines_rolling_iqr_3d', 'organizational_days_until_next_deadline_rolling_q75_3d', 'organizational_days_until_next_deadline_rolling_range_3d', 'organizational_days_until_next_deadline_rolling_iqr_3d', 'stress_level_rolling_median_3d', 'stress_level_rolling_q25_3d', 'stress_level_rolling_range_3d', 'stress_level_rolling_iqr_3d']\n",
      "--- STAGE 1: Finding the globally optimal set of features with RFECV ---\n",
      "\n",
      "--- Running RFECV for domain: environmental (155 features) ---\n",
      "Selected 2 features for environmental: ['environmental_minutes_voice_rolling_min_3d', 'environmental_minutes_voice_rolling_max_3d']\n",
      "\n",
      "--- Running RFECV for domain: individual (93 features) ---\n",
      "Selected 36 features for individual: ['individual_sleep_rate', 'individual_minutes_unknown', 'individual_personality_extraversion', 'individual_personality_agreeableness', 'individual_personality_conscientiousness', 'individual_personality_neuroticism', 'individual_personality_openness', 'individual_sleep_duration_rolling_mean_3d', 'individual_sleep_duration_rolling_std_3d', 'individual_sleep_duration_rolling_min_3d', 'individual_sleep_duration_rolling_trend_slope_3d', 'individual_sleep_duration_rolling_entropy_3d', 'individual_sleep_duration_rolling_zscore_3d', 'individual_sleep_rate_rolling_mean_3d', 'individual_sleep_rate_rolling_cv_3d', 'individual_sleep_rate_rolling_entropy_3d', 'individual_sleep_rate_rolling_zscore_3d', 'individual_minutes_stationary_rolling_mean_3d', 'individual_minutes_stationary_rolling_median_3d', 'individual_minutes_stationary_rolling_q75_3d', 'individual_minutes_walking_rolling_mean_3d', 'individual_minutes_walking_rolling_min_3d', 'individual_minutes_walking_rolling_q25_3d', 'individual_minutes_walking_rolling_cv_3d', 'individual_minutes_walking_rolling_trend_slope_3d', 'individual_minutes_running_rolling_mean_3d', 'individual_minutes_running_rolling_cv_3d', 'individual_minutes_running_rolling_zscore_3d', 'individual_minutes_unknown_rolling_mean_3d', 'individual_minutes_unknown_rolling_std_3d', 'individual_minutes_unknown_rolling_min_3d', 'individual_minutes_unknown_rolling_max_3d', 'individual_minutes_unknown_rolling_median_3d', 'individual_minutes_unknown_rolling_cv_3d', 'individual_minutes_unknown_rolling_zscore_3d', 'individual_minutes_unknown_rolling_time_since_trough_3d']\n",
      "\n",
      "--- Running RFECV for domain: organizational (114 features) ---\n",
      "Selected 30 features for organizational: ['organizational_social_voice_sum', 'organizational_social_voice_mean', 'organizational_days_until_next_deadline', 'organizational_social_interaction_rolling_mean_3d', 'organizational_social_interaction_rolling_min_3d', 'organizational_social_interaction_rolling_zscore_3d', 'organizational_social_voice_sum_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_min_3d', 'organizational_social_voice_count_rolling_median_3d', 'organizational_social_voice_count_rolling_entropy_3d', 'organizational_social_voice_count_rolling_zscore_3d', 'organizational_social_voice_mean_rolling_mean_3d', 'organizational_social_voice_mean_rolling_min_3d', 'organizational_social_voice_mean_rolling_max_3d', 'organizational_social_voice_mean_rolling_median_3d', 'organizational_social_voice_mean_rolling_cv_3d', 'organizational_social_voice_mean_rolling_trend_slope_3d', 'organizational_social_voice_mean_rolling_zscore_3d', 'organizational_social_voice_max_rolling_std_3d', 'organizational_social_voice_max_rolling_min_3d', 'organizational_social_voice_max_rolling_median_3d', 'organizational_social_voice_max_rolling_cv_3d', 'organizational_social_voice_max_rolling_zscore_3d', 'organizational_social_voice_max_rolling_time_since_peak_3d', 'organizational_work_hours_rolling_std_3d', 'organizational_work_hours_rolling_max_3d', 'organizational_deadlines_rolling_mean_3d', 'organizational_deadlines_rolling_std_3d', 'organizational_days_until_next_deadline_rolling_min_3d', 'organizational_days_until_next_deadline_rolling_trend_slope_3d']\n",
      "\n",
      "--- Running RFECV for domain: stress_history (11 features) ---\n",
      "Selected 2 features for stress_history: ['stress_level_rolling_mean_3d', 'stress_level_rolling_min_3d']\n",
      "\n",
      "--- Final combined set of 70 features ---\n",
      "['environmental_minutes_voice_rolling_min_3d', 'environmental_minutes_voice_rolling_max_3d', 'individual_sleep_rate', 'individual_minutes_unknown', 'individual_personality_extraversion', 'individual_personality_agreeableness', 'individual_personality_conscientiousness', 'individual_personality_neuroticism', 'individual_personality_openness', 'individual_sleep_duration_rolling_mean_3d', 'individual_sleep_duration_rolling_std_3d', 'individual_sleep_duration_rolling_min_3d', 'individual_sleep_duration_rolling_trend_slope_3d', 'individual_sleep_duration_rolling_entropy_3d', 'individual_sleep_duration_rolling_zscore_3d', 'individual_sleep_rate_rolling_mean_3d', 'individual_sleep_rate_rolling_cv_3d', 'individual_sleep_rate_rolling_entropy_3d', 'individual_sleep_rate_rolling_zscore_3d', 'individual_minutes_stationary_rolling_mean_3d', 'individual_minutes_stationary_rolling_median_3d', 'individual_minutes_stationary_rolling_q75_3d', 'individual_minutes_walking_rolling_mean_3d', 'individual_minutes_walking_rolling_min_3d', 'individual_minutes_walking_rolling_q25_3d', 'individual_minutes_walking_rolling_cv_3d', 'individual_minutes_walking_rolling_trend_slope_3d', 'individual_minutes_running_rolling_mean_3d', 'individual_minutes_running_rolling_cv_3d', 'individual_minutes_running_rolling_zscore_3d', 'individual_minutes_unknown_rolling_mean_3d', 'individual_minutes_unknown_rolling_std_3d', 'individual_minutes_unknown_rolling_min_3d', 'individual_minutes_unknown_rolling_max_3d', 'individual_minutes_unknown_rolling_median_3d', 'individual_minutes_unknown_rolling_cv_3d', 'individual_minutes_unknown_rolling_zscore_3d', 'individual_minutes_unknown_rolling_time_since_trough_3d', 'organizational_social_voice_sum', 'organizational_social_voice_mean', 'organizational_days_until_next_deadline', 'organizational_social_interaction_rolling_mean_3d', 'organizational_social_interaction_rolling_min_3d', 'organizational_social_interaction_rolling_zscore_3d', 'organizational_social_voice_sum_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_min_3d', 'organizational_social_voice_count_rolling_median_3d', 'organizational_social_voice_count_rolling_entropy_3d', 'organizational_social_voice_count_rolling_zscore_3d', 'organizational_social_voice_mean_rolling_mean_3d', 'organizational_social_voice_mean_rolling_min_3d', 'organizational_social_voice_mean_rolling_max_3d', 'organizational_social_voice_mean_rolling_median_3d', 'organizational_social_voice_mean_rolling_cv_3d', 'organizational_social_voice_mean_rolling_trend_slope_3d', 'organizational_social_voice_mean_rolling_zscore_3d', 'organizational_social_voice_max_rolling_std_3d', 'organizational_social_voice_max_rolling_min_3d', 'organizational_social_voice_max_rolling_median_3d', 'organizational_social_voice_max_rolling_cv_3d', 'organizational_social_voice_max_rolling_zscore_3d', 'organizational_social_voice_max_rolling_time_since_peak_3d', 'organizational_work_hours_rolling_std_3d', 'organizational_work_hours_rolling_max_3d', 'organizational_deadlines_rolling_mean_3d', 'organizational_deadlines_rolling_std_3d', 'organizational_days_until_next_deadline_rolling_min_3d', 'organizational_days_until_next_deadline_rolling_trend_slope_3d', 'stress_level_rolling_mean_3d', 'stress_level_rolling_min_3d']\n",
      "\n",
      "--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\n",
      "\n",
      "Best hyperparameters found: {'n_estimators': 200, 'learning_rate': 0.1484087283408702, 'max_depth': 10, 'subsample': 0.93331478524767, 'colsample_bytree': 0.7668736709223272, 'reg_alpha': 7.961374444864547e-05, 'reg_lambda': 3.8144514833385274e-08}\n",
      "\n",
      "--- STAGE 3: Final evaluation using 70 best features and optimal hyperparameters ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Fold Accuracy: 0.4400\n",
      "Fold F1-Score (Weighted): 0.4439\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Fold Accuracy: 0.4419\n",
      "Fold F1-Score (Weighted): 0.4247\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Fold Accuracy: 0.3816\n",
      "Fold F1-Score (Weighted): 0.4097\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Fold Accuracy: 0.4865\n",
      "Fold F1-Score (Weighted): 0.4617\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Fold Accuracy: 0.5000\n",
      "Fold F1-Score (Weighted): 0.4753\n",
      "\n",
      "--- Final Cross-Validation Results ---\n",
      "Mean Accuracy: 0.4500 ± 0.0417\n",
      "Mean F1-Score (Weighted): 0.4431 ± 0.0238\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24091993)\n",
    "\n",
    "# English: Suppress Optuna's trial logs for a cleaner output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# enriched_df = enriched_df[enriched_df['user_id'] != 59]# dataset.copy()\n",
    "\n",
    "# English: Filter out users who do not have all three stress classes\n",
    "#user_class_diversity = enriched_df.groupby('user_id')['stress_level'].nunique()\n",
    "#complete_users = user_class_diversity[user_class_diversity == 3].index\n",
    "#df_complete_stress = enriched_df[enriched_df['user_id'].isin(complete_users)].copy()\n",
    "\n",
    "# English: From the remaining users, select the top 20 by response count\n",
    "#user_counts_filtered = df_complete_stress['user_id'].value_counts()\n",
    "#num_top_users = min(20, len(user_counts_filtered))\n",
    "#top_users_from_complete = user_counts_filtered.head(num_top_users).index\n",
    "#df_final_selection = df_complete_stress[df_complete_stress['user_id'].isin(top_users_from_complete)].copy()\n",
    "\n",
    "# English: Now, handle NaNs and Infs\n",
    "enriched_df_filled = enriched_df.dropna()\n",
    "#enriched_df_filled.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_model = enriched_df_filled.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# English: Define X, Y, and groups for the entire process\n",
    "Y = df_model['stress_level']\n",
    "X = df_model.drop(columns=['stress_level', 'user_id', 'date'])\n",
    "\n",
    "correlation_threshold = 0.98\n",
    "\n",
    "# Apply the function\n",
    "X, dropped_columns = remove_highly_correlated_features(X, threshold=correlation_threshold)\n",
    "print(\"List of dropped columns:\", dropped_columns)\n",
    "\n",
    "groups = df_model['user_id']\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 1: GLOBAL FEATURE SELECTION WITH RFECV\n",
    "# ==============================================================================\n",
    "print(\"--- STAGE 1: Finding the globally optimal set of features with RFECV ---\")\n",
    "\n",
    "# English: Define your feature domains based on their prefixes\n",
    "# (Adjust these lists based on your actual column names)\n",
    "environmental_cols = [col for col in X.columns if 'environmental_' in col]\n",
    "individual_cols = [col for col in X.columns if 'individual_' in col]\n",
    "organizational_cols = [col for col in X.columns if 'organizational_' in col]\n",
    "stress_history_cols = [col for col in X.columns if 'stress_level_' in col] # Assuming lagged features start with this\n",
    "\n",
    "feature_domains = {\n",
    "    \"environmental\": environmental_cols,\n",
    "    \"individual\": individual_cols,\n",
    "    \"organizational\": organizational_cols,\n",
    "    \"stress_history\": stress_history_cols\n",
    "}\n",
    "\n",
    "best_features_per_domain = {}\n",
    "N_FEATURES_PER_DOMAIN = 1\n",
    "\n",
    "for domain, cols in feature_domains.items():\n",
    "    print(f\"\\n--- Running RFECV for domain: {domain} ({len(cols)} features) ---\")\n",
    "    if not cols:\n",
    "        print(\"No columns found for this domain. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    X_domain = X[cols]\n",
    "    \n",
    "    # Initialize RFECV for this domain\n",
    "    estimator = XGBClassifier(objective='multiclass', random_state=24091993, n_jobs=-1)\n",
    "    cv_strategy = GroupKFold(n_splits=5)\n",
    "    rfecv_domain = RFECV(\n",
    "        estimator=estimator,\n",
    "        step=1,\n",
    "        cv=cv_strategy,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        min_features_to_select=N_FEATURES_PER_DOMAIN # Select at least N\n",
    "    )\n",
    "    \n",
    "    # Fit on the domain-specific data\n",
    "    rfecv_domain.fit(X_domain, Y, groups=groups)\n",
    "    \n",
    "    # Store the best features for this domain\n",
    "    selected_cols = X_domain.columns[rfecv_domain.support_].tolist()\n",
    "    best_features_per_domain[domain] = selected_cols\n",
    "    print(f\"Selected {len(selected_cols)} features for {domain}: {selected_cols}\")\n",
    "\n",
    "# --- Combine the best features from all domains ---\n",
    "final_selected_features = []\n",
    "for domain_features in best_features_per_domain.values():\n",
    "    final_selected_features.extend(domain_features)\n",
    "\n",
    "# Remove duplicates if any feature was selected in multiple domains\n",
    "final_selected_features = list(dict.fromkeys(final_selected_features)) \n",
    "\n",
    "print(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "print(final_selected_features)\n",
    "\n",
    "# Now, use this `final_selected_features` list to create your final X,\n",
    "# and proceed with hyperparameter tuning and model evaluation.\n",
    "X_selected = X[final_selected_features]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 2: GLOBAL HYPERPARAMETER TUNING WITH OPTUNA (ON SELECTED FEATURES)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\")\n",
    "\n",
    "def objective(trial, x_data, y_data, group_data):\n",
    "    param = {\n",
    "        'verbosity': 0, 'objective': 'multiclass', 'random_state': 24091993,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    f1_scores = []\n",
    "    for train_idx, test_idx in gkf.split(x_data, y_data, groups=group_data):\n",
    "        X_train, X_test = x_data.iloc[train_idx], x_data.iloc[test_idx]\n",
    "        y_train, y_test = y_data.iloc[train_idx], y_data.iloc[test_idx]\n",
    "        \n",
    "        # English: Apply class weights inside the objective function\n",
    "        class_weights_fold = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        sample_weights_fold = np.array([class_weights_fold[cls] for cls in y_train])\n",
    "        \n",
    "        model = XGBClassifier(**param)\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weights_fold)\n",
    "        preds = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, preds, average='weighted', zero_division=0))\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# English: Run Optuna study on the data with ONLY the selected features\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_selected, Y, groups), n_trials=50)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\nBest hyperparameters found:\", best_params)\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 3: FINAL UNBIASED EVALUATION\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- STAGE 3: Final evaluation using {len(final_selected_features)} best features and optimal hyperparameters ---\")\n",
    "\n",
    "n_splits = 5\n",
    "gkf_final = GroupKFold(n_splits=n_splits)\n",
    "all_accuracies = []\n",
    "all_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf_final.split(X_selected, Y, groups=groups)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "    \n",
    "    # English: Use the pre-selected features (X_selected) for splitting\n",
    "    X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    # English: Compute sample weights for the current training fold\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(Y_train), y=Y_train)\n",
    "    sample_weights = np.array([class_weights[cls] for cls in Y_train])    \n",
    "\n",
    "    # English: Initialize model with the best global parameters\n",
    "    model = XGBClassifier(objective='multiclass', random_state=24091993, **best_params)\n",
    "    model.fit(X_train, Y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # English: Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    f1 = f1_score(Y_test, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    all_accuracies.append(accuracy)\n",
    "    all_f1_scores.append(f1)\n",
    "    \n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# English: Display final results\n",
    "print(\"\\n--- Final Cross-Validation Results ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending results to experiment_log.txt...\n",
      "Results successfully logged.\n"
     ]
    }
   ],
   "source": [
    "# English: Import the datetime library at the top of your script\n",
    "import datetime\n",
    "\n",
    "# --- Option 2: Append results to a log file with a timestamp ---\n",
    "\n",
    "# English: Define the output filename\n",
    "results_log_filename = 'experiment_log.txt'\n",
    "\n",
    "# English: Get the current timestamp\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# English: Open the file in append mode ('a') to add new results\n",
    "with open(results_log_filename, 'a') as f:\n",
    "    print(f\"Appending results to {results_log_filename}...\")\n",
    "    \n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    \n",
    "    # English: Write a separator and timestamp for this run\n",
    "    f.write(f\"\\n--- Experiment Run: {timestamp} ---\\n\")\n",
    "    \n",
    "    # English: Write the metrics\n",
    "    f.write(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\\n\")\n",
    "    f.write(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\\n\")\n",
    "    f.write(\"\\nBest hyperparameters found: \" + str(best_params))\n",
    "    f.write(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "    f.write(str(final_selected_features))\n",
    "    \n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "print(\"Results successfully logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18 columns with zero or single unique values: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d']\n",
      "List of dropped columns: ['environmental_minutes_unknown', 'environmental_minutes_unknown_rolling_mean_3d', 'environmental_minutes_unknown_rolling_std_3d', 'environmental_minutes_unknown_rolling_min_3d', 'environmental_minutes_unknown_rolling_max_3d', 'environmental_minutes_unknown_rolling_median_3d', 'environmental_minutes_unknown_rolling_q25_3d', 'environmental_minutes_unknown_rolling_q75_3d', 'environmental_minutes_unknown_rolling_range_3d', 'environmental_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_unknown_rolling_cv_3d', 'environmental_minutes_unknown_rolling_trend_slope_3d', 'environmental_minutes_unknown_rolling_direction_changes_3d', 'environmental_minutes_unknown_rolling_entropy_3d', 'environmental_minutes_unknown_rolling_zscore_3d', 'environmental_minutes_unknown_rolling_time_since_peak_3d', 'environmental_minutes_unknown_rolling_time_since_trough_3d', 'stress_level_rolling_direction_changes_3d', 'environmental_temperature_mean_rolling_median_3d', 'environmental_temperature_mean_rolling_q25_3d', 'environmental_temperature_mean_rolling_q75_3d', 'environmental_temperature_mean_rolling_range_3d', 'environmental_temperature_mean_rolling_iqr_3d', 'environmental_temperature_max_rolling_mean_3d', 'environmental_temperature_max_rolling_q25_3d', 'environmental_temperature_max_rolling_q75_3d', 'environmental_temperature_max_rolling_range_3d', 'environmental_temperature_max_rolling_iqr_3d', 'environmental_temperature_min_rolling_q25_3d', 'environmental_temperature_min_rolling_q75_3d', 'environmental_temperature_min_rolling_range_3d', 'environmental_temperature_min_rolling_iqr_3d', 'environmental_humidity_mean_rolling_range_3d', 'environmental_humidity_mean_rolling_iqr_3d', 'environmental_humidity_max_rolling_range_3d', 'environmental_humidity_max_rolling_iqr_3d', 'environmental_humidity_max_rolling_cv_3d', 'environmental_humidity_min_rolling_range_3d', 'environmental_humidity_min_rolling_iqr_3d', 'environmental_precipitation_rolling_q75_3d', 'environmental_precipitation_rolling_range_3d', 'environmental_precipitation_rolling_iqr_3d', 'environmental_cloudcover_rolling_range_3d', 'environmental_cloudcover_rolling_iqr_3d', 'individual_sleep_duration_rolling_range_3d', 'individual_sleep_duration_rolling_iqr_3d', 'individual_sleep_rate_rolling_range_3d', 'individual_sleep_rate_rolling_iqr_3d', 'organizational_social_interaction_rolling_q25_3d', 'organizational_social_interaction_rolling_q75_3d', 'organizational_social_interaction_rolling_range_3d', 'organizational_social_interaction_rolling_iqr_3d', 'organizational_social_voice_sum_rolling_q75_3d', 'organizational_social_voice_sum_rolling_range_3d', 'organizational_social_voice_sum_rolling_iqr_3d', 'organizational_social_voice_count_rolling_range_3d', 'organizational_social_voice_count_rolling_iqr_3d', 'organizational_social_voice_mean_rolling_q75_3d', 'organizational_social_voice_mean_rolling_range_3d', 'organizational_social_voice_mean_rolling_iqr_3d', 'organizational_social_voice_max_rolling_range_3d', 'organizational_social_voice_max_rolling_iqr_3d', 'individual_minutes_stationary_rolling_q25_3d', 'individual_minutes_stationary_rolling_range_3d', 'individual_minutes_stationary_rolling_iqr_3d', 'individual_minutes_walking_rolling_q75_3d', 'individual_minutes_walking_rolling_range_3d', 'individual_minutes_walking_rolling_iqr_3d', 'individual_minutes_running_rolling_q75_3d', 'individual_minutes_running_rolling_range_3d', 'individual_minutes_running_rolling_iqr_3d', 'individual_minutes_unknown_rolling_q75_3d', 'individual_minutes_unknown_rolling_range_3d', 'individual_minutes_unknown_rolling_iqr_3d', 'environmental_minutes_silence_rolling_range_3d', 'environmental_minutes_silence_rolling_iqr_3d', 'environmental_minutes_voice_rolling_range_3d', 'environmental_minutes_voice_rolling_iqr_3d', 'environmental_minutes_noise_rolling_q75_3d', 'environmental_minutes_noise_rolling_range_3d', 'environmental_minutes_noise_rolling_iqr_3d', 'organizational_work_hours_rolling_range_3d', 'organizational_work_hours_rolling_iqr_3d', 'organizational_deadlines_rolling_q75_3d', 'organizational_deadlines_rolling_range_3d', 'organizational_deadlines_rolling_iqr_3d', 'organizational_days_until_next_deadline_rolling_q75_3d', 'organizational_days_until_next_deadline_rolling_range_3d', 'organizational_days_until_next_deadline_rolling_iqr_3d', 'stress_level_rolling_median_3d', 'stress_level_rolling_q25_3d', 'stress_level_rolling_range_3d', 'stress_level_rolling_iqr_3d']\n",
      "--- STAGE 1: Finding the globally optimal set of features with RFECV ---\n",
      "\n",
      "--- Final combined set of 27 features ---\n",
      "['environmental_temperature_mean', 'environmental_cloudcover', 'organizational_social_voice_sum', 'individual_minutes_walking', 'individual_minutes_unknown', 'individual_personality_agreeableness', 'individual_personality_conscientiousness', 'individual_personality_openness', 'individual_flourishing_score', 'environmental_cloudcover_rolling_std_3d', 'environmental_cloudcover_rolling_min_3d', 'environmental_cloudcover_rolling_trend_slope_3d', 'environmental_cloudcover_rolling_zscore_3d', 'individual_sleep_duration_rolling_q25_3d', 'organizational_social_voice_sum_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_min_3d', 'organizational_social_voice_count_rolling_trend_slope_3d', 'organizational_social_voice_count_rolling_zscore_3d', 'organizational_social_voice_mean_rolling_mean_3d', 'organizational_social_voice_mean_rolling_q25_3d', 'organizational_social_voice_max_rolling_trend_slope_3d', 'individual_minutes_walking_rolling_max_3d', 'individual_minutes_walking_rolling_q25_3d', 'individual_minutes_unknown_rolling_min_3d', 'environmental_minutes_noise_rolling_max_3d', 'organizational_deadlines_rolling_zscore_3d', 'stress_level_rolling_mean_3d']\n",
      "\n",
      "--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\n",
      "\n",
      "Best hyperparameters found: {'n_estimators': 120, 'learning_rate': 0.01595626609736153, 'max_depth': 8, 'subsample': 0.9908055748111488, 'colsample_bytree': 0.6259621351668307, 'reg_alpha': 0.00018273503800083003, 'reg_lambda': 0.5230354861971547}\n",
      "\n",
      "--- STAGE 3: Final evaluation using 27 best features and optimal hyperparameters ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Fold Accuracy: 0.5467\n",
      "Fold F1-Score (Weighted): 0.5288\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Fold Accuracy: 0.5000\n",
      "Fold F1-Score (Weighted): 0.4984\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Fold Accuracy: 0.4079\n",
      "Fold F1-Score (Weighted): 0.4448\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Fold Accuracy: 0.6081\n",
      "Fold F1-Score (Weighted): 0.5958\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Fold Accuracy: 0.5814\n",
      "Fold F1-Score (Weighted): 0.5649\n",
      "\n",
      "--- Final Cross-Validation Results ---\n",
      "Mean Accuracy: 0.5288 ± 0.0705\n",
      "Mean F1-Score (Weighted): 0.5265 ± 0.0524\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24091993)\n",
    "\n",
    "# English: Suppress Optuna's trial logs for a cleaner output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "enriched_df = enriched_df[enriched_df['user_id'] != 59]# dataset.copy()\n",
    "\n",
    "# English: Filter out users who do not have all three stress classes\n",
    "#user_class_diversity = enriched_df.groupby('user_id')['stress_level'].nunique()\n",
    "#complete_users = user_class_diversity[user_class_diversity == 3].index\n",
    "#df_complete_stress = enriched_df[enriched_df['user_id'].isin(complete_users)].copy()\n",
    "\n",
    "# English: From the remaining users, select the top 20 by response count\n",
    "#user_counts_filtered = df_complete_stress['user_id'].value_counts()\n",
    "#num_top_users = min(20, len(user_counts_filtered))\n",
    "#top_users_from_complete = user_counts_filtered.head(num_top_users).index\n",
    "#df_final_selection = df_complete_stress[df_complete_stress['user_id'].isin(top_users_from_complete)].copy()\n",
    "\n",
    "# English: Now, handle NaNs and Infs\n",
    "enriched_df_filled = enriched_df.dropna()\n",
    "#enriched_df_filled.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_model = enriched_df_filled.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# English: Define X, Y, and groups for the entire process\n",
    "Y = df_model['stress_level']\n",
    "X = df_model.drop(columns=['stress_level', 'user_id', 'date'])\n",
    "\n",
    "correlation_threshold = 0.98\n",
    "\n",
    "# Apply the function\n",
    "X, dropped_columns = remove_highly_correlated_features(X, threshold=correlation_threshold)\n",
    "print(\"List of dropped columns:\", dropped_columns)\n",
    "\n",
    "groups = df_model['user_id']\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 1: GLOBAL FEATURE SELECTION WITH RFECV\n",
    "# ==============================================================================\n",
    "print(\"--- STAGE 1: Finding the globally optimal set of features with RFECV ---\")\n",
    "        \n",
    "# Initialize RFECV for this domain\n",
    "estimator = XGBClassifier(objective='multiclass', random_state=24091993, n_jobs=-1)\n",
    "cv_strategy = GroupKFold(n_splits=5)\n",
    "rfecv = RFECV(\n",
    "    estimator=estimator,\n",
    "    step=1,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    min_features_to_select=1 # Select at least N\n",
    ")\n",
    "\n",
    "# Fit on the domain-specific data\n",
    "rfecv.fit(X, Y, groups=groups)\n",
    "\n",
    "# Store the best features for this domain\n",
    "selected_cols = X.columns[rfecv.support_].tolist()\n",
    "\n",
    "# Remove duplicates if any feature was selected in multiple domains\n",
    "final_selected_features = selected_cols\n",
    "\n",
    "print(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "print(final_selected_features)\n",
    "\n",
    "# Now, use this `final_selected_features` list to create your final X,\n",
    "# and proceed with hyperparameter tuning and model evaluation.\n",
    "X_selected = X[final_selected_features]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 2: GLOBAL HYPERPARAMETER TUNING WITH OPTUNA (ON SELECTED FEATURES)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- STAGE 2: Finding optimal hyperparameters with Optuna on selected features ---\")\n",
    "\n",
    "def objective(trial, x_data, y_data, group_data):\n",
    "    param = {\n",
    "        'verbosity': 0, 'objective': 'multiclass', 'random_state': 24091993,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, log=True),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    f1_scores = []\n",
    "    for train_idx, test_idx in gkf.split(x_data, y_data, groups=group_data):\n",
    "        X_train, X_test = x_data.iloc[train_idx], x_data.iloc[test_idx]\n",
    "        y_train, y_test = y_data.iloc[train_idx], y_data.iloc[test_idx]\n",
    "        \n",
    "        # English: Apply class weights inside the objective function\n",
    "        class_weights_fold = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        sample_weights_fold = np.array([class_weights_fold[cls] for cls in y_train])\n",
    "        \n",
    "        model = XGBClassifier(**param)\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weights_fold)\n",
    "        preds = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, preds, average='weighted', zero_division=0))\n",
    "        \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# English: Run Optuna study on the data with ONLY the selected features\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_selected, Y, groups), n_trials=50)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\nBest hyperparameters found:\", best_params)\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 3: FINAL UNBIASED EVALUATION\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- STAGE 3: Final evaluation using {len(final_selected_features)} best features and optimal hyperparameters ---\")\n",
    "\n",
    "n_splits = 5\n",
    "gkf_final = GroupKFold(n_splits=n_splits)\n",
    "all_accuracies = []\n",
    "all_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf_final.split(X_selected, Y, groups=groups)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{n_splits} ---\")\n",
    "    \n",
    "    # English: Use the pre-selected features (X_selected) for splitting\n",
    "    X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    # English: Compute sample weights for the current training fold\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(Y_train), y=Y_train)\n",
    "    sample_weights = np.array([class_weights[cls] for cls in Y_train])    \n",
    "\n",
    "    # English: Initialize model with the best global parameters\n",
    "    model = XGBClassifier(objective='multiclass', random_state=24091993, **best_params)\n",
    "    model.fit(X_train, Y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # English: Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    f1 = f1_score(Y_test, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    all_accuracies.append(accuracy)\n",
    "    all_f1_scores.append(f1)\n",
    "    \n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# English: Display final results\n",
    "print(\"\\n--- Final Cross-Validation Results ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending results to experiment_log.txt...\n",
      "Results successfully logged.\n"
     ]
    }
   ],
   "source": [
    "# English: Import the datetime library at the top of your script\n",
    "import datetime\n",
    "\n",
    "# --- Option 2: Append results to a log file with a timestamp ---\n",
    "\n",
    "# English: Define the output filename\n",
    "results_log_filename = 'experiment_log.txt'\n",
    "\n",
    "# English: Get the current timestamp\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# English: Open the file in append mode ('a') to add new results\n",
    "with open(results_log_filename, 'a') as f:\n",
    "    print(f\"Appending results to {results_log_filename}...\")\n",
    "    \n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    # English: Write a separator and timestamp for this run\n",
    "    f.write(f\"\\n--- Experiment Run: {timestamp} ---\\n\")\n",
    "    \n",
    "    # English: Write the metrics\n",
    "    f.write(f\"Mean Accuracy: {np.mean(all_accuracies):.4f} ± {np.std(all_accuracies):.4f}\\n\")\n",
    "    f.write(f\"Mean F1-Score (Weighted): {np.mean(all_f1_scores):.4f} ± {np.std(all_f1_scores):.4f}\\n\")\n",
    "    f.write(\"\\nBest hyperparameters found: \" + str(best_params))\n",
    "    f.write(f\"\\n--- Final combined set of {len(final_selected_features)} features ---\")\n",
    "    f.write(str(final_selected_features))\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "    f.write(f\"\\n-----------------------------------------------------\\n\")\n",
    "print(\"Results successfully logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5158066523448012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>environmental_temperature_mean</th>\n",
       "      <th>environmental_temperature_max</th>\n",
       "      <th>environmental_temperature_min</th>\n",
       "      <th>environmental_humidity_mean</th>\n",
       "      <th>environmental_humidity_max</th>\n",
       "      <th>environmental_humidity_min</th>\n",
       "      <th>environmental_precipitation</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level_rolling_q75_3d</th>\n",
       "      <th>stress_level_rolling_range_3d</th>\n",
       "      <th>stress_level_rolling_iqr_3d</th>\n",
       "      <th>stress_level_rolling_cv_3d</th>\n",
       "      <th>stress_level_rolling_trend_slope_3d</th>\n",
       "      <th>stress_level_rolling_direction_changes_3d</th>\n",
       "      <th>stress_level_rolling_entropy_3d</th>\n",
       "      <th>stress_level_rolling_zscore_3d</th>\n",
       "      <th>stress_level_rolling_time_since_peak_3d</th>\n",
       "      <th>stress_level_rolling_time_since_trough_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>76.333333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>3.354167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.150000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1.929167</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>47.041667</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>2</td>\n",
       "      <td>3.525000</td>\n",
       "      <td>9.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>58.875000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>1</td>\n",
       "      <td>18.033333</td>\n",
       "      <td>24.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>87.875000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-22</td>\n",
       "      <td>1</td>\n",
       "      <td>14.208333</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>87.708333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>24.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>88.083333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>2</td>\n",
       "      <td>13.508333</td>\n",
       "      <td>19.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>59</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>2</td>\n",
       "      <td>9.662500</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.041667</td>\n",
       "      <td>95.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id        date  stress_level  environmental_temperature_mean  \\\n",
       "3          4  2013-03-28             0                        3.450000   \n",
       "4          4  2013-03-29             1                        3.354167   \n",
       "2          4  2013-04-03             2                       -1.150000   \n",
       "5          4  2013-04-04             0                        1.929167   \n",
       "6          4  2013-04-05             2                        3.525000   \n",
       "..       ...         ...           ...                             ...   \n",
       "643       59  2013-05-21             1                       18.033333   \n",
       "644       59  2013-05-22             1                       14.208333   \n",
       "645       59  2013-05-23             1                       18.450000   \n",
       "646       59  2013-05-24             2                       13.508333   \n",
       "647       59  2013-05-27             2                        9.662500   \n",
       "\n",
       "     environmental_temperature_max  environmental_temperature_min  \\\n",
       "3                              8.0                            0.9   \n",
       "4                              8.6                           -1.6   \n",
       "2                              4.0                           -4.2   \n",
       "5                              8.6                           -2.2   \n",
       "6                              9.9                           -2.0   \n",
       "..                             ...                            ...   \n",
       "643                           24.4                           13.9   \n",
       "644                           24.5                            8.5   \n",
       "645                           24.7                           13.7   \n",
       "646                           19.4                            6.9   \n",
       "647                           17.4                            2.3   \n",
       "\n",
       "     environmental_humidity_mean  environmental_humidity_max  \\\n",
       "3                      76.333333                        95.0   \n",
       "4                      75.833333                        95.0   \n",
       "2                      45.833333                        58.0   \n",
       "5                      47.041667                        58.0   \n",
       "6                      58.875000                        78.0   \n",
       "..                           ...                         ...   \n",
       "643                    87.875000                        97.0   \n",
       "644                    87.708333                        99.0   \n",
       "645                    88.083333                        99.0   \n",
       "646                    94.250000                       100.0   \n",
       "647                    69.041667                        95.0   \n",
       "\n",
       "     environmental_humidity_min  environmental_precipitation  ...  \\\n",
       "3                          47.0                          1.5  ...   \n",
       "4                          55.0                          1.3  ...   \n",
       "2                          29.0                          0.0  ...   \n",
       "5                          33.0                          0.0  ...   \n",
       "6                          40.0                          0.0  ...   \n",
       "..                          ...                          ...  ...   \n",
       "643                        67.0                          5.5  ...   \n",
       "644                        63.0                          6.2  ...   \n",
       "645                        68.0                          1.9  ...   \n",
       "646                        84.0                         11.7  ...   \n",
       "647                        38.0                          0.0  ...   \n",
       "\n",
       "     stress_level_rolling_q75_3d  stress_level_rolling_range_3d  \\\n",
       "3                           0.75                            1.0   \n",
       "4                           1.00                            0.0   \n",
       "2                           0.00                            0.0   \n",
       "5                           1.75                            1.0   \n",
       "6                           1.50                            2.0   \n",
       "..                           ...                            ...   \n",
       "643                         1.75                            1.0   \n",
       "644                         1.00                            0.0   \n",
       "645                         1.00                            0.0   \n",
       "646                         1.00                            0.0   \n",
       "647                         1.75                            1.0   \n",
       "\n",
       "     stress_level_rolling_iqr_3d  stress_level_rolling_cv_3d  \\\n",
       "3                            0.5                    1.414214   \n",
       "4                            0.0                    0.000000   \n",
       "2                            0.0                    0.000000   \n",
       "5                            0.5                    0.471405   \n",
       "6                            1.0                    1.414214   \n",
       "..                           ...                         ...   \n",
       "643                          0.5                    0.471405   \n",
       "644                          0.0                    0.000000   \n",
       "645                          0.0                    0.000000   \n",
       "646                          0.0                    0.000000   \n",
       "647                          0.5                    0.471405   \n",
       "\n",
       "     stress_level_rolling_trend_slope_3d  \\\n",
       "3                                    1.0   \n",
       "4                                    0.0   \n",
       "2                                    0.0   \n",
       "5                                    1.0   \n",
       "6                                   -2.0   \n",
       "..                                   ...   \n",
       "643                                 -1.0   \n",
       "644                                  0.0   \n",
       "645                                  0.0   \n",
       "646                                  0.0   \n",
       "647                                  1.0   \n",
       "\n",
       "     stress_level_rolling_direction_changes_3d  \\\n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "2                                          0.0   \n",
       "5                                          0.0   \n",
       "6                                          0.0   \n",
       "..                                         ...   \n",
       "643                                        0.0   \n",
       "644                                        0.0   \n",
       "645                                        0.0   \n",
       "646                                        0.0   \n",
       "647                                        0.0   \n",
       "\n",
       "     stress_level_rolling_entropy_3d  stress_level_rolling_zscore_3d  \\\n",
       "3                                1.0                   -7.071068e-01   \n",
       "4                                0.0                   -1.000000e+08   \n",
       "2                                0.0                    1.000000e+08   \n",
       "5                                1.0                    7.071068e-01   \n",
       "6                                1.0                   -7.071068e-01   \n",
       "..                               ...                             ...   \n",
       "643                              1.0                   -7.071068e-01   \n",
       "644                              0.0                    0.000000e+00   \n",
       "645                              0.0                    0.000000e+00   \n",
       "646                              0.0                    0.000000e+00   \n",
       "647                              1.0                    7.071068e-01   \n",
       "\n",
       "     stress_level_rolling_time_since_peak_3d  \\\n",
       "3                                        0.0   \n",
       "4                                        1.0   \n",
       "2                                        1.0   \n",
       "5                                        0.0   \n",
       "6                                        1.0   \n",
       "..                                       ...   \n",
       "643                                      1.0   \n",
       "644                                      1.0   \n",
       "645                                      1.0   \n",
       "646                                      1.0   \n",
       "647                                      0.0   \n",
       "\n",
       "     stress_level_rolling_time_since_trough_3d  \n",
       "3                                          1.0  \n",
       "4                                          1.0  \n",
       "2                                          1.0  \n",
       "5                                          1.0  \n",
       "6                                          0.0  \n",
       "..                                         ...  \n",
       "643                                        0.0  \n",
       "644                                        1.0  \n",
       "645                                        1.0  \n",
       "646                                        1.0  \n",
       "647                                        1.0  \n",
       "\n",
       "[544 rows x 445 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context-stress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
